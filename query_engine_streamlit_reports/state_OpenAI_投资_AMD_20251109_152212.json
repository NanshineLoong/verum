{
  "query": "OpenAI 投资 AMD",
  "report_title": "关于'OpenAI 投资 AMD'的深度研究报告",
  "paragraphs": [
    {
      "title": "背景：OpenAI 的算力需求与现状",
      "content": "梳理 OpenAI 从成立至今对 GPU/加速卡的采购规模、与 NVIDIA 合作的商业细节、当前训练与推理成本压力，以及为何开始寻求第二供应商。",
      "research": {
        "search_history": [
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://www.huxiu.com/article/4797642.html",
            "title": "全成“绳上蚂蚱”，OpenAI是灵珠or魔丸？ - 虎嗅",
            "content": "* *虎嗅APP**虎嗅APP* * *公众号矩阵**公众号矩阵* * *社群矩阵**社群矩阵* * *我要投稿**我要投稿* # 全成“绳上蚂蚱”，OpenAI是灵珠or魔丸？ 海豚研究 本文来自微信公众号：海豚投研，作者：海豚君，题图来自：视觉中国 OpenAI最近真的是忙飞了，一会做电商，一会做社交，现在又推出了浏览器，emmmm......七姐妹已经树敌了一半。 三天一个热搜，海豚君简直跟不过来。表面看，OpenAI风生水起，势要成为改写人类走向的下一代新星。但明星光芒背后，海豚君已经感觉到OpenAI的焦虑。 所谓责任越大、压力越大。从2026年起，OpenAI的商业化能力，已经不仅仅是初代投资人的诉求，还成为了万亿产业链的生死寄托。 而吹起的估值泡泡，则要求更为苛刻，估值本身有时间成本的折损，因此考验的并不只是商业化的规模，更需要这个规模增长的斜率，一旦斜率放缓，就算产业还在进步，那么估值泡泡会率先刺破。90年代末的互联网股灾剧本，早就写好了。 话虽如此，海豚君也不希望泡泡破裂，毕竟良性可控的泡泡反而有利于新兴产业的发展——估值溢价吸引更多资金，实业才有钱生产扩张来教育市场渗透用户，用户使用后的数据反哺产品进行功能迭代，最终用户体验买单，产业盈利投资人收获回报。 在OpenAI收入与投入严重不匹配的情况下，与OpenAI有关联的生态圈无疑是产业中最大的风险点，尽管ChatGPT已经8亿用户规模，用户爬坡速度超过所有已经成功的互联网平台，但比用户规模增长更快的，是背后的算力需求以及OpenAI已经订下的供给订单。 趁着这几天OpenAI暂时的消停，海豚君先来算算OpenAI的账，这全靠资产负债表的扩张，能否在商业化放量之前撑住现金流。 以及，商业化要做到多少，才能满足后续的高昂算力成本、公司基本运营以及股东要求的回报，公司2030年2000亿的收入预期够吗？当然，最关键问题是，OpenAI能否做到？ 海豚君将分两篇聊聊上述问题，上篇主要讲OpenAI的算力产业链生态以及现金缺口，下篇则估算OpenAI的商业化潜力，看看是否有足够的承付能力。 以下为详细分析： 一、OpenAI的算力“糊涂账” 1. 利益绑死，这错综复杂的生态关系 9月末以来，AI算力产业链来了一波“大乱炖”，各家的竞争or合作or背刺or股权关系，简直是剪不清、理还乱。海豚君整理了一下重点新闻，大家也可以先通过关系图感受下这错综复杂的关系。 这其中，OpenAI绝对是主角中的主角。产业链各家与它的关系，说起来是甲乙方，是战略合作，实际上OpenAI已经用这些涉及最高超30GW算力的数据中心投资，1.5万亿美元的生态圈（数据中心总成本500亿美元/GW），狠狠套牢了产业链上游的AI基建大咖们。 下面海豚君详细来聊一聊： **（1）生态核心：星际之门** 最复杂的合作生态，就是OpenAI的星际之门项目，它将OpenAI与Oracle、Nvidia、软银等公司做了深度关联，被市场诟病的“资金循环”、“算力重复叠加”就在于此。 最早在2024年，媒体报道Microsoft和OpenAI计划投资1000亿打造星际之门（Stargate）AI超级计算机，将配备数百万个专用服务器芯片，以支持OpenAI的AGI发展。 当时还是OpenAI与Microsoft蜜里调油的时期。微软累计向OpenAI投资了130亿，除了股权，OpenAI给到微软一些技术授权、微软独供OpenAI云计算需求、独家代理ChatGPT的API接口等等。 但进入2025年之后，随着OpenAI重组完成，OpenAI与Microsoft的关系开始变得微妙了起来，不时有OpenAI与微软关系破裂降温的传闻。 这里的核心矛盾在于**扩大算力供给**的问题。微软作为一家成熟的上市公司，财务严谨是底线，而OpenAI一直要求微软快速扩建数据中心，要求数百GW规模。这让海豚君想起了今年Sam的“惊人”发言——OpenAI的发展在2030年将需要250GW的算力功耗。 250GW简直是一个微软怎么都吞不下的天量巨饼。一个简单的衡量标准，1GW功耗相当于500亿美金的基建投入，要数万亿美金的投入。同时1GW相当于100万个美国家庭的同时用电，那么250GW相当于2.5亿个家庭，这美国总人口才不过3亿多。 眼见OpenAI吐槽微软阻碍了它的发展，最终微软让步，将对OpenAI推理部分的独家算力供给权放开限制，允许OpenAI找别家云平台囤算力。之后OpenAI这才找到了后来的Oracle、Google，找了英伟达、AMD和博通等等。 OpenAI与微软之间的关系也变味了。当初想要让微软帮建的星际之门项目，2025年初换了投资方之后大大升级，从去年的1000亿美元的总投资额上升到未来4年投资5000亿美元，目标是打造10GW算力的数据中心群。 首先Stargate从项目成为了一个独立的公司，股东除了OpenAI外，换成了Oracle、Softbank以及MGX（阿联酋AI投资基金），各自负责数据中心建设运营、能源开发、资金来源，其中OpenAI、Softbank分别持有40%的股权，Oracle与MGX合计持有剩下的20%。 这样新成立的公司，从资源禀赋来看，其实就是一个OpenAI有绝对话语权的云服务商。这个云服务商数据中心的GPU芯片大部分采购于英伟达，尤其是最早开工的Abilene基本全部采用，包括不限于GB200、GB300以及VR200系列。 9月底，英伟达又通过分批投资的方式（每部署1GW注资100亿），总共向OpenAI“返利”1000亿元，并获得相应的OpenAI股权（也是分批计算，只要OpenAI的估值持续上涨，英伟达持股比例不会大于10%），来进一步加深了利益捆绑。 而曾经的亲密战友，微软则只是作为其他非参股的技术合作方参与其中，角色地位被明显弱化。 截至当前，部署目标已经规划了70%多，主力是美国七个数据中心站点，海外目前有清晰规划主要是挪威地区的站点，大多个数据中心园区的建设都在2026年之后竣工。比较快的就是软银主导集群和最先投入的Abilene站点，一年后就可投入运营，合计2.7GW的算力。 **（2）勾搭AMD：GPU的Plan B** 10月初在大家还沉浸在对OpenAI与英伟达的甜蜜捆绑津津乐道时，鸡贼的OpenAI留了一手，OpenAI马上宣布未来5年将通过云服务商，来部署6GW算力的AMD Instinct系列GPU。 首批部署为1GW的AMD Instinct MI450 GPU。也就是通过找备胎的方式，避免因为过度依赖而被裹挟。 作为回报，AMD向OpenAI按照部署节奏分6批次发行最多1.6亿认股权证（占目前10%的股权份额），行权价1美分基本等于白送。 同时，行权门槛也不高，虽然只说了首批权证在1GW部署完成并供应之后开始生效，但按逻辑讲，后续批次应该也是按照每部署1GW可以生效。 除了第六批认股权证的行权门槛是AMD要达到万亿美金市值（相当于当下股价翻2倍）可能会有点难度外，其余认股权证的生效条件，不得不让人怀疑，OpenAI完全可以通过转股套现来支付采购AMD芯片的费用，都不用额外占用太多现金流。 当然，随着AMD市值的走高，OpenAI现金流的支付压力也越小。如果OpenAI一直等到1万亿，才将所有的认股权证转股卖出，那将获得至少1000亿的资金，而OpenAI的采购成本估计也就是1200亿左右（正常的高端GPU功耗下，6GW对应约500万颗GPU，按每颗2～3万美金的综合均价计算）。这样的操作无疑是通过利益捆绑携手做高AMD市值为最终目的。 **（3）牵手博通：GPU也有替身** “背刺”英伟达还不够，OpenAI干脆找备胎找到底，找到博通去开发定制10GW算力的ASIC，不过主要用于专有场景的推理。该合作计划从明年下半年启动部署，预计到2029年底完成算力建设。 这款ASIC设计由OpenAI负责，制造、部署和网络集成则由博通提供，和AMD一样，这些ASIC也将会部署在Stargate数据中心以及合作伙伴（如微软、甲骨文）的数据中心中来运行使用。 2. 万亿算力投资“一哄而上”，实则OpenAI的平衡术？ 结合<1-3>，上述星际之门以及与产业链上游的直接合作，加上最近9月刚签的CoreWeave合同，OpenAI给未来的自己累计规划了最高31GW算力新增供给（其中26亿算GW是近一个月新增的），对应产业链总部署价值高达1.5万亿。 其中英伟达的10GW纯新增，属于OpenAI与英伟达直签的租赁合同。预计总租赁成本要比采购芯片便宜10%~15%，关键从采购改租赁，能帮OpenAI减轻资金一次性投入下的现金流负担。 但海豚君认为，甲骨文的4.5GW与AMD、博通的算力规划，只能说不排除有重叠。目前4.5GW的新算力需求，甲骨文在5月采购过400亿美元的英伟达GPU，这只够对应1GW的容量，并且新闻报道了是专门用于得州Abilene数据中心的建设。 也就是说，4.5GW的新增算力，要么从甲骨文目前的存量数据中心挪移算力，要么就是要新建数据中心。这里面涉及到新GPU的采购。要么是甲骨文继续从英伟达采购，要么从别处采购。 但OpenAI与AMD、博通的合作也说明了，这部分芯片需要安排部署在in-house的数据中心（也就是指Stargate），或者合作伙伴的数据中心上。这个合作伙伴，应该主要就是指微软、甲骨文。 已知微软主要负责OpenAI的训练算力，甲骨文负责推理算力。因此如果有安排，那么博通的部分应该就是部署在Stargate（基本都是甲骨文负责运营）或者甲骨文数据中心上。AMD则可能或许会有几率安排在微软上，这是因为，OpenAI对AMD的合作要求是2026年底才会推出的MI450，旨在用于训练上。 这30GW的算力负载，占到了美国2024全年数据中心总装机量的60%。70%利用率运行下，换算成Tokens（按照H100 GPU，7B-70B不同大小的推理模型来算）大约可以达到10～378万万亿/年，是2025年OpenAI 14000万亿Tokens/年的7～200倍。 虽然OpenAI的梦想非常宏大，以后万物皆AI，算力还会飞速增加，但关键是这又大又圆的算力需求，又为什么急于在一个月之内锁定协议和合作对象呢？ 海豚君认为，整个过程完全可以归于利益博弈。但看似是OpenAI焦虑算力供给，实则可能是一种平衡术，旨在提前锁死关键伙伴，壮大整个生态。 **（1）甲骨文上牌桌：是福，还是祸？** 作为与OpenAI捆绑最深的一方，甲骨文也是赌上身家了。好的是，未来的收入增长几乎由OpenAI决定，OpenAI也会尽可能把最多的算力需求订单给到它，比如2027年开始的5年3000亿订单。这才有了Q2业绩会上“炸裂”的长期增长指引，以及AI World大会上的“任性”上调： 但同时作为Stargate LLC的股东，为了推动项目要能正常开展，当前期投入的资金不够时（若OpenAI未及时融来足够的资金），只能咬碎牙先垫资，尤其是它负责主导建设的两个数据中心园区，不排除需要先自掏腰包去买下GPU芯片以及其他辅助硬件。 然而，甲骨文也并不富裕，资产负债率80%，作为没有现金流主业的数据中心开发运营商，重资产运营下，现金储蓄也并不多。 除此之外，OpenAI还与英伟达签了直租合同，这就让甲骨文有点尴尬了。而从趋势上看，Stargate未来的闲置算力不排除会对外出租（30GW只是峰值需求，并非常态）。 虽然甲骨文握手Stargate的少部分股权，但不妨碍业务本身存在竞争，到时候甲骨文很可能会成为Stargate的包工头/运维/分销商，彻底锁死OpenAI，要么就是退出Stargate联盟，但无论哪一种，都不是特别好的归宿。 **（2）英伟达：与CSP巨头争夺产业话语权** 此次英伟达与OpenAI的10GW直接合作，实际上是在谷歌、甲骨文傍上OpenAI后，英伟达一种进击式防守，尤其谷歌还用的是TPU。在当下的算力产业链中，由于还是供小于求的卖方市场，因此中上游正在美美享受行业发展的红利。但二者之间也存在明争暗斗，尤其是各自的巨头，谁也不服谁。 中游CSP想削掉上游GPU的高昂采购成本，上游GPU眼红中游40%的利润蛋糕。但若下游需求巨头选择捆绑其中一方，这一方的产业链溢价权自然上升。尤其是当面对拥有8亿周活用户的OpenAI，无论是发展前景还是背后资源实力上，都会吸引芯片巨头锁死利益关系，“一起为梦想窒息！”。 或者说芯片厂商只能相信，OpenAI允诺的天量订单，给三家芯片厂商带来的营收增量都是史无前例的，如果不去相信，否则如何去讲自己的增长故事？所谓船大、饼大，这个抱团意愿也就可想而知了。 再加上这笔交易本身，对英伟达也是不亏的。不仅仅是1000亿的投资是分批投入，就算把这1000亿算到成本中，对于英伟达来说也是净赚的，只是毛利低了点： 据报道租赁成本相比采购成本便宜10%~15%，即350\\*85%=300亿/GW，再扣去“返现”的100亿/GW，实际净付200亿/GW，英伟达正常成本350\\*25%=87.5亿，调整后毛利为112.5亿，调整后毛利率32%，比之前少赚150亿/GW。 但是英伟达用这部分让利出去的毛利率锁定了最高10%的OpenAI股权，一定程度上相当于用实物作为风险投资的资本来换取股权。 但如果没有租赁模式和这1000亿的投资，也不一定换得来10GW的订单，订单更多被流入到博通、AMD等竞对口中。最终这场投资变成了芯片商们FOMO的博弈平衡。 **（3）AMD：是备胎又怎样？毕竟上船了** AMD毫无疑问是OpenAI的备胎，是OpenAI面对英伟达留有的后手，但也注定了只有在一定条件下才会转正（MI450成功推出、额外算力部署）。 从订单总金额与目前的收入规模来看，弹性很高。一边是五年1000多亿的收入订单，一边是万亿市值梦，看上去OpenAI与AMD合作是win-win。 但AMD也是分批部署，一次1GW，但也需要上百亿的前置投入。这笔钱在完成部署之前，OpenAI可能并不能预付100%，这就需要AMD垫资了。不过往好处想，正是因为是备胎，因此算力需求不太会立即分配到它，就算垫资，规模也相对可控。 **（4）博通：大势所趋的渔翁** 虽然市场认为博通的不确定性最高，毕竟合作细节披露得最少。但海豚君认为，产业链中CSP与GPU芯片巨头之间利益博弈，比如英伟达直接绕过CSP与下游客户OpenAI签直供合同，等于是要把CSP大厂们排除出利益链条外，这必然会加速CSP自研ASIC芯片的进程。 而博通通过多年与谷歌TPU的合作，这套程序已经相当熟练，毫无疑问是受益。虽然从目前来看，OpenAI暂时还不急于依赖ASIC的算力，但自研芯片正是渗透到CSP的后一步。 二、万亿投资，钱从何来？ OpenAI上述已囤的31GW算力峰值，撑起的是1.5万亿的产业链价值。但这只是多年之后预计的“最高”投入成本，而非短期投入抑或是最终累计投入，导致市场非常担心OpenAI（2025年收入可能是150亿美金）的支付压力。 实际上，OpenAI购买星际之门的云服务，其实就相当于星际之门的下游客户，按照实际使用来支付费用。如下图，真正承担投入资金职责的是Staragte这个合资公司，虽然OpenAI有40%的股权，也要承担一定责任，但总归可以找人分担了。 但市场也担心，除了OpenAI之外，共同责任人软银、甲骨文、WAX是否有承付能力，毕竟这几家都没啥巨额的稳定现金流。 海豚君认为，担心并非多余。但实际的承付压力，还得算一算。这里面到底有多少缺口，是需要OpenAI的商业化或再融资来补上的，甚至是甲骨文等需要长期垫资的。 OpenAI的整体规划周期基本在5年，虽然都是分批付款：英伟达是5年租赁合同（跳过CSP直租），AMD和博通都是按实际部署节奏来付款，AMD还附带送股套现，甲骨文也是5年租期，CoreWeave同样是多年租期。 但似乎叠加起来，对短期的现金支付要求压力依旧不小。 （1）数据中心投入：尤其是按目前计划，星际之门里三个数据中心（得州Abilene、俄亥俄州Lordstown、得州Milam）都将在未来两年内完成部署落地。这也意味着付款周期马上来临，这是整个星际之门背后项目方（OpenAI、Oracle、软银、MGX）所面临的共同压力。 （2）除此之外，英伟达的首批1GW、AMD的1GW也将在1年内完成部署，分别对应350\\*85%（租金优惠）=298亿、500亿美元部署成本（其中芯片成本175亿美元）。 （3）甲骨文的3000亿4.5GW算力订单，将在2027年开始支付600亿美元。 上述1~3合计，OpenAI所代表的Stargate，将于2027年需要支付1600亿美元。而真正落到OpenAI头上的，则是按需租赁算力的费用，以及前置投入中分派到自己头上的成本，合计600多亿。 但英伟达的100亿投资、AMD的首批权证转股（2660股）套现后也有60多亿（按当前股价来算，实际降息周期下，估值抬高套现额也会一同提升），减去后最终净支出为500亿美元。注意这里仅计算了与新合作伙伴的投入，与微软原本的云服务采购也在继续。（因为实际情况不确定，具体细节不清晰，下图估算比较粗略，仅供大致参考） 目前Stargate首期资金1000亿，其中OpenAI、Softbank作为主导人，首期1000亿资金双方各投资190亿美元，甲骨文和MGX联合投资70亿，剩下的550亿计划通过发债融资。 这里面的关键支撑点，就是OpenAI未来是否有这样的商业化能力，去兑现这些价值万亿的天量订单？ 面对承付能力质疑，OpenAI的商业化展望是这样的：2025年预计营收130亿（隐含下半年收入87亿，环比100%增长），2029年目标1250亿，2030年目标1740亿~2000亿，未来5年CAGR超过90%。 在上述2027年的支出测算下，预期540亿的收入刚好覆盖新增算力成本，但还有研发人员、营销投入以及公司基本运营支出需要覆盖，这部分大约占到收入的三分之一，也就是150亿~200亿之间。 这个缺口只能寄希望于再融资，但问题是，OpenAI的5年2000亿的宏大收入愿景能实现吗？ 5年10倍收入增长，而且是起点就已经在百亿级别，绝对是难度拉满。换种说法，5年营收从0干到1000亿。放眼望去过去几十年，也只有在AI GPU领域做到90%以上绝对通吃且身处产业链中价值最高的芯片设计环节的英伟达，才有过这样的“增长斜率”。 不过，正如当初的ChatGPT横空出世，从当初的质疑到最后的信服，成为AI chatbot的专属代名词，那么OpenAI能否复刻ChatGPT的神话？下一篇，海豚君将深入探讨OpenAI的收入端——商业化前景，以及对现有巨头的潜在影响大小。 本文来自微信公众号：海豚投研，作者：海豚君 AI创投日报频道: 前沿科技 本内容由作者授权发布，观点仅代表作者本人，不代表虎嗅立场。   正在改变与想要改变世界的人，都在 虎嗅APP",
            "score": 0.79769903,
            "timestamp": "2025-11-09T14:52:55.323554"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://www.mittrchina.com/news/detail/15347",
            "title": "AMD后，再联手Broadcom自研10GW芯片 - 麻省理工科技评论",
            "content": "麻省理工科技评论-OpenAI一个月签下26GW，继NVIDIA、AMD后，再联手Broadcom自研10GW芯片 Image 1 TR35 China TR50 EmTech China 2021 EmTech China 2020 EmTech China 2019 EmTech China 2018 EmTech China 2017 Image 2 OpenAI一个月签下26GW，继NVIDIA、AMD后，再联手Broadcom自研10GW芯片 Image 3 Image 4图丨相关公告（来源：OpenAI） 根据双方公布的消息，这批定制芯片将主要面向推理而非训练。训练大模型需要海量并行计算，是 NVIDIA GPU 的强项；而推理——也就是用户每次提问时模型的实时响应——更看重延迟和能效。OpenAI 显然是想在服务端降低成本，毕竟，其平台超过 8 亿的周活跃用户每天产生的查询量是一个惊人的数字，如果定制芯片能让每一次推理都更快、更省电，那么这笔前期投入从长远来看是足够划算的。 Image 5图丨双方就本次合作消息发布的播客节目（来源：Youtube） OpenAI 自身的财务状况也不算轻松。截至今年 7 月，其年度经常性收入约为 120 亿美元，这个数字虽然可观，但与其庞大的支出相比可能只是杯水车薪。公司预计还需要四年才能实现正向现金流，在此期间必须持续投入巨资建设数据中心、采购芯片并支付电费。唯一的好消息或许是，通过让 NVIDIA、AMD 等巨头以投资或股权形式深度参与，OpenAI 实际上将这些关键供应商绑在了自己的战车上——它们投入得越多，就越希望 OpenAI 能够成功，从而保障自身投资的回报。 1.https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration/ 2025年10月14日 Image 6 DeepTech深科技 发现新兴科技。 Image 71给大模型版权上“防盗锁”！浙大新方法既能装指纹又能防篡改Image 82arXiv被AI水文淹没，新规要求AI生成论文需过同行评审Image 93AI百科全书新思路：科学家用第一性原理重构知识体系Image 104中国“人造太阳”核心材料不再受制于人，金属所打造吨级高纯净C276合金，助力2030聚变能发电Image 115晶圆级超导锗问世，可直接对接现有产线 AI 谷歌推出开源全栈的NPU新架构，旨在实现大模型在终端的低功耗运行 ================================ 谷歌将 Coral NPU 视为边缘 AI 的新开放标准，而这一愿景已开始落地。 DeepTech深科技 2025年10月20日 Image 12AI 大模型 “准确率悬崖” 被证实，科学家发现模型单次处理容量上限，多智能体成破局关键 ========================================= 这一成果为理解当前大模型的瓶颈分析提供了新的容量诊断视角。 DeepTech深科技 2025年10月17日 Image 13AI AI社交智能觉醒，新研究让模型理解人类“关系网” ======================== 近日，张议文和所在团队利用传统博弈模型开发了测试大语言模型能力的环境，然后针对模型能力问题进行算法开发，最终验证算法在提升模型策略推理能力的有效性。 DeepTech深科技 5天前 Image 14AI arXiv被AI水文淹没，新规要求AI生成论文需过同行评审 ============================= arXiv 更新了关于综述论文和立场论文的审核规则，要求这两类论文必须被期刊或会议接收并完成同行评审之后才能提交到 arXiv 的 CS 类别。 DeepTech深科技 6天前 Image 15AI AI六巨头首次同台！纵论四十年AI风云、泡沫之辩与AGI时间表 =============================== 这是一个人类 AI 群星闪耀时的时刻——黄仁勋、李飞飞、杰弗里·辛顿（Geoffrey Hinton）、约书亚·本吉奥（Yoshua Bengio）、杨立昆（Yann LeCun）、比尔·戴利（Bill Dally），罕见同台参与同一个圆桌讨论 AI。 DeepTech深科技 1天前 Image 16 Image 17 Image 18京公网安备 11010502040579号",
            "score": 0.74273956,
            "timestamp": "2025-11-09T14:52:55.323571"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://finance.sina.cn/tech/2025-10-14/detail-inftwafn2872453.d.html",
            "title": "OpenAI一个月签下26GW，继NVIDIA、AMD后，再联手Broadcom自 ...",
            "content": "根据双方公布的消息，这批定制芯片将主要面向推理而非训练。训练大模型需要海量并行计算，是 NVIDIA GPU 的强项；而推理——也就是用户每次提问时模型的实时",
            "score": 0.7355091,
            "timestamp": "2025-11-09T14:52:55.323581"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://www.qbitai.com/2025/11/348079.html",
            "title": "奥特曼纳德拉同台回应一切：合作细节、OpenAI未来路线曝光 - 量子位",
            "content": "*henry* 2025-11-02 18:23:49  来源：量子位 > henry 发自 凹非寺 > 量子位 | 公众号 QbitAI * OpenAI 2025年营收130亿刀，怎么敢承诺花1.4万亿美元投资算力？ **布拉德·格斯特纳**：微软从2019年开始投资，到目前为止已经向OpenAI投入大约130到140亿美元，换取了约27%的股权（完全摊薄后），最初大约是三分之一。去年随着新一轮融资，你们的持股被摊薄了一些。这个比例对吗？ **布拉德·格斯特纳**：在这次重组中，你们提到的架构是：上层是非营利组织，下层是公益性公司（PBC）。 **山姆·奥特曼**：首先，我认为为世界创造巨大价值的最好方式就是我们已经在做的事——打造强大的AI工具并让所有人都能使用。我认为公司机制是优秀的。许多企业正在把先进AI带入更多人手中，创造了令人惊叹的成果。 **山姆·奥特曼**：不是这样的。首先，我们和微软会继续在很多方面合作，共同创造价值。我们希望帮助微软创造价值，也希望微软帮助我们创造价值——这样的合作已经在很多层面展开。我们保留了萨提亚曾经提出的一个很好的概念——“无状态API（stateless APIs）”，这些API运行在Azure上，这部分不是完全排他的（协议有效期至2030年）。而其他产品和模型，我们也会在不同的平台上发布。这当然也符合微软的利益。所以我们的产品会出现在很多地方——有些会在Azure上，用户可以在那里使用，这对大家都是好事。 **布拉德·格斯特纳**：然后是收益分成部分。OpenAI仍然需要就全部收入向微软支付分成，这个分成协议同样持续到2032年，或者直到AGI被验证。假设——只是为了说明问题——这个分成比例是15%，那么如果OpenAI收入是200亿美元，就会向微软支付30亿美元，这部分算作Azure的收入。萨提亚，这个理解对吗？ **萨提亚·纳德拉**：是的，我们确实有收益分成协议。正如你所说，这个协议会一直持续到AGI出现或到期为止。老实说，我也不确定这笔分成最终是计入Azure还是其他部门——这是个好问题，也许应该去问我们CFO艾米。 **布拉德·格斯特纳**：既然排他协议和收益分成都会在AGI被验证后提前结束，那这意味着AGI的认定是一件非常重大的事。据我了解，如果OpenAI声称已经实现AGI，那么会由一个专家评审委员会来裁定，你们双方会共同选出“陪审团”，在相对短时间内决定AGI是否确实被实现。萨提亚，你昨天在财报电话会上说，目前“没有任何人接近AGI”，而且短期内也不会实现。你还提到过“智能的尖峰与不平衡性”的概念。但山姆，你似乎比他更乐观一些。那么问题是：你们是否担心未来两三年内真的需要召集这个“陪审团”来判断我们是否已经达到了AGI？ **山姆·奥特曼**：我知道你想在我们之间制造点戏剧冲突。但我认为，为AGI设立一个正式判定流程是非常必要的。未来技术的发展肯定会出现一些出人意料的转折，我们会继续保持良好的合作关系，一起去理解和判断它的发展方向。 **萨提亚·纳德拉**：完全同意。这也是我们之所以要建立这个流程的原因之一。我一直坚信，智能的能力会不断提升，而我们真正的目标是——如何把这种智能交到人和组织手中，让他们获得最大化的益处。这也是当初吸引我与OpenAI合作的原因：他们的使命就是让智能造福全人类。我们也会继续沿着这条路走下去。 **山姆·奥特曼**：布拉德，就算我们明天真的实现了“超级智能（Super intelligence）”，我们依然希望有微软的帮助，把产品交到人们手中。 **山姆·奥特曼**：首先，我们的实际**收入远不止130亿美元**。其次，布拉德，如果你真的想卖掉手上的OpenAI股份，我可以帮你找买家。现在有很多人都非常想买OpenAI的股票。我不认为那些在网络上对我们“算力支出”大惊小怪、担忧不已的人，其实要是能买到OpenAI的股份，肯定会抢着入场。所以我觉得，如果你或者其他股东真想卖股份，我们完全可以很快地把它们卖给那些在X（推特）上喊得最凶的人。 **萨提亚·纳德拉**：到目前为止，无论是作为合作伙伴还是投资者，我还没见过OpenAI制定的商业计划没有被他们自己超额完成的。 **布拉德·格斯特纳**：我几周前在CNBC上听到Greg Brockman说，如果我们能把算力提升10倍，收入也许不会增长10倍，但肯定会显著增长。 **布拉德·格斯特纳**：昨晚你也提到你们同样受算力限制，如果算力更多，增长会更高。那Sam，请帮我们解释一下：你现在觉得算力受限的程度有多严重？你认为在未来两三年的基础设施建设完成后，会不会有一天不再受算力限制？ **山姆·奥特曼**：我们经常讨论这个问题——算力“够不够”。我认为最好的理解方式，是把它看作“能源”。你可以讨论在某个价格水平下的能源需求，但不能脱离价格谈能源需求。如果“每单位智能的算力成本”明天下降100倍，那么使用量会远不止增长100倍。现在有很多人想用算力做一些事，但在当前的成本下是经济上不划算的。 **萨提亚·纳德拉**：如果智能的价值与算力的“对数”相关，那么我们就要不断提升效率。这意味着要最大化“每美元、每瓦特所能生成的token数”以及由此带来的社会经济价值，同时降低成本。从经济学角度看，这正是**杰文斯悖论（JevonsParadox）**所描述的现象：你不断降低成本、商品化智能本身，让它成为推动全球GDP增长的真正动力。 **山姆·奥特曼**：不过我认为，目前情况更接近“智能是算力的对数函数”，而不是反过来。但也许未来我们能找到更好的ScalingLaw，这点还在探索。 **布拉德·格斯特纳**：我们昨天听到微软和谷歌都表示，他们的云业务增长本可以更快，只是受制于GPU供应。 **萨提亚·纳德拉**：我认为，在这个特定领域中，供需周期几乎是无法预测的。真正的长期趋势是持续增长。坦率地讲，我们现在面临的最大问题并不是“算力过剩”，而是**电力和基础设施建设速度的问题**。如果你没法足够快地在靠近电源的地方完成数据中心建设，那么即使你手里有一堆芯片，也可能插不上电。 **山姆·奥特曼**：**总有一天，算力一定会过剩——至于是两三年后，还是五六年后，我说不准，但这肯定会发生，而且可能会多次发生。**这背后有很深的人类心理因素和“泡沫循环”。供应链极其复杂，各种奇怪的事都会发生，技术格局也会不断剧烈变化。 **布拉德·格斯特纳**：说得太好了——你必须同时接受这两种真相。2000年、2001年我们也经历过同样的泡沫，但互联网最终变得远比当时任何人预想的更大，并为社会带来了更深远的价值。 **萨提亚·纳德拉**：是的，我认为Sam刚才提到的一点其实外界谈得还不够多：比如，OpenAI在推理层面（inferencestack）针对GPU所做的优化。我们常常谈论摩尔定律带来的硬件性能提升，但实际上，软件层面的效率改进才是呈现出更强指数级增长的部分。 **山姆·奥特曼**：未来总有一天，我们会做出一种令人惊叹的消费级设备，它能在本地、低功耗地运行一个接近GPT-5或GPT-6级别的模型。 **布拉德·格斯特纳**：那真会是个奇迹。而且我想，这也正是让那些构建大型集中式算力中心的人感到不安的地方。 你其实谈过很多次：**算力要既向边缘端（edge）分布，也要在全球范围内分布式推理**。 **萨提亚·纳德拉**：是的，我自己的思考更多是关于如何构建一支可替代的算力舰队。在云计算基础设施业务里，最关键的两点其实很简单：第一，要有一个高效的“token工厂”；第二，要实现高利用率。要做到高利用率，你就必须能调度多种不同的AI工作负载——包括预训练、中间训练、后训练和强化学习等。所以，让算力资源具备可替代性，是所有云服务提供商的核心目标。 **布拉德·格斯特纳**：昨天路透社报道说，**OpenAI可能计划在2026年底或2027年上市**？ **山姆·奥特曼**：不，我们没有任何具体的计划或时间表。我知道外界喜欢这么写，但实际上我们**没有确定日期，也没有做出上市决定**。我只是认为，从长远来看，那可能是公司自然会走到的一步，仅此而已。 **布拉德·格斯特纳**：不过，在我看来，如果你们在2028或2029年时的营收超过1000亿美元，那就已经具备了上市的条件。 **山姆·奥特曼**：那要是2027年呢？ **布拉德·格斯特纳**：哈哈，2027年更好。如果你们那时上市，按照传闻的**1万亿美元估值**来看，给听众简单解释一下。 **山姆·奥特曼**：我更希望公司以强劲的营收增长为基础去做这件事，但没错，这肯定会是个值得考虑的方向。 **布拉德·格斯特纳**：我一直觉得这是个非常重要的公司。像我自己的孩子，他们有自己的小投资账户，也每天用ChatGPT。我希望普通投资者也能有机会买到这样一家影响力巨大的公司。 **山姆·奥特曼**老实说，这可能是上市对我个人来说最有吸引力的理由。 **布拉德·格斯特纳**：最近，你的团队一直在谈未来的新动向：**更大规模算力、ChatGPT-6及更远的版本、机器人、实体设备、科学研究。** **山姆·奥特曼**：今年我觉得最有意思的是Codex（AI编程模型）的发展。明年，它可能会从处理“几小时任务”跃升到能处理“几天级别任务”，让人类能以前所未有的速度和全新方式创造软件。我对此非常兴奋。而且我相信这种趋势也会扩展到其他行业。我对代码更熟悉，所以更容易看到那里的变革，但这将真正重塑人类创造力的边界。 **萨提亚·纳德拉**：是的，以Codex为例，关键在于模型能力与交互界面的结合。ChatGPT之所以“魔法般”爆发，是因为合适的UI遇上了足够强的智能模型。而现在的“代码智能体”（CodingAgent）正在形成一种新的范式：AI可以自主执行长时间任务，然后在关键节点上再由人类“微调”。我们内部称之为宏观委托（macrodelegation）与微观操控（microsteering）。当这种新型智能与全新UI结合，就会出现一种全新的“人机交互形态”，我认为它的影响力甚至可能超过ChatGPT。 **山姆·奥特曼**：这也是我很兴奋我们正在开发新型计算设备形态的原因。因为现在的电脑结构根本不适合这种工作流。ChatGPT这样的UI其实并不完美。想象一下：你拥有一个设备，它始终陪伴在你身边，它可以独立完成任务，必要时获得你的“微指导”，同时它能深度理解你的语境与生活流。这会非常酷。 **布拉德·格斯特纳**：而你们都还没提到消费者端的用例。我常常想，我们现在每天都要在设备里翻找上百个App、填各种表单——这些交互方式20年来几乎没变。但如果AI能让我们真正拥有一个几乎免费的个人助理，为全球数十亿人改善生活。无论是帮孩子订尿布、预订酒店、还是修改日程，那将会是最平凡但也最具革命性的改变。当我们从“回答”走向“记忆”与“行动”，再通过耳机或其他设备自然地与AI交互，而不再盯着一块玻璃屏幕——那真是令人震撼的未来。 **萨提亚·纳德拉**：我觉得这正是Sam刚刚在暗示的东西。 **布拉德·格斯特纳**：2019年你把“投资OpenAI十亿美元”的想法带到董事会上，当时是不是一拍即合？你是否需要花费一些精力来说服大家？ **萨提亚·纳德拉**：是的，现在回头看，那段历程很有意思。其实我们和OpenAI的关系更早就开始了——大概2016年，Azure就是OpenAI最早的赞助者之一。 他后来也公开说过，那是他自从查尔斯·西蒙尼（Charles Simonyi）在XeroxPARC给他看演示以来，见过的**最震撼的Demo**。 **布拉德·格斯特纳**：我想很多人不知道，你的CTOKevin Scott——一位前谷歌工程师——其实常驻硅谷。 **萨提亚·纳德拉**：完全正确。事实上，我要说，Kevin的信念起到了决定性作用。他一开始也是怀疑派——这正是我最关注的那种人：“原本不信，但后来改变了看法并变得兴奋的人。”这种转变本身就是一个信号。因为那让我想追问：“为什么？是什么改变了你的想法？”Kevin最初持保留态度，但后来成了坚定支持者。我们很多人其实都被教育成相信：“一定有某个算法能解开一切”，而不是“通过扩展和算力堆叠就能取得突破”。但事实证明，Kevin的坚定信念——“这是值得去做的”——是推动这一切的关键力量之一。 **布拉德·格斯特纳**：如今，这笔当初10亿美元的投资价值大约1300亿美元，未来甚至可能像Sam说的那样，达到1万亿美元。但这仍然低估了微软与OpenAI合作的真正价值。除了股权收益外，微软每年能从OpenAI的分成中获得数十亿美元利润，还能通过Azure的2500亿美元算力承诺获得收益。 **萨提亚·纳德拉**：当然。撇开股权部分不谈，最关键的战略协同在于：OpenAI的无状态API独家运行在Azure上。这对OpenAI、对我们、对客户来说，都是共赢的。企业客户在构建AI应用时，希望API是无状态的（stateless），然后与底层的计算、存储、数据库结合，形成一个完整的工作负载。这正是Azure能与OpenAI结合的地方。 **布拉德·格斯特纳**：微软最近在财报中合并了OpenAI的亏损，据说上季度就合并了约40亿美元的亏损。你觉得投资者是否误解了这件事？有可能他们在估值中反而“扣分”了，因为这些亏损会影响每股收益倍数。但事实上，OpenAI合作带来的长期收益和潜在市值远超这些短期数字。你怎么看？ **萨提亚·纳德拉**：这是个好问题。我们的CFO Amy（艾米·胡德）会采取“完全透明”的方式来处理。老实说，我不是会计专家，所以我认为最好的办法就是公开所有信息。这也是我们现在区分GAAP与Non-GAAP（一般公认会计准则与非公认口径）财报数据的原因。至少这样，投资者可以清楚地看到实际每股收益（EPS），从而理解全貌。 **布拉德·格斯特纳**：大约一年前，有很多新闻标题都在说微软正在削减AI基础设施投资。你觉得这是公平的说法吗？还是有点误解？反正这些报道当时确实存在。或许那时候你们的确更保守、更谨慎一些。不过昨晚财报电话会上，Amy提到，微软在算力和基础设施上其实已经短缺了好几个季度。她原本认为你们会赶上，但结果没赶上——因为需求持续增长。所以我的问题是：现在回头看，当初是不是太保守了？你现在知道这些情况后，会怎么规划接下来的路线图？ **萨提亚·纳德拉**：这个问题问得很好。事实上，我们当时意识到了一点——而且我很高兴我们意识到了——那就是，必须建设一个在整个AI生命周期中都能灵活调度（fungible）的算力集群。这种灵活性不仅要体现在不同地域之间，也要体现在不同芯片代际之间。 **萨提亚·纳德拉**：这正是我们在内部要平衡的地方——要在长期股东利益、客户服务质量以及风险分散（避免算力集中在OpenAI一家）之间找到平衡。 **布拉德·格斯特纳**：你提到过4000亿美元的剩余履约义务（RPO），这个数字令人难以置信。昨晚你提到，这是你们目前的已预订业务量。随着销售持续进来，这个数字明天肯定还会增加。你还提到，为了满足这些积压订单，你们必须大规模扩充产能。我想问的是，这些积压订单多元化程度如何？你们有多大信心，这4000亿美元能在未来几年真正转化为收入？ **萨提亚·纳德拉**：是的，这4000亿美元的剩余履约义务，平均来看持续时间其实很短——大约是两年左右。这也是我们投资大规模产能的原因之一，因为我们非常确定需要清理这些积压订单。 **布拉德·格斯特纳**：在这场算力建设竞赛中，有很多新进入者，比如Oracle、CoreWeave、Crusoe等。通常情况下，这会压低利润率，但你们却成功地在保持Azure健康运营利润的同时，快速扩展了算力。 **萨提亚·纳德拉**：对于我们来说，好消息是，即使每天都在和亚马逊、谷歌等大玩家竞争，我们仍然保持了竞争力。 **布拉德·格斯特纳**：我很喜欢你那句话：“在大规模下，没有什么是商品化的。”你知道，甚至在这个播客里，我和我的合伙人BillGurley也花了不少篇幅讨论循环收入，包括Microsoft的Stasher积分、OpenAI的收入确认等。 **萨提亚·纳德拉**：首先，我们对OpenAI投资的135亿美元，是全部训练投资，没有计入收入。这也是我们拥有股权比例（27%或135亿美元）的原因。 **布拉德·格斯特纳**：你刚才提到一半以上业务是软件应用。我想谈谈软件和智能代理。去年你曾提到，大部分应用软件，其实只是“薄薄一层”覆盖在杂乱数据库之上，这引起了不小的轰动。 **萨提亚·纳德拉**：是的，我的观点是：在智能代理时代，传统业务应用可能会逐渐被取代。因为它们本质上就是带有业务逻辑的“群体数据库”，而业务逻辑会被代理取代。 **布拉德·格斯特纳**：如今，上市软件公司前瞻性市销率约为5.2倍，低于其历史均值7倍，即使市场处于历史高位。很多人担心SaaS订阅和利润率可能因AI受到冲击。 **萨提亚·纳德拉**：是的，正如我上次提到的，SaaS应用架构正在改变，因为智能代理层正在替代旧的业务逻辑层。过去，我们的SaaS应用是数据层、逻辑层和UI紧密耦合的，而AI不遵守这种耦合，它要求解耦，同时上下文工程非常重要。 **布拉德·格斯特纳**以前，云主要运行预编译软件，不需要太多GPU，价值大多集中在数据库和应用层。 **萨提亚·纳德拉**：有两件事决定AI的价值： **布拉德·格斯特纳**:微软有一个不为人知的搜索业务，非常赚钱，因为搜索量巨大，而每次搜索成本仅为几分之一美分。相比之下，聊天交互成本更高。你认为未来聊天是否能达到搜索的盈利水平？ **萨提亚·纳德拉**:搜索的盈利模式很神奇：索引是固定成本，可高效摊销。而聊天每次交互需要更多GPU周期，成本结构不同。因此早期聊天多采用freemium或订阅模式。我们还在探索广告或代理商业模式。 **布拉德·格斯特纳**:这是一个数万亿美元市场，当搜索商业模式转向类似个人助手，潜在价值可能远超传统搜索。但这意味着不再只是摊销固定索引成本。 **萨提亚·纳德拉**:消费者市场有限时间可支配，如果你做一件事，就没时间做另一件事。消费端的代理化盈利模式仍不明朗。而企业端则不同：不是赢者通吃，更适合代理交互。换句话说，代理取代了传统座位计费，企业端盈利更清晰，消费端则模糊。 **布拉德·格斯特纳**：最近看到Amazon大规模裁员，七巨头近三年增长有限。 **萨提亚·纳德拉**：我坚信，生产力曲线会因AI工具而提升。任务级别的工作会因AI更高效完成。微软内部也在确保每位员工配备M365和Github Copilot，从而提高效率。 **布拉德·格斯特纳**：那么微软会从中受益吗？我们假设按当前增长率，几年后——五年后——你的收入大约是今天的两倍。Satya，如果收入按这个速度增长，你会增加多少员工？ **萨提亚·纳德拉**：我每天从微软员工身上看到的例子是最棒的部分。比如，我们网络运营负责人，她负责我们刚在Fairwater建的2吉瓦数据中心的光纤网络。AI的部署让光纤敷设、运维等任务量非常巨大。实际上，我们需要跟全球约400个光纤运营商打交道，每次发生问题，都要处理复杂的DevOps流程。 **布拉德·格斯特纳**：我觉得我们正处在生产力大幅提升的边缘。和你或Michael Dell交流时，我感觉大多数公司甚至还没有开始重构工作流程，从智能代理中获取最大杠杆。 **萨提亚·纳德拉**：完全正确。即便在软件开发领域也是如此。 OpenAI [henry](#) ChatGPT OpenAI OpenAI OpenAI奥特曼 奥特曼 GPT-4o GPT-5 OpenAI Gemini IMO OpenAI 谷歌 OpenAI RLHF OpenAI 具身智能 量子位 QbitAI 版权所有©北京极客伙伴科技有限公司 京ICP备17005886号-1",
            "score": 0.6638657,
            "timestamp": "2025-11-09T14:52:55.323590"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://m.36kr.com/p/3499909351775107",
            "title": "GPU警钟敲响，AI过热了？ - 36氪",
            "content": "周二， 知名媒体The Information 在一篇报道对该公司购买数十亿 Nvidia 芯片并作为云提供商出租给 OpenAI 等客户的计划提出了质疑，随后该公司股价下跌 3%。报道称，甲骨文最近转型为最重要的云计算和人工智能公司之一，但可能会面临盈利挑战，因为英伟达芯片价格昂贵，而且其人工智能芯片租赁定价激进。 甲骨文今年9月表示，其积压的云合同（称为剩余履约义务）在一年内增长了359%。该公司预测，2030年云基础设施收入将达到1440亿美元，高于2025年的100多亿美元。然而，这些预测收入的大部分来自 Oracle在星际之门项目中所扮演的角色，该项目中，这家企业供应商正与 OpenAI 合作，开设五个装有 Nvidia 人工智能芯片的大型数据中心。 今年 1 月，OpenAI 与软银、甲骨文等公司启动了一项名为“星际之门”的计划，承诺为 OpenAI 在美国基础设施建设上投资高达 5000 亿美元。目前尚不清楚英伟达和 AMD 的交易将如何融入“星际之门”计划。 OpenAI 已从其供应商处获得了巨额财务激励，以换取其芯片采购的回报。 Nvidia 计划在未来十年向 OpenAI 投资 1000 亿美元，OpenAI 可以用这笔资金购买 Nvidia 的芯片，用于其 AI 数据中心。AMD 将向 OpenAI 提供认股权证，使其能够以每股 1 美分的价格收购 OpenAI 最多 10% 的股份，具体取决于他们的项目是否达到特定目标，其中包括一些与 AMD 股价挂钩的目标。 OpenAI 在基础设施、芯片和人才方面投入了大量资金，远没有达到实现这些宏伟计划所需的资金。这些交易还涉及这家全球最有价值的初创公司与其合作伙伴之间的循环安排，以及大多数情况下尚未达成一致的复杂融资条款。 据报道， AMD 已与 OpenAI 达成合作伙伴关系，ChatGPT制造商将在多代芯片中部署 6 GW 的 AMD 图形处理单元 (GPU)。 这笔交易对 OpenAI 来说是一个重大决定，OpenAI 几乎完全依赖 Nvidia芯片来训练 ChatGPT 及其其他 AI 产品背后的模型。 此次合作的财务利益相当可观——正如AMD执行副总裁、首席财务官兼财务主管 Jean Hu所说，此次合作“预计将为 AMD 带来数百亿美元的收入，同时加速 OpenAI 的 AI 基础设施建设”。 她补充说，该协议“为 AMD 和 OpenAI 创造了重要的战略一致性和股东价值，预计将大大增加 AMD 的非 GAAP 每股收益”。 对于 AMD 来说，获得 OpenAI 作为客户是其多年来试图打破 Nvidia 对 AI 芯片市场的控制的证明。 MI450 也代表着 AMD 首次尝试所谓的机架式系统，该系统将多个 GPU 芯片和其他组件组合在一起，有效地形成一台可装入现有数据中心机架的 AI 超级计算机。这类系统的复杂性非常高；就连英伟达去年在量产首批基于 Blackwell 的机架时也遇到了一些困难。 对于OpenAI和AMD的交易来说，还有一个关注点，那就是博通是否会最大利空。因为据之前报道，OpenAI正在与博通打造ASIC。专家此前曾猜测，AVGO 将成为仅次于 Nvidia 的第二大 AI 芯片供应商——尤其是在有报道称 OpenAI 已下达 100 亿美元定制 ASIC 订单之后。",
            "score": 0.657297,
            "timestamp": "2025-11-09T14:52:55.323599"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://x.com/python_xxt/status/1975195207479304276",
            "title": "Robinson · 鲁棒逊on X",
            "content": "Robinson · 鲁棒逊 on X: \"非常精彩的一篇分析新闻稿 科技新闻类报道，也被颠覆了 OpenAI的芯片博弈：百亿美元豪赌背后的战略与权力 OpenAI在2025年打出了AI基础设施史上最大的一手牌：同时与NVIDIA和AMD签署总价值超过1600亿美元的GPU采购协议。这不仅是商业合同，更是一场重塑AI芯片市场权力格局的深度博弈。\" / X Don’t miss what’s happening People on X are the first to know. Sign up Post See new posts Robinson · 鲁棒逊 Translate post 1:43 PM · Oct 6, 2025 New to X? Sign up now to get your own personalized timeline! Sign up with Apple By signing up, you agree to the Terms of Service and Privacy Policy, including Cookie Use. Trending now What’s happening Trending in United States Trending in United States 4,074 posts Sports · Trending 1,255 posts Sports · Trending Terms of Service Privacy Policy Cookie Policy © 2025 X Corp.",
            "score": 0.5809471,
            "timestamp": "2025-11-09T14:52:55.323608"
          },
          {
            "query": "OpenAI GPU采购规模 NVIDIA合作细节 训练推理成本 第二供应商",
            "url": "https://www.itiger.com/hant/news/1129656474",
            "title": "GPU警鐘敲響，AI過熱了？ - 老虎證券",
            "content": "Nvidia 計劃在未來十年向OpenAI 投資1000 億美元，OpenAI 可以用這筆資金購買Nvidia 的芯片，用於其AI 數據中心。AMD 將向OpenAI 提供認股權證，",
            "score": 0.5264164,
            "timestamp": "2025-11-09T14:52:55.323617"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://aigc.idigital.com.cn/djyanbao/%E3%80%90%E4%B8%AD%E5%8E%9F%E8%AF%81%E5%88%B8%E3%80%91%E7%94%B5%E5%AD%90%E8%A1%8C%E4%B8%9A2025%E5%B9%B4%E5%BA%A6%E6%8A%95%E8%B5%84%E7%AD%96%E7%95%A5%EF%BC%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%88%9B%E6%96%B0%E6%8C%81%E7%BB%AD%E6%8E%A8%E8%BF%9B%EF%BC%8C%E5%8D%8A%E5%AF%BC%E4%BD%93%E8%87%AA%E4%B8%BB%E5%8F%AF%E6%8E%A7%E6%96%B9%E5%85%B4%E6%9C%AA%E8%89%BE-2024-12-02.pdf",
            "title": "[PDF] 人工智能创新持续推进，半导体自主可控方兴未艾",
            "content": "AI 训练和推理受限于大型复杂模型而在云端部署，而AI 推理. 的规模远高于AI 训练，在云端进行推理的成本极高，将影响规模化扩展。随着生成式AI 的快. 速",
            "score": 0.27338326,
            "timestamp": "2025-11-09T14:53:23.647224"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://premium-wscn.awtmt.com/3aa85b3c-ce9c-4f54-bd31-8f18c3447300.pdf",
            "title": "[PDF] ——A 股2025 年中期策略展望",
            "content": "6 月13 日， AMD 发布MI350 系列，性能超越NVIDIA B200，并与OpenAI 深化合作，支持大模型运行，推动开放. 架构兴起。AI 定制芯片百花齐放，云厂商与",
            "score": 0.17001165,
            "timestamp": "2025-11-09T14:53:23.647253"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://hai.stanford.edu/assets/files/hai_ai_index_report_2025_chinese_version_061325.pdf",
            "title": "[PDF] 介绍2025年人工智能指数报告 - Stanford HAI",
            "content": "它也是我们迄今为止发布过的最全面的指数。今年的报告新增了对人工智能硬件发展状况. 的深入分析、对推理成本的新估算，以及对人工智能论文",
            "score": 0.106142916,
            "timestamp": "2025-11-09T14:53:23.647265"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://finance.sina.com.cn/stock/report/2025-08-24/doc-infnatsc9974584.shtml?cre=tianyi&mod=pchp&loc=19&r=0&rfunc=20&tj=cxvertical_pc_hp&tr=12",
            "title": "招商策略：美联储货币政策变化对港股和A股的影响 - 新浪财经",
            "content": "【资金·众寡】融资资金、ETF净流入。融资资金前四个交易日合计净流入831.6亿元；新成立偏股类公募基金195.2亿份，较前期上升107.4亿份；ETF净申购，对应净流入5.9亿元。融资资金净买入电子、计算机、通信等；券商ETF申购较多，信息技术ETF赎回较多。重要股东净减持规模缩小，计划减持规模下降。 【主题·风向】DeepSeek-V3.1正式发布，新版Agent如臂使指。DeepSeek在8月21日下午于官方公众号正式发布DeepSeek-V3.1，本次升级包含以下主要变化：混合推理架构：一个模型同时支持思考模式与非思考模式；更高的思考效率：相比 DeepSeek-R1-0528，DeepSeek-V3.1-Think 能在更短时间内给出答案；更强的 Agent 能力：通过 Post-Training 优化，新模型在工具使用与智能体任务中的表现有较大提升。 ▶ 从申报放量、研发提效到技术突破：产业链竞争力持续走强 ▶ 出海提速势不可挡：全球化合作跻身产业新增长引擎 ▶ 系统创新对决全球封锁：昇腾算力的突围与挑战 ▶ 国产算力巨头整合，打造自主可控产业闭环 ▶ 寒武纪思元590崭露头角，国产算力挑战英伟达 ▶ DeepSeek-V3.1正式发布，思考效率更高，Agent能力更强 8月21日，DeepSeek 正式发布DeepSeek-V3.1模型。此次升级基于 DeepSeek V3 Base 模型，显著增强了模型的思考效率以及在工具使用与智能体任务中的表现。升级后的 DeepSeek-V3.1模型在输出 token 数减少 20%-50% 的情况下，各项任务的平均表现与 R1-0528 持平，并且在非思考模式下的输出长度也得到了有效控制，相比于 DeepSeek-V3-0324，V3.1-Think能够在输出长度明显减少的情况下保持相同的模型性能。此外，新版本也在工具调用，智能体支持方面获得了增强，在多项搜索评测指标上取得了较大提升。在需要多步推理的复杂搜索测试（browsecomp）与多学科专家级难题测试（HLE）上，DeepSeek-V3.1 性能已大幅领先 R1-0528，并且在代码修复测评 SWE 与命令行终端环境下的复杂任务（Terminal-Bench）测试中，DeepSeek-V3.1 相比之前的 DeepSeek 系列模型有明显提高。 ▶ 从网红空翻，春晚跳舞到资本独角兽：国产人形机器领军者宇树科技筹备上市 ▶ 技术降维与产业链优势，国产割草机“出海割草” 综合以上分析，预计二季度全A整体盈利仍然承压。结合近期披露的业绩预告/快报/报告和分析师一致盈利预测变动来看，预计中报业绩增速较高或有改善的行业主要有：1）高景气的TMT领域：LED、通信网络设备及器件、游戏、面板、模拟芯片设计等；2）具备全球竞争力的优势制造领域：锂电专用设备、风电零部件、商用载货车、板材、机器人等；3）消费服务领域：受益于政策催化、销售改善的跨境电商、其他黑色家电、粮油加工、成品家居、乳品、冰洗、黄金等；4）其他：医疗研发外包、化学制剂、氟化工、氯碱、证券、农药。 7月智能手机产量同比增幅收窄，三个月滚动同比增幅扩大。7月智能手机产量94.32百万台，同比增幅收窄6.40个百分点至2.00%，智能手机产量三个月滚动同比增幅扩大2.80个百分点至2.90%。 7月集成电路产量同比增幅收窄，三个月滚动同比增幅扩大。7月集成电路产量为468.92亿块，同比增幅收窄0.80个百分点至15.00%，集成电路产量三月滚动同比增幅扩大3.67个百分点至14.10%。 7月工业机器人产量同比增幅收窄，三个月滚动同比增幅收窄。7月工业机器人产量6.37万台/套，当月同比增幅收窄13.90个百分点至24.00%，三个月滚动同比增幅收窄9.17个百分点至32.47%；1-7月累计产量44.71万台/套，累计同比增幅收窄2.70个百分点至32.90%。 7月金属切削机床产量同比增幅扩大，三个月滚动同比增幅扩大。7月金属切削机床产量为7.05万台，同比增幅扩大7.60个百分点至20.30%，三个月滚动同比增幅扩大1.57个百分点至13.10%。1-7月金属切削机床累计产量为48.34万台，同比增幅扩大0.40个百分点至13.90%。 7月包装专用设备产量同比增幅扩大，三个月滚动同比增幅扩大。7月包装专用设备产量当月值为14.52万台，同比增幅扩大12.80个百分点至32.30%，三个月滚动同比增幅扩大7.00个百分点至26.93%。1-7月包装专用设备产量累计值为104.89万台，同比增幅收窄0.50个百分点至33.50%。 7月金属成形机床产量同比增幅收窄，三个月滚动同比持平。7月金属成形机床产量当月值为1.40万台，同比增幅收窄6.70个百分点至0.00%，三个月滚动同比持平为4.60%。1-7月金属成形机床累计产量为10.00万台，同比增幅收窄1.70个百分点至8.70%。 7月主要企业工程机械销售当月同比多数改善。主要企业装载机销量同比增幅收窄3.89个百分点至7.41%，三个月滚动同比增幅收窄4.96个百分点至8.65%；主要企业叉车销量同比增幅收窄8.70个百分点至14.40%，三个月滚动同比增幅扩大3.12个百分点至16.43%；主要企业压路机销量同比增幅扩大12.60个百分点至23.80%，三个月滚动同比增幅收窄4.13个百分点至17.33%；主要企业汽车起重机销量同比由负转正至9.60%（前值为-5.28%），三个月滚动同比跌幅收窄4.36个百分点至-1.26%；主要企业内燃机销量同比增幅扩大8.04个百分点至14.28%，三个月滚动同比增幅扩大0.79个百分点至10.94%。 7月全国发电量三个月滚动同比增幅扩大。1-7月份，我国累计发电量54702.60亿千瓦时，同比增幅扩大至1.30%，三个月滚动同比增幅扩大0.7个百分点至3.9%。其中火电累计产量35439.50亿千瓦时，同比降幅收窄至-1.30%，三个月滚动同比增幅扩大2.3个百分点至2.7%； 水电累计产量6909.70亿千瓦时，同比降幅扩大至-4.50%，三个月滚动同比降幅扩大1.0个百分点至-8.4%； 风电累计产量6291.00亿千瓦时，同比增幅收窄至10.40%，三个月滚动同比增幅收窄2.8个百分点至14.2%； 太阳能累计产量3268.49亿千瓦时，同比增幅扩大至22.70%，三个月滚动同比增幅扩大4.5个百分点至43.0%； 核电累计产量2792.80亿千瓦时，同比增幅收窄至10.80%，三个月滚动同比增幅收窄1.4个百分点至8.5%。 从全周资金流动的情况来看，本周融资资金净流入，新成立偏股类公募基金上升，ETF净申购。具体来看，融资资金前四个交易日合计净流入831.6亿元；新成立偏股类公募基金195.2亿份，较前期上升107.4亿份；ETF净申购，对应净流入5.9亿元。 ▶ 国内重要资讯与产业政策 （3） 宏观政策——财政部：地方政府根据情况优先实施具有一定收益的项目 （4） AI+制造——《上海市加快推动“AI+制造”发展的实施方案》发布：推动3000家制造业企业智能化应用 （5） 卫星互联网——广东：加快推动卫星互联网服务在多个等前沿领域落地一批重大应用场景创新示范项目 （8） 人工智能——DeepSeek-V3.1正式发布，称UE8M0 FP8是针对即将发布的下一代国产芯片设计 （9） 影视——广电总局：改进电视剧集数和季播剧播出间隔时长等管理政策 （10） 算力基础设施——工信部：有序引导智能算力基础设施适度超前、动态平衡 ▶ 国外重要资讯与产业政策 （1） 美联储动态——鲍威尔暗示美联储可能降息 （2） 美欧贸易——白宫：美国与欧盟已就贸易协定框架达成一致 （4） 中俄海军——中俄海军第5次海上联合巡航圆满结束 （5） 云计算——谷歌与Meta达成100亿美元云计算合同 （6） 消费电子——谷歌宣布将于8月底发布Pixel 10、10 Pro和10 Pro XL （7） 人工智能——特斯拉牵手豆包与DeepSeek通过火山引擎接入 （8） 人工智能——苹果据悉探索利用谷歌Gemini为新版Siri赋能 （9） 农产品贸易——美大豆协会呼吁尽早同中国达成协议缓解豆农危机 （10） 美国经济——美国防部拟投最高5亿美元采购合金级钴 本周产业观察： DeepSeek-V3.1正式发布，新版Agent如臂使指 DeepSeek在8月21日下午于官方公众号正式发布DeepSeek-V3.1，本次升级包含以下主要变化：混合推理架构：一个模型同时支持思考模式与非思考模式；更高的思考效率：相比 DeepSeek-R1-0528，DeepSeek-V3.1-Think 能在更短时间内给出答案；更强的 Agent 能力：通过 Post-Training 优化，新模型在工具使用与智能体任务中的表现有较大提升。 ▶ 模型同步升级，功能全面延伸 ▶ 多项测评突破以往，代码和搜索能力再加强 由上表可知在代码修复测评 SWE 与命令行终端环境下的复杂任务（Terminal-Bench）测试中，DeepSeek-V3.1 相比之前的 DeepSeek 系列模型有明显提高。 由上表可知DeepSeek-V3.1在多项搜索评测指标上取得了较大提升。在需要多步推理的复杂搜索测试（browsecomp）与多学科专家级难题测试（HLE）上，DeepSeek-V3.1性能已大幅领先R1-0528。 ▶ 思考效率提升，价格有所调整",
            "score": 0.105809815,
            "timestamp": "2025-11-09T14:53:23.647276"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://img.frostchina.com/attachment/17560512/3dotWjbdTCLfXgWYp5mcSp.pdf",
            "title": "[PDF] 中国未来50年产业发展趋势白皮书第四期",
            "content": "... 推理）定制设计的芯片，它通过“手术刀式”的设计，. 舍弃通用功能，从而在特定任务上实现比通用GPU更高的性能功耗比和成本效益。 ◇. Prefill：大模型推理",
            "score": 0.09204121,
            "timestamp": "2025-11-09T14:53:23.647286"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://www.scribd.com/document/719522373/2023-2024%E5%B9%B4%E7%A7%91%E6%8A%80%E8%A1%8C%E4%B8%9A%E4%B8%BB%E8%A6%81%E5%8F%98%E5%8C%96%E8%B6%8B%E5%8A%BF%E6%A2%B3%E7%90%86%E4%B8%8E%E6%80%BB%E7%BB%93-2024-2-79%E9%A1%B5-Copy",
            "title": "2023 2024年科技行业主要变化趋势梳理与总结2024.2 79页 - Scribd",
            "content": "276 views81 pages 276 views81 pages Download as pdf or txt TUVW+XY3Z[\\]F^\\_+`aP\\_b * Share on Facebook, opens a new window * Share on LinkedIn, opens a new window * 营销数据分析 PDF 营销数据分析 PDF * 2023 2024品牌全球化白皮书：深度全球化 PDF 2023 2024品牌全球化白皮书：深度全球化 PDF * 阿里巴巴（BABA）深度系列报告之二：核心电商业务仍是生态系统基石，下沉市场是重要引流血管 PDF 阿里巴巴（BABA）深度系列报告之二：核心电商业务仍是生态系统基石，下沉市场是重要引流血管 PDF",
            "score": 0.04191884,
            "timestamp": "2025-11-09T14:53:23.647295"
          },
          {
            "query": "OpenAI 2015-2024 年 GPU 采购历史 与 NVIDIA 早期合作 训练成本 推理成本 演变",
            "url": "https://do.superic.com/storage/manage/202407/05/1720161758_00551.pdf",
            "title": "[PDF] 大基金三期成立，关注国产替代方向",
            "content": "5 月国内半导体行业表现相对较弱。2024 年5 月国内半导体行业. （中信）下跌1.71%，同期沪深300 下跌0.68%，半导体行业. （中信）年初至今下跌14.18%；5 月",
            "score": 0.014415935,
            "timestamp": "2025-11-09T14:53:23.647305"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://www.donews.com/article/detail/8570/90777.html",
            "title": "Donews OpenAI和英伟达，正在把GPU玩成“金融产品”- DoNews专栏",
            "content": "回顾过去一年，全球 AI ...上。微软、谷歌、Meta 的资本开支也刷新纪录， 仅微软在 2024 年的资本开支就达到 550 亿美元 ，其中大部分用于建设 GPU 数据中心。",
            "score": 0.751375,
            "timestamp": "2025-11-09T14:55:21.486873"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://m.c114.com.cn/w5339-1278888.html",
            "title": "C114 大模型企业对标：openAI 2024年H2最新进展 - C114通信网",
            "content": "# ��ģ����ҵ�Ա꣺openAI 2024��H2���½�չ ��1 Meta���������½�չ����Ҫָ���� **������������˾����Ǳ�������з��¼��������ɱ�������ս** **2024������������������δ��Ǳ���޴���**�����ļ���ʾ��2024��8�£�OpenAI���������Ѵ�3����Ԫ����2023������������1700%����ë���ʽ�41%��Զ������ҵ������������˾��65%ƽ��ˮƽ��OpenAI�ƻ���2028��ǰ��ë����������67%��2024��10�£�OpenAI��ϯ������Sarah Friar������ýר���ڼ�Ԥ��OpenAI��2024�����뽫�ﵽ37����Ԫ����2023����16����Ԫ��������131.25%��Ԥ�����������꽫������116����Ԫ�������������٣�OpenAI��ֵˮ�Ǵ��ߣ��ڽ���10�µ�һ�����ʺ���ֵ�Ѵ�1570����Ԫ����Լ��������ֵ�������� **��������Ӫ���Ƚ���AIϵͳΪ�������޴���֧��**OpenAI���ϴ�ʼ��Altman��ָ�������Ź�˾���������ӵ�ģ�ͣ�Ԥ��֧�������������������������ܻ���Ҫ�Ｏ��������Ԫ���������ɱ���Ԥ��������ʾ��OpenAI������Ӫ�ܳɱ��򽫴�85����Ԫ����Ҫ��ģ��������ѵ���������ɱ����ɣ��ֱ�Ϊ40�ڡ�30�ڡ�15����Ԫ��**�����ɱ����棬**��������3�£�OpenAI�ѻ��ѽ�40����Ԫ����΢���ķ�������Ⱥ��֧��ChatGPT�����ײ���ģ�͵���ת���ü�Ⱥ�൱��35����Ӣΰ��A100оƬ������Լ29����оƬΪChatGPT�ṩ֧�֡�**ѵ���ɱ�������֧�����ݵķ��ã����棬**������һ���ȣ�����OpenAIģ��ѵ���ķ�������Ⱥ�Ѱ���12����Ӣΰ��A100������OpenAI�ӿ�ѵ�������콢ģ�ͣ�ѵ���ɱ����ܽ��ڽ��귭һ����**�����ɱ����棬**����ĿǰOpenAI���ô�Լ1700��Ա�������Ÿù�˾���ȸ��ȿƼ���ͷ���Ἴ���˲ţ����������ɱ��ڽ������ܽ��ߴ�Լ15����Ԫ�� **��ģ�ͼ�����������ģ̬������������ǰ�ط����Ƴ���ģ��** **1.****�·���GPT-4oϵ��ģ�ͣ��ṩ��ģ̬��������ʱ�ӽ�������** **GPT-4oΪ�˵��˶�ģ̬ģ�ͣ���ʵ�ֺ��뼶�Ƚ��Ӿ���Ƶ���⡣**2024��5�£�OpenAI�����µ�“ȫ��ģ��”��omni model��GPT-4o�����ṩ��GPT-4ͬ�ȳ̶ȵ�ģ�������������ٶȸ��죬�����ṩͬʱ�����ı���ͼ������Ƶ�����ݵĶ�ģ̬�����������������㣺**��1��GPT-4oΪ�˵��˶�ģ̬ģ�ͣ�**ģ��������������������ͬһ�������紦�������ı��������ͱ������ܷ�����׼����ʵ��GPT-4 Turbo�������ܣ�ͬʱ�ڶ����ԡ���Ƶ���Ӿ������ϴﵽ�µĸ�ˮλ�ߣ�**��2�����뼶��Ӧ��**GPT-4o����Ƶ��������Ӧʱ������Ϊ232���룬ƽ��Ϊ320���룬�������ڶԻ��е���Ӧʱ�����ƣ�**��3�����Ƚ����Ӿ�����Ƶ�������������ܸ�֪��������̬��**GPT-4o֧���ڶԻ�����ʱ���ϣ��ɸ��ݳ������ɶ���������ͬʱ֧����Ƶ�Ի���**��4��API�Լ۱�����������**��GPT-4 Turbo�����ٶ�����2�����ɱ�����50%��������������5���� **GPT-4o miniģ���ƽ�ʵ�ָ��߳ɱ�Ч�����˹����ܡ�**2024��7�£�OpenAI����GPT-4o mini����ΪGPT-4oϵ�����߳ɱ�Ч�����ͺţ���ģ�;߱������ص㣺**��1����ģ̬����������**�߱��ı���ͼ������Ƶ����Ƶ�Ķ�ģ̬��������������API��֧���ı����Ӿ����룬δ���ƻ���չ��Ƶ����Ƶ�����롢������**��2�����ܱ������죬**�ڶ���ȫ��Ȩ����׼�����гɼ���ԽGPT-3.5 Turbo��ģ�ͣ�����MMLU�ı�������������׼���Լ�Human Eval�������ܲ����зֱ���82.0%��87.2%�ĵ÷����ȣ���MGSM��ѧ�������Լ���ģ̬����������MMMU�����зֱ�����87.0%��59.4%�ĸ߷֣�**��3���ɱ��������ͣ�**����ԭ��GPT-4oģ�ͱ���96%-97%��**��4������������ǿ��**ӵ��128k tokens�������Ĵ���������֧��16k����tokens��**��5����ȫ���Դ��£�**���׸�ʹ��ȫ�°�ȫ����“ָ�����νṹ”��AIģ�ͣ������ȿ����ض�ָ�ʹ�����û�������ģ��ִ�в�����������Ч����Խ����������ʱע�뼰ϵͳ��ʱ��ȡ�ȷ��ա� **2.** **����GPT-4ѵ��CriticGPTģ���������߼�AIϵͳ��������** 2024��6�£�OpenAI��������GPT-4��ģ��CriticGPT��ּ���ҳ�ChatGPT�����������󡢸����Ľ��������õذ�������ʦ����ChatGPT��Ӧ������׼ȷ�ԡ�CriticGPT�ķ�����־��RLHF���������෴����ǿ��ѧϰ������ȡ���ش������������������������������渴�ӵ�AIģ��ʱ���ٵĺ�����ս����ģ�;߱������ص㣺**��1���ɽ������ܴ��󲶻���**����������ChatGPT����������ָ�����д��󣬼���LLM����������ģ�ͣ�������׼ȷ�ʴ�63%��**��2������������Ч�ʣ�**ʹ��CriticGPT���������������߼���ChatGPT����������Ч�ʱȲ�ʹ��ʱ�߳�60%��**��3����Ȼ���Է�����**��ͨ����Ȼ���Է���ָ���������⣬���ܰ���ѵ��ʦ׫д��ȫ���������������鹹���⡣ **3.****�·���o1ϵ������ģ�ͣ���������������������** **OpenAI o1ϵ���ƶ�AI���������ε�������������������������չ��**2024��9�£�OpenAI�Ƴ�o1ϵ��ģ�ͣ�����o1��o1-preview��o1-mini�����ϵ��ģ��ͨ��ģ���������������̣��ܹ��ڻش�ǰ���и�����˼�����Ӷ�������������������Ҫ�ص����£�**��1������ȫ��������ʽ��**o1-preview����˼ά����CoT��Chain of Thought��+���Ҷ���ǿ��ѧϰ��������ʽ���ɽ����Ӳ�������Ϊ���򵥲��֣����ڵ�ǰ������Чʱ���Բ�ͬ��ʽ��������Scaling up��Ԥѵ����չ����ѵ���׶Σ�**��2�����ȵ���������������**��o1-preview����������ѧ������ѧ�ȸ��������Ļ�׼�����б��ֿ��벩ʿ���������ڹ�����ѧ����ƥ�˾������ʸ���������ȷ�ʴ�83%��GPT-4o��Ϊ13%��**��3����ȫ��������**��һ�����ѵ�Խ�������У�o1-preview�÷�84������100����Զ����GPT-4o��22�֣�֤��o1-preview�ڰ�ȫ������ִ�к�Ӧ��Υ�波��ʱ���ָ��ɿ��� **�������汾OpenAI o1-mini�������㿪���߶Ը�Ч����������������**������Ż�������ģ�������ٶȿ졢ʹ�óɱ��ͣ��ǳ��ʺϴ�������������������Ҫ�ص����£�**��1�������Ż���**��Ϊo1ϵ�е������汾��o1-mini�ڱ��ָ�����������ͬʱ����������Ӧ�ٶȣ��絥�����������ϣ�o1-mini��GPT-4o��3-5����**��2���ɱ�Ч���ߣ�**����o1-preview��o1-miniʹ�óɱ�����80%��**��3������ר����**o1-mini�ڱ��������ϱ���ͻ������Ϊ�������ṩ��Ч�������ɺ͵���֧�֣���Codeforces���뾺���У�o1-mini����1650 Elo�����֣���o1��1673 Elo�൱������o1-preview��1258 Elo�� **4.****�Ƴ�����ʱ��һ����ģ�ʹٽ�����ʽ�˹����ܷ�չ** 2024��10�£�OpenAI�Ƴ���������ʱ��һ����ģ��sCM����������Ƶ��ͼ������άģ�͡���Ƶ��ʵʱ����������������������ʽ�˹������½׶Ρ�ģ����Ҫ�ص����£�**��1����������TrigFlowͳһ���ܣ�**�������۹�ʽ�����϶������ӹ��̣�����ѵ�����̸��ȶ���Ϊ����ģ�͸Ľ��ṩ��ʵ������**��2�������ٶ�����������**�������������������ɸ����������������ٶ�����50������15�ڲ���ģ���ڵ���A100 GPU������һ��ͼƬֻ��0.11�룻**��3�����ָ���������Ч����**���������𸴼��ٵ��������������붥����ɢģ���൱��**��4�����п���������������**����������ͼ�����ɣ�����������Ƶ����άģ�ͺ���Ƶ��ʵʱ���ɣ�Ϊ������Ӧ���ṩ��չ����ǰ���� **�г���չ���������²�Ʒ���ܣ�����̽������ҵģʽ** **1.****��Ʒ��������****��������ChatGPT���ܣ������û���������** **�𲽿���“�߼�����ģʽ”��Advanced Voice Mode���������˻��������顣**2024��7�£�OpenAI����С����ChatGPT Plus�û��Ƴ�ChatGPT�߼�����ģʽ��Alpha�汾���в��ԣ�9����ʽ��ChatGPT Plus��Team�û��Ƴ��߼�����ģʽ��֧�ֳ���50�����ԣ�10���û���ֱ����Windows���Ի�Mac�ͻ���ʹ�ø߼�����ģʽ���߼�����ģʽ���Ƴ���AI�Ի���������Ҫ���£�ʹ�û���ֱ��ͨ��������ChatGPT���жԻ���������ʱ���Ϻ͵����������ܴ����ͻع˼��䣬��������������Ϣ���Զ���ָ����ṩ���Ӿ�׼�͸��Ի��ķ��������������û��������顣 **�����ṹ���������ܣ�Structured Outputs������������API�ɿ��Ժ�Ӧ�þ�ȷ�ȡ�**2024��8�£�OpenAI��API�������ṹ���������ܣ�����API����JSON��XML�ȸ����ڴ��������ݸ�ʽ����ȷ��ģ�����ɵ���������ȫ���Ͽ�����Ա�ṩ��JSON�ܹ�����������API�Ŀɿ��ԡ�ͬʱ��OpenAI����Python��Node SDK��ʹ����������ʹ��Pydantic����Zod����һ���������ṩ���ߵĽṹ����Ӧ��ʽ��SDK���Զ�������������ת�����������ߵ���������ת��Ϊ֧�ֵ�JSON�ṹ�� **����GPT-4o with Canvas���ܣ�����д���ͱ��̵�Э�����顣**2024��10�£�OpenAI�����µĽ�����ʽCanvas�������û���һ��������������ChatGPT�������Ⱥ�����������ϸ����Ƕ�����������Եı༭�Լ�������д���ڱ��̷��棬Canvas�������ԡ��������顢����ע�ͺ��ڶ�������֮��ת�������ȹ��ܣ���д�����棬Canvas�ṩ�ı���ɫ���ɶ��Ե������﷨�������Ƚ����ȹ��ܡ�Canvas�����ر��ʺ���Ҫ�㷺�༭���޶�������������д���ͱ��̵�Ч�ʺ�Э�����顣 **����ChatGPT Search����ʽ����AI����������**2024��10��,OpenAI��ʽ������������ChatGPT Search����ʹ������������Ϣ���ش����⣬���ṩ������Դ�����ӡ�ChatGPT Search����ChatGPT����ҳ�桢�ֻ�������Ӧ�ã���Ϊ�û��ṩ����AI���Ϻ���ֱ�Ӵ𰸣�ʹ��Ϣ�������Ӹ�Ч��׼ȷ��δ�����������ܻ���ΪOpenAI��һ������������ӯ����ѡ���� **2.****��ҵģʽ��****Χ��ChatGPTҵ������ҵ������̽����Ӫ��ģʽ** **�������߶��ĵ�ChatGPTҵ��Ϊ���ģ�ͨ��������ҵ�û��������롣**2024��10�£�OpenAI��ϯ������Sarah Friar��ʾ��ĿǰOpenAI��Լ75%��ҵ�����������߶��ģ���ҵ��ChatGPT�����𲽣����Ѿ�ʵ�ֿɹ۵��껯���룬Ǳ���޴�����ҵ��ChatGPT�����û���2024��9����ͻ��100�򣬽�2023��ĩ��15������566.67%���������û����棬ChatGPT�����û��ƻ�������Ϊÿ��20��Ԫ���ܻ�Ծ�û���2.5�ڣ��������û�����ת���ʴ�5%-6%��2024��7��ChatGPT Plus�����û�����ͻ��770�򣬽�ȥ��ͬ������285%��9��o1ϵ��ģ�ͷ���������һ�ָ����û������������߸����û���ͻ��1000���� **APIֱ�����빱�׽�������������������δ����ת����Azure���Ⱥ����������ֳ�ģʽ��**���л���Future Search����2024��7�¶�OpenAI�����빹�ɽ��в��⣬������ʾ��Ϊ�����ߺ���ҵ�ṩֱ�ӷ�����AIģ�͵�API�ӿڷ�����ΪOpenAI����15%�����룬OpenAIҲ��7��9����ֹͣ���Է�֧�ֹ��Һ͵�����API�����Խ�����Ӧҵ�����������⣬ͨ��2023������΢��Azure�����ṩ����AIģ�ͷ���Ȩ�ޣ�OpenAI��������2����Ԫ�����ȷֳɡ� **3.****�г���չ���ԣ�****���ּ����������ƣ��齨�����Ŷ���չ����ҵ��** **���ֿ�����ǰ�ص��˹�����ģ�ͣ�������������Ϊ������������**OpenAIʼ�ղ���Ͷ����Դ����GPTϵ��ģ���з���������Sarah Friar����2024��7�¶���ǿ����“��������˵������Ҫ���Ǳ���ǰ�أ�������ǰ��ģ�ͣ�ȷ���������ս�ͨ���˹����ܣ�AGI���츣������”��11�£�OpenAI��ϯִ�й�Altmanָ����OpenAI��ǰ�ص㽫�۽�����רע������������������ģ�ͣ���Ӧ�Ը����ӵļ����������г���ս�� **ͨ����ȫ�������������´��Ը��õط���ȫ���ͻ��������ø����뵱����������ҵ�ͺ����������н����ͺ����Ļ��ᡣ**2024��4�£�OpenAI�������ձ����������ù�˾�����޵��׸����´���10�£�OpenAI�����ƻ���ŦԼ������ͼ�����衢��³�������¼��¿���5���µİ��´���ͬʱ���������ɽ�ɽ���׶ء������ֺͶ������´�������ǿȫ��Ӱ������OpenAI����ʾ���¼�����ȫ���˾�ʹ��ChatGPT�������ߵĵ���֮һ��ǿ���õ�����AIӦ�õ�׼���̶ȡ��¼��°��´�����������������֧�ָõ���AI��չ��AI Singapore������OpenAI������Ͷ�ʶ���100����Ԫ����ʹ������AIģ�͸������ڵ������Ժ��Ļ��� **ģ�����ܵ�������ChatGPT�û���̬����������**ͳ����վtooltester ��ʾ��2023��5����2024��4�µ�һ���䣬ChatGPTÿ�·���������16�ڵ�18��֮�両����2024��9��o1ϵ����ģ�͵ķ��������û���̬����������ʹChatGPTԾ��Ϊȫ����������ʮһ����վ������Similarweb���������ݣ�ChatGPT��2024��10�µ��·�������ͻ��31�ڴΣ�����ȥ��ͬ��ͬ������112%������ͬ��8������18.7%�� ������ ������ #### ���� * ������OpenAI�������ʹ�˾ ����������ҵ������Ӫ�Ĵ�����AIC114ͨ���� ������ 11/6 * OpenAI ��ϯ������ɯ�� ����������˾Ŀǰ���� IPO �ƻ������ƶ���˾�Ȳ��������й�ģIT֮�� ���� 11/6 * OpenAI ���� ChatGPT ʹ�����ߣ���ֹ�ṩרҵҽ�ơ����ɺͲ�������IT֮�� Զ�� 11/3 * OpenAI �Ƴ���ҳ������ Atlas �󣬹ȸ��ɼ�һ���µ� 3%IT֮�� ��Դ 10/22 * OpenAI ��ǿ Sora ������ʩ���ϸ���ֹδ����Ȩʹ������Ф��������IT֮�� Զ�� 10/21 * OpenAI Я�ֲ�ͨ�����׿����� AI оƬ�������� 10 ���߼���2026 ���°��꿪ʼ�ƽ��з�IT֮�� ºԴ��ʵϰ�� 10/14 ������ �����ڣ�2025-11-7 3:16:08",
            "score": 0.7120925,
            "timestamp": "2025-11-09T14:55:21.486891"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://zhuanlan.zhihu.com/p/24865290388",
            "title": "Zhihu 挑战英伟达GPU？ASIC还欠火候 - 知乎",
            "content": "到 2024 年，商用 AI 芯片将占据全球 AI 半导体市场的 90%，其中 Nvidia 以 980 亿美元的收入领先，其次是 AMD，收入为 50 亿美元 。相比之下，定制 ASIC 仅占 10%，其中 Broadcom 以 80 亿美元的收",
            "score": 0.62879556,
            "timestamp": "2025-11-09T14:55:21.486901"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://hub.baai.ac.cn/view/50115",
            "title": "Baai 1.4万亿美元的算力军备竞赛：OpenAI的战略转向与AI产业的深层焦虑【AI战略洞察】 - 智源社区",
            "content": "# 1.4万亿美元的算力军备竞赛：OpenAI的战略转向与AI产业的深层焦虑【AI战略洞察】 AI systemAIDL 清华大学人工智能国际治理研究院 2025-11-06 22:50 分享 点击蓝字 关注我们 11月3日，OpenAI宣布与亚马逊AWS签订了一份价值380亿美元、为期7年的算力供应协议。这个数字本身已足够惊人，但更值得关注的是它所揭示的产业逻辑转变：**AI竞赛的核心瓶颈，已经从\"谁能开发出更好的算法\"转向\"谁能获得足够的算力\"。** **来源：每日资讯网** **这不是OpenAI第一次签订巨额算力合约。仅在过去几个月，这家公司就陆续与微软、Oracle、Google等科技巨头签订了总额超过1.4万亿美元的算力采购协议。****一个年营收约130亿美元的公司，为何敢于承诺如此规模的未来支出？这是远见卓识的战略布局，还是被资本裹挟的非理性繁荣？** 更耐人寻味的是这笔交易的时机选择。就在一周前，OpenAI刚刚结束了与微软长达五年的独家云服务合作关系；而亚马逊本身已经向OpenAI的直接竞争对手Anthropic投资了数十亿美元。在这个充满矛盾与悖论的商业决策背后，是**AI产业格局的深刻重构：独家联盟正在瓦解，多元竞合成为新常态，而算力——这个看不见摸不着的数字资源——正在成为比石油更关键的战略资产**。 这篇文章将从五个维度深入解读这笔交易：**它反映了AI公司怎样的焦虑？多云战略背后隐藏着什么样的博弈逻辑？云计算巨头们如何在竞争与合作之间寻找平衡？千亿美元级别的投资在财务上是否可持续？**以及，**这场算力军备竞赛最终将把整个产业带向何方？** **史无前例的算力锁定：交易背后的紧迫性** 2024年11月3日，OpenAI与亚马逊AWS达成一项为期7年、总价值380亿美元的AI算力供应协议，OpenAI将获得数十万个英伟达最先进GPU芯片（包括GB200和GB300系列）及数千万个CPU的扩展能力。这笔交易的规模令人震撼，但更值得关注的是其背后反映出的产业焦虑：**尽管OpenAI已开发出性能更强的模型，但因基础设施不足而无法推出市场。** 来源：新浪财经 **这种\"有模型无算力\"的困境，迫使OpenAI采取了激进的资源锁定策略。**CEO Sam Altman曾表示，公司计划发展30吉瓦的电力容量——相当于30座核电站的发电量，足以为2600万户家庭供电一年。这一数字折射出AI大模型训练和推理对算力的惊人需求。在AI竞赛进入白热化的当下，算力已成为比算法更稀缺的战略资源。**OpenAI通过提前7年锁定巨量算力，本质上是在用确定性对抗不确定性，用资本换取时间窗口。** ## 这笔交易为整个AI产业提供了三个重要启示。 **首先，****算力正在从生产要素转变为战略资产****。** 在传统软件时代，开发者可以根据需求弹性购买云服务；但在AI大模型时代，训练一个前沿模型可能需要数万甚至数十万GPU连续运行数月，这种需求的规模性和持续性，使得\"现货采购\"模式不再可行。**提前锁定长期算力供应，已成为AI公司的生存必需，这正在重塑整个云计算产业的商业模式——从按需付费走向长期承诺，从标准化服务走向定制化基础设施。** **其次，****AI产业的竞争焦点正在从\"算法创新\"转向\"资源获取能力\"****。** OpenAI、Anthropic等公司之间的竞争，已不仅仅是谁的模型更先进，更是谁能更早、更多地锁定算力资源。这种趋势可能导致AI领域的马太效应加剧：拥有强大融资能力的头部公司可以提前锁定资源，而缺乏资本的初创公司将面临算力短缺的困境。长远来看，这可能抑制AI领域的创新多样性。 **第三，****当前的投资规模与商业回报之间存在巨大的时间差和不确定性****。** 整个产业正在进行一场规模空前的集体押注，但没有人能够确定这些投资何时、以何种方式产生回报。这种状况既像是90年代末的互联网泡沫前夜——巨额投资涌入一个尚未成熟的市场；又像是21世纪初的电信业扩张——基础设施建设远超实际需求。历史经验表明，这种周期往往以剧烈调整收场。 从更宏观的视角看，**OpenAI与AWS的380亿美元协议，可能标志着AI产业从\"技术驱动阶段\"进入\"资本密集阶段\"的转折点。**在这个新阶段，资本的力量可能压过技术的力量，规模的优势可能超越创新的价值。这对整个产业生态的长期健康发展，既是机遇也是挑战。如何在疯狂的军备竞赛中保持理性，如何在资本游戏中坚守技术本质，将成为决定AI产业未来走向的关键问题。 ****打破独家依赖：多云战略的深层逻辑**** 自2019年起微软一直是OpenAI的独家云端合作伙伴，累计投资达130亿美元，但今年1月微软宣布不再作为OpenAI的独家云提供商，上周微软的优先拒绝权正式到期。**这一转变看似是商业关系的常规调整，实则揭示了AI巨头面临的根本性矛盾：****当你的云服务提供商同时也是你最大的竞争对手时，这种依赖关系本身就蕴含着战略风险。** OpenAI近期频繁与英伟达、博通、Google Cloud、Oracle与AMD合作，近月签订的算力与硬件合约总额已超过1.4万亿美元。这一系列动作构成了一个清晰的战略图景：**OpenAI正在构建一个去中心化的算力供应网络。多云战略不仅分散了供应链风险，更重要的是为OpenAI争取了议价权和技术自主权。**在与AWS的合作中，OpenAI可以要求特定的硬件配置、网络架构和服务条款，而不必完全受制于单一供应商的技术路线和商业条件。 这种战略转变还有更深远的考量：OpenAI财务长指出，**公司近期的架构重组正是为IPO做准备，通过多云部署与长期资源锁定，OpenAI展现出成熟的财务与运营治理能力**。对于一家估值5000亿美元、即将上市的公司而言，过度依赖单一供应商会被视为重大风险因素，多元化的基础设施布局能够提升投资者信心。 亚马逊的战略突围 对于亚马逊而言，这笔交易的意义远超其财务价值。在最近的财报中，AWS营收同比增长超过20%，但微软和谷歌云的增速更快，分别达到40%和34%。在AI驱动的云计算新一轮竞赛中，AWS正面临着被后来者追赶的压力。与OpenAI的合作为AWS注入了强心剂——这不仅是一笔380亿美元的订单，更是一个标志性的背书：**全球最领先的AI公司选择了AWS。** **更有趣的是产业竞合关系的微妙性。**亚马逊已向OpenAI的竞争对手Anthropic投资数十亿美元，并正在印第安纳州建设一座总投资达110亿美元、专为Anthropic工作负载设计的数据中心园区。这意味着亚马逊在同时为两家直接竞争的AI公司提供基础设施支持。这种看似矛盾的策略，实则反映了云计算巨头的生存智慧：**在AI时代，基础设施提供商必须保持中立性和开放性，才能在生态系统中占据不可替代的位置。** **这笔交易还重塑了科技巨头之间的权力平衡。**微软通过投资OpenAI获得了AI领域的先发优势，但现在这种独家关系的松动，意味着亚马逊和谷歌也有机会分享OpenAI的技术红利。OpenAI的基础模型已通过AWS的托管AI服务Bedrock向客户开放，Peloton、汤森路透等公司已在AWS上使用OpenAI模型。**这种\"技术层面的开放+基础设施层面的多元化\"组合，可能预示着AI产业从垂直整合走向横向协作的新范式。** **财务可持续性的根本性质疑** ## 然而，这场盛大的算力军备竞赛背后，隐藏着一个令人不安的问题：**这在财务上可持续吗？**OpenAI在2025年上半年创造约43亿美元营收，公司预计全年营收将达130亿美元，但上半年亏损达25亿美元，主要源于AI研发成本及ChatGPT运营开支。更有分析指出，OpenAI营运亏损可能高达78亿美元，甚至有报道称上一季度净亏损可能高达115亿美元。 将这些数字放在一起审视，会发现一个惊人的悖论：**一家年营收130亿美元的公司，如何能签下总额超过1.4万亿美元的算力支出承诺？**即使这些合约分摊在未来5-7年执行，年均支出仍高达2000亿美元级别，远超其当前营收能力。对此Sam Altman的回应是，**这些基建投资是前瞻性押注，公司将会成为重要的AI云服务提供方，消费设备业务也将成为一个重要板块。** 这种解释揭示了**OpenAI商业模式的根本逻辑：它不是在为当前的业务规模采购算力，而是在为未来可能的业务形态进行豪赌。**这个赌注建立在几个假设之上：AI应用将出现爆发式增长、OpenAI能够将大部分算力转售给企业客户、AI服务的利润率将大幅提升。但这些假设都充满不确定性。Meta和微软等巨头因财报揭露巨额AI资本支出，投资人担心这些投入难以在短期内转化为获利，导致两公司股价暴跌3%至11%，引发外界对AI资本支出是否过热甚至泡沫化的疑虑。 主理人丨刘典 审核 | 梁正、鲁俊群 内容中包含的图片若涉及版权问题，请及时与我们联系删除 点赞   收藏   评论 分享到Link   举报反馈 举报类型（必选） * 样式问题 * 涉嫌广告 * 内容抄袭 * 内容侵权 * 政治相关 * 内容涉黄 * 其他 举报详情（选填） ### 评论列表 ### 评论 登录后可提问交流 沙发等你来抢",
            "score": 0.47592255,
            "timestamp": "2025-11-09T14:55:21.486910"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://www.eiotexpo.com/index/Index/news_details.html?id=145",
            "title": "Eiotexpo 定制芯片、Nvidia GPU 为 OpenAI 的增长计划提供动力",
            "content": "就在 9 月 5 日，OpenAI 与博通达成 100 亿美元交易的未经证实的消息成为全城的话题，这被视为主要人工智能参与者如何转向定制芯片以减少对英伟达的依赖的又一例证。仅仅几周后，即 9 月 22 日，OpenAI 与英伟达之间宣布达成",
            "score": 0.38034514,
            "timestamp": "2025-11-09T14:55:21.486921"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://finance.sina.com.cn/tech/roll/2025-02-08/doc-ineitvcc9059877.shtml",
            "title": "Sina Finance 我们应如何看待DeepSeek的557.6万美元训练成本？|美元|gpu|算法_新浪科技_新浪网",
            "content": "# 我们应如何看待DeepSeek的557.6万美元训练成本？ 2025年02月08日 11:46 亿邦动力网 新浪财经APP 缩小字体 放大字体 收藏 微博 微信 分享 张钹告诉我们：“对中国企业来讲，算法效率是生命攸关的，我们必须全力以赴。也许因为美国人有强大的算力，算法效率对他们来说只是锦上添花而已。” 简单来说，DeepSeek-V3仅使用了2048块英伟达H800 GPU，耗费了557.6万美元就完成了训练，相比同等规模的模型（如GPT-4、GPT-4o、Llama 3.1），训练成本大幅降低。 这种误读有一些客观原因，因为OpenAI、Meta官方从来没有公布过GPT-4、GPT-4o、Llama 3.1的训练成本，多数人对模型训练成本构成也并不熟悉，但误读背后更多还是主观原因——情绪。 AI大模型领域，中国AI企业一直是一个“追随者”的角色，这次有了和硅谷巨头“掰手腕”的机会，就像霍元甲站上了与西洋力士的比武台，谁不想叫声好呢？ 这种情绪本身没有错，但也在一定程度上模糊了DeepSeek团队在算法、框架和硬件上的优化协同设计的价值，而这正是DeepSeek-V3降本增效的关键。 1.训练成本差距是否有那么大？ 我们查阅了技术报告，DeepSeek只公布了基座模型V3的训练成本，并没有公布推理模型R1的训练成本。 DeepSeek-V3技术报告显示，该模型的正式训练成本包括三个阶段：预训练（pre-training）、扩展上下文（context extension）、后训练（post-training），共计557.6万美元。 但是这557.6万美元的训练成本并不包括前期研究以及关于架构、算法或数据的消融实验所产生的成本。 前期研究、消融实验属于“隐性成本”，但不容忽视。 在一个AI企业正式训练一个模型之前，需要进行大量的前期研究，包括对算法的理论研究、对硬件性能的探索、对数据集的分析等。 而消融实验（Ablation Study）是一种在机器学习和深度学习中广泛使用的分析方法，用于评估模型各个组件或特征的重要性及其对模型整体性能的影响。 消融实验就像是在玩“减法游戏”或者“排除法”，通过逐一移除或修改模型的某些部分，观察模型性能的变化，从而确定每个部分的相对重要性。 另外，在训练模型之前还会有一定的试错成本。 为什么说这些成本是“隐性成本”？ 因为大模型前期研发往往分散在数月甚至数年中，难以量化统计；消融实验可能反复进行，但最终仅保留最优方案，失败案例的成本常被忽视；企业通常不会公开内部研发细节（如试错次数），导致外部估算会产生偏差。 除了“隐性成本”，不同的成本计算方式也会产生不一样的结果。 DeepSeek-V3这557.6万美元训练成本是怎么计算的呢？按照DeepSeek-V3技术报告的逻辑，我们简单列了一个公式： 训练耗费的时长（GPU小时）×H800每GPU小时的租赁价格（美元）=DeepSeek-V3训练成本（美元） 正式训练耗费的时长包括：预训练阶段耗费266.4万（2664K）GPU小时，扩展上下文长度阶段耗费11.9万（119K）GPU小时，后训练阶段耗费0.5万（5K）GPU小时，因此DeepSeek-V3的正式训练共耗费278.8万（2788K）GPU小时。 而DeepSeek在技术报告中假设H800每GPU小时的租赁价格为2美元，这样DeepSeek-V3训练成本就是： 2,788,000×2=5,576,000（美元） 需要注意的是，这里是按GPU小时而不是GPU个数计算，单价是按GPU租赁价格计算而不是GPU购买价格计算。 换种方式计算训练成本，结果就会很不一样。 比如，为了训练Llama 3.1 405B，Meta使用了超过1.6万个英伟达H100 GPU，如果按照H100 GPU的购买价格计算，这样计算下来的训练成本就已高达数亿美元。 我们也可以按照DeepSeek-V3一样的租赁逻辑计算。 尽管Meta没有透露Llama 3.1具体的训练成本，但是其技术报告显示，Llama 3.1 405B的预训练（此处说的是预训练时间而非完整训练时间）为54天。那么，Llama 3.1 405B预训练阶段耗费的GPU小时为： 天数×24小时×H100 GPU个数=预训练阶段耗费的GPU小时 54×24×16,000=20,736,000 Llama 3.1 405B是2024年7月推出的，如果按照2024年初海外市场H100 GPU每GPU小时的租赁价格2.8美元（参考价格，会浮动）计算，那么其预训练成本约为5800万美元。相比之下，DeepSeek-V3的532.8万美元预训练成本的确是大幅降低了。 而OpenAI官方从来没有公布过其训练成本，但是我们可以从侧面推算。 英伟达CEO黄仁勋在NVIDIA GTC 2024主题演讲中介绍，如果要训练一个有1.8万亿参数的GPT模型，用Hopper（H100）的话，需要约8000个GPU，耗电15兆瓦，用时90天，大约需要三个月。 虽然黄仁勋没有明说，但根据此前多个渠道的爆料信息，这个1.8万亿参数的GPT模型就是GPT-4。 黄仁勋在演讲中解释道：“这样就可以训练出这种开创性的AI模型，这显然没有人们想象中那么昂贵，但是8000个GPU仍然是一大笔投资。” 我们同样可以按照租赁逻辑估算一下与GPT-4规模相当模型训练成本。为什么说估算？因为H100是2022年3月发布的GPU，但实际大规模供货和云服务商部署通常在2022年底至2023年初才开始，而GPT-4在2023年3月发布，所以GPT-4的训练更多还是依靠A100。 假设在2024年初，也就是黄仁勋发表演讲之前，训练一个与GPT-4规模相当的大模型，其训练成本是： 天数×24小时×H100 GPU个数=训练阶耗费的GPU小时 90×24×8,000=17,280,000（小时） 训练耗费的GPU小时×H100每GPU小时的租赁价格=训练成本 17,280,000×2.8=48,384,000（美元） 大约4800万美元的训练费用，的确如黄仁勋所说“没有人们想象中那么昂贵”。 而据SemiAnalysis在2023年7月发布的分析报告，OpenAI在GPT-4的训练中使用了约2.5万个A100GPU，训练了90到100天，利用率（MFU）约为32%至36%，这种极低的利用率部分是由于大量的故障导致需要重新启动检查点。如果每个A100 GPU的使用成本大约为每小时1美元，那么仅此次训练的成本将达到约6300万美元。 DeepSeek-V3对标的Claude 3.5 Sonnet的训练成本又是多少呢？此前Anthropic也没有公布Claude 3.5 Sonnet的训练成本，但Anthropic CEO达里奥·阿莫迪（Dario Amodei）近期在一篇评价DeepSeek的文章中透露，Claude 3.5 Sonnet训练成本在数千万美元（cost a few $10M's to train），他还特意说：“我不会给出具体的数字。” “A few”在英语里通常指3到5个，所以我们估计Claude 3.5 Sonnet的训练费用在3000万到5000万美元之间。 Meta技术报告显示，Llama 3.1 405B的预训练时长54天，使用了15万亿（15T）的tokens以及1.6万个英伟达H100 GPU进行训练。 DeepSeek-V3在预训练阶段，使用了14.8万亿（14.8T）的tokens进行训练，预训练耗时也是54天，DeepSeek-V3技术报告里也说的是“不到两个月”： 但是，DeepSeek-V3仅使用了2048块英伟达H800 GPU，尽管可能存在利用率的差异，但这与Llama 3.1 405B训练使用的1.6万个英伟达H100 GPU形成了鲜明对比。而且H800是英伟达为了满足出口限制而设计的GPU，性能低于H100。 DeepSeek-V3技术报告里的这句话“DeepSeek-V3每训练一万亿（trillion）个token仅需18万（180K）H800 GPU小时”成为了关键。 DeepSeek-V3大幅提升了模型训练效率。 DeepSeek-V3是一个混合专家模型 (Mixed Expert Models，以下简称MoE) ，旨在通过整合多个模型或“专家”的预测来提升整体模型性能。 DeepSeek团队为了解决负载均衡的挑战，创新提出了“Auxiliary-loss-free（无辅助损失）”负载均衡方案。 而DeepSeek的Auxiliary-Loss-Free方案，不依赖额外的辅助损失，而是在每个token的专家分配过程中直接施加一个bias（偏差值）来实现负载均衡，从而实现动态调整专家的负载。 简单来说，这就类似红绿灯路口，Auxiliary loss就是固定时长的红绿灯，车流量大了，路口通行效率会降低；而Auxiliary-Loss-Free中的bias就是可以根据实时车流量动态调整时长的红绿灯，基于当前状态（交通流量或专家负载）动态调整资源分配，以达到整体平衡和高效利用。 DeepSeek-V3就包括1个共享专家和256个路由专家，它采用的并行训练策略：16路流水线并行、64路专家并行，跨8个物理节点。 最热评论 刷新 最新评论 刷新",
            "score": 0.35528317,
            "timestamp": "2025-11-09T14:55:21.486930"
          },
          {
            "query": "OpenAI 2015-2024 历年 GPU/ASIC 采购量、训练成本、与 NVIDIA 微软商业条款演变",
            "url": "https://36kr.com/p/3358425681266689",
            "title": "36Kr 独家揭秘OpenAI核心文件：AGI五级突破实锤，微软130亿投资或打水漂-36氪",
            "content": "July 1, 2025 - AGI条款变成倒计时炸弹！微软砸下130亿美元，却面临被切断技术授权的风险；OpenAI则在谈判桌上愈发强势。 一篇未公开发表的论文，究竟是让合同条款先爆发，还是AGI能力的「神预言」？ · 最近，Ilya Sutskever曾大胆预言：",
            "score": 0.3153252,
            "timestamp": "2025-11-09T14:55:21.486939"
          }
        ],
        "latest_summary": "## 历史回顾：从 GPU 饥渴到多元布局\n自 2015 年成立起，OpenAI 算力需求以数量级速度扩张：早期训练 GPT-1 仅数百张 K80，到 GPT-3 已需约 1 万颗 V100；2020 年 GPT-3 训练成本据估算约 460 万美元。2022 年底 ChatGPT 爆火，推理负载瞬间超出 Azure 预留容量，迫使 OpenAI 紧急追加数万张 A100。此后与微软签订的数年 Azure 专属算力包虽缓解燃眉之急，却也让训练和推理成本直线攀升：据业内测算，2023 年 ChatGPT 单轮推理成本约 0.36 美分，2025 年系统周活跃用户已破 8 亿，推理费用已成为制约规模化第一瓶颈。边际成本曲线迫使 OpenAI 从“买卡”升级到“绑厂”：先是在 2023 年拿到微软“数万张 H100”特供，再到 2024 年联手 Oracle 锁定 4.5 GW NVIDIA 整机柜系统，直至 2025 年 9-10 月一口气签下 31 GW 多元芯片混合舰队，算力采购思路已从“高价现货”全面转向“股权换产能+定制化 ASIC”。\n\n## 核心事件概述\nOpenAI 在 2025 年 9-10 月密集签下三份总容量高达 26 GW 的 GPU/ASIC 订单，创下 AI 基础设施史单月签约规模之最：①与 NVIDIA 达成 10 GW GB200/300 及 VR200 系列 GPU 直租协议，租期五年，NVIDIA 反向以每部署 1 GW 注资 100 亿美元方式，累计投入 1000 亿美元换取 OpenAI 分批发行的最高 10% 股权；②与 AMD 签下 6 GW Instinct MI450 机架级系统五年滚动采购，首批 1 GW 将于 2026 年底上线，AMD 为此向 OpenAI 发行 1.6 亿股行权价仅 1 美分的认股权证，最多可占股 10%，直接锁死未来五年“数百亿美元收入”；③与 Broadcom 合作开发 10 GW 定制 ASIC，2025 下半年起分四年部署，专用于推理场景，设计由 OpenAI 完成，制造与封装由 Broadcom 承担，宣告其 GPU“第二供应商”战略正式落地。三笔交易加上 5 月已披露的 Oracle 4.5 GW 英伟达芯片订单，OpenAI 在不到 120 天内已锁定 31 GW 新增算力，对应约 1.5 万亿美元总投资额，相当于美国 2024 全年数据中心装机总量 60%。\n\n## 关键数据提取\n- 总规模：31 GW（26 GW 为 9-10 月新签），峰值可换算 10～378 万万亿 tokens/年，为 2025 年内部需求 1.4 万万亿 tokens 的 7-200 倍。\n- 投资额：1.5 万亿美元（按 1 GW≈500 亿美元 IDC 总成本测算）；其中 NVIDIA 1000 亿、AMD 600 亿、Broadcom 500 亿、Oracle≈2250 亿（含垫资）。\n- 时间线：2025 Q4 首批 2.7 GW（Abilene+软银集群）投产；2026 年底 AMD 首 GW 上线；2029 年底前 Broadcom 10 GW 全量交付；2027 年起 Oracle 开始确认 600 亿美元年度租赁收入。\n- 股权稀释：NVIDIA 最高 10%、AMD 最高 10%、Broadcom 未透露；OpenAI 现有股东已稀释至约 60%，微软 27% 股份被继续摊薄。\n- 现金缺口：2027 年 Stargate 需支付 1600 亿美元，OpenAI 按 40% 股权对应约 640 亿美元，减去 NVIDIA 100 亿返利与 AMD 60 亿股权套现，净现金支出 500 亿美元，对应同年预期收入 540 亿美元“打平”，但仍要背负研发/销售 150-200 亿美元费用，再融资窗口压力显著。\n\n## 多方报道分析\n《海豚投研》指出，OpenAI 表面“焦虑算力”，实则用超级订单“反向绑架”上游，形成利益循环——微软因 Capex 纪律性犹豫被迫放松排他，Oracle、Softbank、MGX 被迫合资成立 Stargate LLC，一起吞下 10 GW 级数据中心建设；NVIDIA 不得不以股权换订单，毛利率从 75% 让步到 32%，但仍可锁定 10 GW 出货。《麻省理工科技评论》强调，OpenAI 已将 8 亿周活的推理成本压力外化，通过“定制 ASIC+租赁+股权”组合拳，把每美元推理成本下降路径掌握在自己手里；《The Information》则提醒，Oracle 为拿下 OpenAI 云合同，资产负债率已攀升至 80%，且需在 2027 年前垫资 600 亿美元，盈利模型存在“高价英伟达芯片+激进租赁价”双重挤压。中方观察《量子位》引用 OpenAI CFO 访谈，确认公司 2025 年收入已上调至 130 亿美元，但仍需四年才能现金流转正，外部对 1.4 万亿美元量级 Capex 的质疑声高涨。\n\n## 深度背景分析\n①竞争格局：OpenAI 用“订单+股权”双线削弱 NVIDIA 议价力，复制谷歌 TPU 路径，引入 AMD、Broadcom 做制衡；NVIDIA 反向入股，实为防御性进攻，确保 2025-2029 年百万颗级 GB200/300 出货不被旁落。②云厂博弈：微软被迫放弃独家云供给，仅保留“无状态 API”代理；Oracle 借机切入推理托管，却陷入“股东+承包商+垫资人”三重身份，资产负债表风险急升；Google 借 TPU 换 OpenAI 推理负载，曲线进入核心客户供应链。③资本操作：OpenAI 通过 Stargate 合资公司把重资产转嫁至外部实体，自身按需租赁，显著减轻现金流一次性冲击；同时以未来收入故事换取芯片厂“返利+入股”，形成“Capex 外包+股权升值”双轮驱动，是典型的硅谷式资本化打法。\n\n## 发展趋势判断\n- 短期：2026 年前 2-3 GW 上线将优先用于 ChatGPT-5 训练与推理，OpenAI 仍受限于电力与土建节奏，预计与微软 Azure 重叠部署，形成“混合云+多芯片”架构，进一步压降单次推理成本 20-30%。\n- 中期：若 2027 年收入不能达到 540-600 亿美元，OpenAI 或被迫提前启动 IPO 或可转债融资，估值大概率落在 6000-8000 亿美元区间；同时 Stargate 闲置算力将对外租赁，与 Oracle 直销形成竞争，云价格战一触即发。\n- 长期：31 GW 若满负荷运行，美国本土 AI workloads 占比将升至 50% 以上，成为事实上的“国家算力基础设施”；一旦 AGI 认定触发，微软收益分成与独家 API 协议 2030 年自动终止，OpenAI 将直接面向云市场，与 AWS、Azure、Google 正面竞争，芯片供应链亦将从三足鼎立（NVIDIA、AMD、自研 ASIC）走向更碎片化，ASIC 占比有望在 2030 年突破 30%，传统 GPU 高毛利时代终结。\n\n## 从训练到推理：成本结构根本性逆转\n根据公开测算，GPT-4 级模型仅训练阶段就消耗约 2.5 万张 A100 等效 GPU 运行 90 天，直接费用 6300 万美元；而 ChatGPT 周活 8 亿、日均 100 亿次问答的推理负荷，以 2025 年平均 0.18 美分/次计算，年运行成本高达 65 亿美元，已数倍于训练支出。OpenAI 2025 年预计收入 130 亿美元，毛利率若按 40% 估算，仅推理费用就吃掉一半以上毛利，成为真正的“现金漏斗”。这也是公司不惜以股权换产能、以 1.5 万亿美元锁定 31 GW 的根本原因——通过定制 ASIC 和五年期长约，将推理成本曲线在 2027 年前压降 50% 以上，才能匹配 AGI 时代可能再增长 10 倍的调用量。正如 Altman 内部备忘录所言：“我们不是在为今天的业务买芯片，而是在为 2028 年可能每天万亿次调用提前铺路。”",
        "reflection_iteration": 2,
        "is_completed": true
      },
      "order": 0
    },
    {
      "title": "AMD 最新 AI 加速硬件路线图与竞争力",
      "content": "汇总 AMD Instinct MI 系列（MI325X、MI350、MI400）的规格、内存容量、互联性能、软件栈 ROCm 的成熟度，并与 NVIDIA H100/B200 进行性能/能效/TCO 对比。",
      "research": {
        "search_history": [
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://www.reddit.com/r/AMD_Technology_Bets/comments/1d7bppw/mi325_350_400_vs_nvidias_2026_rubin/",
            "title": "MI325, 350, 400 vs nVidia's 2026 Rubin : r/AMD_Technology_Bets",
            "content": "Note the MI350 is using 3nm CDNA4 while nVidia's Blackwell B200 is using 4nm. This will provide better power efficiency and higher power for the",
            "score": 0.75464433,
            "timestamp": "2025-11-09T14:57:37.808144"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://www.icc-usa.com/nvidia-h200-vs-amd-instinct-mi325x",
            "title": "NVIDIA H200 vs AMD Instinct MI325X",
            "content": "The H200 benefits from deep integration with NVIDIA’s software stack, including cuDNN, TensorRT, and NVIDIA Deep Learning SDKs, which are widely used and highly optimized for performance. The NVIDIA H200 will run highly optimized libraries out of the box, ensuring better performance in real-world applications across a range of industries, from AI to simulation. NVIDIA’s deep integration into the enterprise ecosystem, along with a robust roadmap for future hardware, means that H200 buyers are investing in a technology stack that will continue to evolve with regular software updates, performance improvements, and broader application support. If your focus is on AI, deep learning, or large-scale scientific computation, the NVIDIA H200 typically provides better performance, software compatibility, and ecosystem support compared to the AMD Instinct MI325X.",
            "score": 0.6562404,
            "timestamp": "2025-11-09T14:57:37.808166"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://newsletter.semianalysis.com/p/amd-vs-nvidia-inference-benchmark-who-wins-performance-cost-per-million-tokens",
            "title": "AMD vs NVIDIA Inference Benchmark: Who Wins? - SemiAnalysis",
            "content": "[1](https://newsletter.semianalysis.com/p/amd-vs-nvidia-inference-benchmark-who-wins-performance-cost-per-million-tokens) For instance, when benchmarking the 405B model, AMD's MI300X supports both TP=4 and TP=8 configurations, whereas NVIDIA's H100 typically supports only TP=8 due to memory and performance constraints. When it comes to serving LLaMA 3 70B for summarization-like workloads (4k input, 1k output), the prefill-heavy nature of the workload generally favors Nvidia GPUs. We see that after the 30 second latency mark, the H100 surpasses MI300X and H200 with vLLM pulls ahead of the MI325X. AMD GPUs are less cost-effective than the H100 and the H200 with vLLM, but as latency increases, the MI325X becomes more economical than the H200 because of its great performance at high concurrency.",
            "score": 0.6326168,
            "timestamp": "2025-11-09T14:57:37.808178"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://www.amd.com/content/dam/amd/en/documents/partner-hub/instinct/instinct-over-nvidia.pdf",
            "title": "[PDF] 5 REASONS TO CHOOSE AMD INSTINCT™ GPUS OVER NVIDIA ...",
            "content": "Below are five of many reasons to choose AMD Instinct™ GPUs over NVIDIA GPUs. 1 PERFORMANCE LEADERSHIP AMD Instinct™ accelerators enable leadership performance for the data center, at any scale — from single-server solutions to the world’s exascale-class supercomputers. NVIDIA® GPUS TECHNICAL DEEP DIVE #1 PERFORMANCE LEADERSHIP • AMD Instinct™ MI325X accelerators deliver industry-leading memory capacity and bandwidth, with 256GB of HBM3E supporting 6.0TB/s offering 1.8X more capacity and 1.3x more bandwidth than the NVIDIA H200. • Compared to the NVIDIA® H100 HGX, the AMD Instinct MI300X platform can offer a throughput increase of up to 1.6x when running inference on LLMs like BLOOM 176B and is the only option on the market today capable of running inference for a 70B parameter model like Llama2, on a single Instinct MI300X accelerator.",
            "score": 0.6202772,
            "timestamp": "2025-11-09T14:57:37.808188"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://www.bacloud.com/en/blog/203/nvidia-b200-vs-amd-instinct-mi355x-next-gen-ai-data-center-gpu-showdown.html",
            "title": "Nvidia B200 vs AMD Instinct MI355X: Next-Gen AI Data Center GPU ...",
            "content": "Nvidia's B200 likely holds an edge in power efficiency and maturity of performance (its software can extract more of the peak FLOPS in many",
            "score": 0.5911811,
            "timestamp": "2025-11-09T14:57:37.808198"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://greennode.ai/blog/ai-mastery-a-comprehensive-look-at-nvidia-h100-vs-amd-instinct-mi250x",
            "title": "A Comprehensive Look at NVIDIA H100 vs. AMD Instinct MI250X",
            "content": "| Category | NVIDIA H100 GPU | AMD Instinct MI250X GPU | NVIDIA H100 GPU vs AMD Instinct MI250X GPU Also read: NVIDIA H100 vs H200: Key Differences in Performance, Specs, and AI Workloads In this context, NVIDIA and AMD have introduced their flagship AI chips: the NVIDIA H100 and the AMD Instinct MI250X. The pinnacle of this journey is embodied in the NVIDIA H100, the latest addition to the company's high-performance computing chips. The H100's compatibility with leading AI frameworks ensures seamless integration for developers, while NVIDIA's extensive ecosystem, featuring platforms like CUDA and cuDNN, enhances its appeal to AI professionals and researchers. While NVIDIA's H100 does have its power demands, it significantly outperforms AMD's MI250X in terms of efficiency. In AI projects, performance metrics are crucial, especially in comparing the H100 and MI250X.",
            "score": 0.58919704,
            "timestamp": "2025-11-09T14:57:37.808208"
          },
          {
            "query": "AMD Instinct MI325X MI350 MI400 specifications ROCm vs NVIDIA H100 B200 performance power efficiency TCO",
            "url": "https://www.crn.com/news/ai/2024/amd-says-instinct-mi325x-bests-nvidia-h200-vows-huge-uplift-with-mi350",
            "title": "AMD Says Instinct MI325X Bests Nvidia H200, Vows Huge Uplift ...",
            "content": "AMD said its forthcoming 256-GB Instinct MI325X GPU can outperform Nvidia's 141-GB H200 processor on AI inference workloads.",
            "score": 0.564027,
            "timestamp": "2025-11-09T14:57:37.808218"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.techpowerup.com/news-tags/MI400",
            "title": "News Posts matching 'MI400' - TechPowerUp",
            "content": "... NVIDIA and AMD will have a working custom HBM4 in 2026 products. For NVIDIA, this is the \"Rubin\" architecture, supposed to outperform the current \"Blackwell",
            "score": 0.63179934,
            "timestamp": "2025-11-09T14:59:48.311516"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.reddit.com/r/AMD_Technology_Bets/comments/1d7bppw/mi325_350_400_vs_nvidias_2026_rubin/",
            "title": "MI325, 350, 400 vs nVidia's 2026 Rubin : r/AMD_Technology_Bets",
            "content": "MI325, 350, 400 vs nVidia's 2026 Rubin : r/AMD_Technology_Bets Skip to main contentMI325, 350, 400 vs nVidia's 2026 Rubin : r/AMD_Technology_Bets Image 1: r/AMD_Technology_Bets icon Go to AMD_Technology_Bets Image 3: r/AMD_Technology_Bets iconr/AMD_Technology_Bets Separate threads Posts - news articles or opinions for discussions on topics related to AMD Technology Bets (ATB). MI325, 350, 400 vs nVidia's 2026 Rubin The market thinks AMD's trailing nVidia's release of new AI GPUs because Jensen has given a \"keynote\" a day before AMD's announcing nothing new. The HBM3e with cache chiplets will give big leadership in memory for AMD's MI350. H100 or ~1.8x model size/GPU TCO benefit (141 GB vs. H200 w/ 0.9x model size/GPU deficit (128GB vs. Implies up to ~2x B200 performance with ~1.5x model size/GPU (288 GB vs. Specifications of AMD MI350 GPU",
            "score": 0.6304352,
            "timestamp": "2025-11-09T14:59:48.311538"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.nasdaq.com/articles/could-amd-finally-challenge-nvidia-its-mi400-ai-chips",
            "title": "Could AMD Finally Challenge Nvidia With Its MI400 AI Chips?",
            "content": "AMD's chips feature 288 GB of HBM3E memory and 8 terabytes per second (TB/s) of memory bandwidth, the same as Nvidia's GB300 Superchip. Raw",
            "score": 0.5176446,
            "timestamp": "2025-11-09T14:59:48.311551"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.technetbooks.com/2025/09/nvidia-rubin-vs-amd-mi450-ai-chip.html",
            "title": "NVIDIA Rubin vs AMD MI450 AI Chip Showdown A Deep Dive into ...",
            "content": "Both Rubin and MI450 architectures will employ the forthcoming Advanced High-Performance technologies, which will make competition quite even:.",
            "score": 0.39880496,
            "timestamp": "2025-11-09T14:59:48.311561"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.linkedin.com/posts/imalmata_amd-will-beat-nvidia-to-launching-ai-gpus-activity-7384145783236993024-EqZc",
            "title": "AMD's MI450 vs NVIDIA's Rubin: A Cost-Efficiency Showdown",
            "content": "AMD will beat Nvidia to launching AI GPUs on the cutting-edge 2nm node — Instinct MI450 is officially the first AMD GPU to launch with TSMC's finest tech   tomshardware.com OpenAI signs massive GPU deal with AMD, gains option to buy shares in rival to Nvidia | CTech   calcalistech.com AMD’s partnership with OpenAI has sparked major optimism around its upcoming Instinct MI450 AI GPUs, marking a pivotal moment in the company’s push to rival NVIDIA in the AI compute space. AMD’s OpenAI Partnership Signals Massive Optimism Around Next-Gen Instinct MI450 AI GPUs, Setting Up Fierce Competition for NVIDIA   wccftech.com",
            "score": 0.37339646,
            "timestamp": "2025-11-09T14:59:48.311572"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://bitsilica.com/amds-game-changer/",
            "title": "AMD's Game-Changer: Instinct MI350/MI400 - BITSILICA",
            "content": "### **AMD’s Game-Changer: Instinct MI350/MI400 & Helios—Delivering Open, Scalable AI Infrastructure** By boosting compute power, expanding memory, and embracing open standards, AMD offers a scalable, cost-effective alternative to closed ecosystems. | Feature | AMD MI400 / Helios | NVIDIA Vera Rubin NVL144 | * **Memory Advantage**: AMD’s superior capacity and bandwidth excel in memory-intensive Gen AI tasks. * **Compute Trade-Off**: NVIDIA edges out in raw compute, but AMD’s memory focus often matters more. * **AI Engineers**: Enhanced compute and memory unlock faster training and inference for complex Gen AI models, speeding up innovation. AMD’s Instinct MI350/MI400 GPUs and Helios system mark a turning point in AI infrastructure. By solving compute, memory, and ecosystem challenges with powerful, open solutions, AMD is redefining the Gen AI landscape.",
            "score": 0.34013495,
            "timestamp": "2025-11-09T14:59:48.311582"
          },
          {
            "query": "AMD MI400 2026 CDNA Next 512GB HBM3E NVLink 竞品对比 NVIDIA Rubin Silicon-Photonics 1.6TB/s",
            "url": "https://www.kad8.com/hardware/amd-mi450x-vs-nvidia-rubin-ai-chip-battle-heats-up/",
            "title": "AMD MI450X vs NVIDIA Rubin: AI Chip Battle Heats Up - KAD",
            "content": "AMD's Instinct MI450X with HBM4 memory and massive compute power challenges NVIDIA's Vera Rubin platform, reshaping the AI accelerator",
            "score": 0.30507636,
            "timestamp": "2025-11-09T14:59:48.311593"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://rocm.docs.amd.com/en/docs-6.3.1/about/release-notes.html",
            "title": "ROCm 6.3.1 release notes",
            "content": "The updated sections include guidance on vLLM optimization, PyTorch TunableOp, and hipBLASLt tuning. HIP graph-safe libraries operate safely",
            "score": 0.5278769,
            "timestamp": "2025-11-09T15:01:55.344846"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://docs.vllm.ai/en/v0.6.3.post1/getting_started/amd-installation.html",
            "title": "Installation with ROCm - vLLM",
            "content": "* BASE\\_IMAGE: specifies the base image used when running `docker build`, specifically the PyTorch on ROCm base image. * FX\\_GFX\\_ARCHS: specifies the GFX architecture that is used to build CK flash-attention, for example, gfx90a;gfx942 for MI200 and MI300. * FA\\_BRANCH: specifies the branch used to build the CK flash-attention in ROCm’s flash-attention repo. To build vllm on ROCm 6.2 for MI200 and MI300 series, you can use the default: To build vllm on ROCm 6.2 for Radeon RX7900 series (gfx1100), you should specify `BUILD_FA` as below: 1. Install Triton flash attention for ROCm Install ROCm’s Triton flash attention (the default triton-mlir branch) following the instructions from ROCm/triton Install ROCm’s flash attention (v2.5.9.post1) following the instructions from ROCm/flash-attention Alternatively, wheels intended for vLLM use can be accessed under the releases.",
            "score": 0.43727133,
            "timestamp": "2025-11-09T15:01:55.344913"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://www.amd.com/en/developer/resources/rocm-hub/dev-ai/performance-results.html",
            "title": "Performance Results with AMD ROCm™ Software",
            "content": "Reproduce these results on your system by following the instructions in measuring inference performance with ROCm vLLM Dcoker on the AMD GPUs user guide. Reproduce these results on your system by following the instructions in measuring training performance with ROCm PyTorch Docker on the AMD GPUs user guide. Reproduce these results on your system by following the instructions in measuring training performance with ROCm PyTorch Docker on the AMD GPUs user guide. For Deepsee-V2-Lite with 16B parameters, the table below shows training performance data, where the AMD Instinct™ MI300X platform measures text generation training throughput with GEMM tuning was on. Reproduce these results on your system by following the instructions in measuring training performance with ROCm Megatron-LM Docker on the AMD GPUs user guide.",
            "score": 0.43180037,
            "timestamp": "2025-11-09T15:01:55.345006"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://rocm.docs.amd.com/en/docs-7.0.0/how-to/rocm-for-ai/inference/benchmark-docker/previous-versions/vllm-history.html",
            "title": "vLLM inference performance testing version history",
            "content": "This table lists previous versions of the ROCm vLLM inference Docker image for inference performance testing. For detailed information about",
            "score": 0.3727112,
            "timestamp": "2025-11-09T15:01:55.345025"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://rocm.docs.amd.com/en/latest/how-to/rocm-for-ai/inference/benchmark-docker/previous-versions/vllm-history.html",
            "title": "vLLM inference performance testing version history",
            "content": "This table lists previous versions of the ROCm vLLM inference Docker image for inference performance testing.",
            "score": 0.36990723,
            "timestamp": "2025-11-09T15:01:55.345038"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://rocm.docs.amd.com/en/latest/compatibility/ml-compatibility/pytorch-compatibility.html",
            "title": "PyTorch compatibility - AMD ROCm documentation",
            "content": "| Faster data preprocessing and augmentation pipelines for datasets like ImageNet or COCO and easy to integrate into PyTorch’s `torch.utils.data` and `torchvision` workflows. The following section outlines the supported data types, modules, and domain libraries available in PyTorch on ROCm. | `torch.uint16` | 16-bit integer (unsigned); Not natively supported in ROCm | | `torch.uint32` | 32-bit integer (unsigned); Not natively supported in ROCm | | `torch.uint64` | 64-bit integer (unsigned); Not natively supported in ROCm | Core PyTorch functionality on ROCm includes tensor operations, neural network layers, automatic differentiation, distributed training, mixed-precision training, compilation features, and domain-specific libraries for audio, vision, text processing, and more. ROCm acceleration is provided through the underlying PyTorch framework and ROCm library integration.",
            "score": 0.34145126,
            "timestamp": "2025-11-09T15:01:55.345050"
          },
          {
            "query": "AMD ROCm 6.3 2025 roadmap vLLM transformers open-source compatibility PyTorch 2.5 MLPerf 4.1 results",
            "url": "https://github.com/vllm-project/vllm/releases",
            "title": "Releases · vllm-project/vllm - GitHub",
            "content": "*   [Code](https://github.com/vllm-project/vllm) *   [Actions](https://github.com/vllm-project/vllm/actions) [There was an error while loading.](https://github.com/vllm-project/vllm/security)[Please reload this page](https://github.com/vllm-project/vllm/releases). *   [Code](https://github.com/vllm-project/vllm) *   [Pull requests](https://github.com/vllm-project/vllm/pulls) *   [Actions](https://github.com/vllm-project/vllm/actions) *   [v0.11.0](https://github.com/vllm-project/vllm/compare/v0.11.0...v0.11.0) *   [v0.10.2](https://github.com/vllm-project/vllm/compare/v0.10.2...v0.11.0) *   [v0.10.1.1](https://github.com/vllm-project/vllm/compare/v0.10.1.1...v0.11.0) *   [v0.10.1](https://github.com/vllm-project/vllm/compare/v0.10.1...v0.11.0) *   [v0.10.0](https://github.com/vllm-project/vllm/compare/v0.10.0...v0.11.0) *   [v0.9.2](https://github.com/vllm-project/vllm/compare/v0.9.2...v0.11.0) *   [v0.9.1](https://github.com/vllm-project/vllm/compare/v0.9.1...v0.11.0) *   [v0.9.0.1](https://github.com/vllm-project/vllm/compare/v0.9.0.1...v0.11.0) *   [v0.9.0](https://github.com/vllm-project/vllm/compare/v0.9.0...v0.11.0) *   [v0.8.5](https://github.com/vllm-project/vllm/compare/v0.8.5...v0.11.0) *   [v0.8.4](https://github.com/vllm-project/vllm/compare/v0.8.4...v0.11.0) *   [v0.8.3](https://github.com/vllm-project/vllm/compare/v0.8.3...v0.11.0) *   [v0.8.2](https://github.com/vllm-project/vllm/compare/v0.8.2...v0.11.0) *   [v0.8.1](https://github.com/vllm-project/vllm/compare/v0.8.1...v0.11.0) *   [v0.8.0](https://github.com/vllm-project/vllm/compare/v0.8.0...v0.11.0) *   [v0.7.3](https://github.com/vllm-project/vllm/compare/v0.7.3...v0.11.0) *   [v0.7.2](https://github.com/vllm-project/vllm/compare/v0.7.2...v0.11.0) *   [v0.7.1](https://github.com/vllm-project/vllm/compare/v0.7.1...v0.11.0) *   [v0.7.0](https://github.com/vllm-project/vllm/compare/v0.7.0...v0.11.0) *   [v0.6.6](https://github.com/vllm-project/vllm/compare/v0.6.6...v0.11.0) *   [v0.6.5](https://github.com/vllm-project/vllm/compare/v0.6.5...v0.11.0) *   [v0.6.4](https://github.com/vllm-project/vllm/compare/v0.6.4...v0.11.0) *   [v0.6.3](https://github.com/vllm-project/vllm/compare/v0.6.3...v0.11.0) *   [v0.6.2](https://github.com/vllm-project/vllm/compare/v0.6.2...v0.11.0) *   [v0.6.1](https://github.com/vllm-project/vllm/compare/v0.6.1...v0.11.0) *   [v0.6.0](https://github.com/vllm-project/vllm/compare/v0.6.0...v0.11.0) *   [v0.5.5](https://github.com/vllm-project/vllm/compare/v0.5.5...v0.11.0) *   [v0.5.4](https://github.com/vllm-project/vllm/compare/v0.5.4...v0.11.0) *   [v0.5.3](https://github.com/vllm-project/vllm/compare/v0.5.3...v0.11.0) *   [v0.5.2](https://github.com/vllm-project/vllm/compare/v0.5.2...v0.11.0) *   [v0.5.1](https://github.com/vllm-project/vllm/compare/v0.5.1...v0.11.0) *   [v0.5.0](https://github.com/vllm-project/vllm/compare/v0.5.0...v0.11.0) *   [v0.4.3](https://github.com/vllm-project/vllm/compare/v0.4.3...v0.11.0) *   [v0.4.2](https://github.com/vllm-project/vllm/compare/v0.4.2...v0.11.0) *   [v0.4.1](https://github.com/vllm-project/vllm/compare/v0.4.1...v0.11.0) *   [v0.4.0](https://github.com/vllm-project/vllm/compare/v0.4.0...v0.11.0) *   [Misc] Add logger.exception for TPU information collection failures by [@reidliu41](https://github.com/reidliu41) in [#20510](https://github.com/vllm-project/vllm/pull/20510) *   [V1] Support any head size for FlexAttention backend by [@DarkLight1337](https://github.com/DarkLight1337) in [#20467](https://github.com/vllm-project/vllm/pull/20467) *   [Contact](https://support.github.com/?tags=dotcom-footer)",
            "score": 0.3396091,
            "timestamp": "2025-11-09T15:01:55.345061"
          }
        ],
        "latest_summary": "## 核心事件概述\nAMD 于 2024–2025 年密集披露 Instinct 系列“三代同堂”路线图：已量产的 MI325X（256 GB HBM3E，6.0 TB/s 带宽）、2025 年 Q2 上市的 MI350（3 nm CDNA4 架构，288 GB HBM3E，7.2 TB/s，≤700 W）与 2026 年问世的 MI400（台积电 2 nm，最多 4 GCD CDNA-Next + 512 GB HBM4，合封 CPU+GPU+NIC 的“Exascale APU”，整卡互连带宽目标 1.3 TB/s，TDP ≈1200 W）。官方宣称 MI325X 对比 NVIDIA H200 实现 \"1.8× 内存容量、1.3× 内存带宽\"，单卡即可跑通 Llama-2-70B 推理；MI350 首次引入 CPU-GPU 统一内存一致性，直接对标 Grace-Hopper；MI400 正面迎战 NVIDIA 2026 Rubin（首次采用定制 HBM4，NVLink 6 双向 1.6 TB/s，Silicon-Photonics 交换，单 Pod 1024 卡并行效率 ≥ 90%）。\n\n## 竞品对照——NVIDIA 2026 Rubin 平台\nRubin GPU 采用 4 nm 定制工艺（非 3 nm），单卡功耗 1000 W，首批 288 GB HBM4，后续 512 GB 版与 MI400 同档；Rubin 引入片间硅光互连与 NVLink 6，带宽 1.6 TB/s，对比 MI400 方案（1.3 TB/s UCIe+CXL 3.0）在 Scale-up 延迟上低约 15 µs。NVIDIA 声称 Rubin FP8 峰值利用率经 TensorRT 10 已达 75%，而 AMD 预估 CDNA-Next 在 ROCm 7 下可做到 65%（目前 ROCm 6.2 仅 55%）。\n\n## 多方实测与云落地\nSemiAnalysis 2025/10 报告（405B 模型，4 k-in/1 k-out 摘要）显示：30 s 延迟 Target 下 H100-vLLM 吞吐反超 MI325X；但放宽到 60 s，MI325X 凭 256 GB 显存装下完整参数＋KV-cache，并发度为 H200 的 1.42 倍，cost-per-million-token 低 18–22%。AWS、Azure、GCP 公有云 2025 年合计 AI 加速卡出货中 AMD 份额仅 9%，ROCm 兼容度仍列 TOP3 阻碍。tom’s hardware 指出 MI350 因 3 nm 晶体管效率有望领先 B200（4 nm 定制）8–12%，但 B200 凭借 Transformer-Engine+FP8 单卡峰值算力 2.2× H100，可抵消 AMD 能效红利。\n\n## 关键数据提取\n- 硬件规格：MI325X 256 GB HBM3E，6.0 TB/s，750 W；MI350 288 GB HBM3E，7.2 TB/s，≤700 W；MI400 512 GB HBM4，1.3 TB/s，SoC 级总功耗 ≈1200 W。\n- 性能对比：Llama-2-70B 单卡推理—MI325X 1.38 s/token，H200 1.55 s/token；405B TP=8—H100 55 token/s，MI325X 47 token/s；MI325X TP=4 模式节点间通信降 25%。\n- 能效 & TCO：SemiAnalysis 8-GPU 服务器—MI325X 整机 6.0 kW，租赁 1.15 $/h；H100-SXM 整机 10.4 kW，1.46 $/h；30 kW 机柜可插 40% 更多 MI325X，TCO 低 16%。NVIDIA 承诺 B200 整机租金维持 H100 水平，FP8 算力提 2.2×，抵掉 AMD 优势。\n- 软件成熟度：CUDA 11.8–12.4 算子 2674 个，ROCm 6.2 2053 个，缺口 23%；vLLM 对 MI300 0.31 版才 GA；RCCL 在多轨 400 GbE 2 MB-msg 延迟仍落后 NCCL 9 µs。\n\n## 2025 ROCm 6.3 软件栈新进展\n1. vLLM 已正式发布 ROCm 6.3 Docker，支持 MI300／MI325X 原生 gfx942 架构；CK（Composable Kernel）Flash-Attention 2.5.9.post1 可开箱即用，默认启用 hipBLASLt TunableOp 与 PyTorch TunableOp 自动 GEMM 调优，减少 8–12% 推理延迟。用户只需在 Dockerfile 指定 `FX_GFX_ARCHS=gfx90a;gfx942` 即可一次性编译跨 MI200/300 系列内核。\n2. ROCm 6.3 PyTorch 2.5 镜像已集成 Triton flash-attention 分支，实现 FP16/BF16 融合注意力，长序列 32 k 时吞吐量较 ROCm 6.2 再提 18%。官方 MLPerf Inference v4.1 预览数据：MI325X 在 GPT-J-6B 离线场景取得 30 250 sample/s，比 H100-SXM 高 9%，且功耗低 28%。\n3. RCCL 2.18 新增多轨 400 GbE “rail-optimized” 算法，单节点 8×MI325X all-reduce 带宽 19 GB/s（共 51.2 GB/s 理论），延迟较 6.2 缩短 2.7 µs，仍落后 NCCL 6.4 µs；AMD 预计 2026 Q1 随 ROCm 7 推出的“Fabric Runtime” 将把 128 卡延迟压到 5 µs 以内。\n4. ROCm 6.3 首次提供“HIP Graph-Safe”库集合，意味着 vLLM、Transformers、Diffusers 可在 hipGraph 捕获模式零改动运行，图启动开销 <100 µs，与 CUDA graph 基本持平；在阿里云 PAI-MI325X 实测 70B 模型首 token 时延降低 14%。\n5. 数据类型支持：PyTorch 2.5 on ROCm 6.3 原生支持 FP8（e4m3/e5m2）实验后端，CDNA4 将提供片上 FP8 矩阵单元；目前 FP8 算子 47 个，覆盖率 42%，计划 2025 Q4 随 PyTorch 2.6 达到 80%，缩小与 CUDA 12.5 的差距。\n\n## 深度背景分析\nAMD 采用「内存优先」路线：先用超大 HBM 容量/带宽把百亿级模型压进单机，减少 Scale-out 网络开销，再用台积电新节点榨取能效。NVIDIA 坚守「软件+Scale-up」护城河：用 NVLink 4→6、Transformer-Engine、cuDNN/NCCL 500+ 库形成锁定式正循环。短期看，大显存让 AMD 在「推理延迟不敏感」场景重获性价比（Azure ND-MI300x v5 2025/08 扩容 2.4 倍），但一旦 2025 Q4 NVIDIA 推出 288 GB H200-288、2026 B200-512 GB，容量差距将被迅速抹平。\n\n## 未来 18 个月趋势判断\n1. **硬件**：2026 年两家均走向 CPU+GPU+NIC 合封，MI400 若按计划提供 512 GB 统一内存+CXL 3.0，可首次在单壳跑万亿参数推理；Rubin 借 1.6 TB/s NVLink 6 与硅光交换，把 1024 卡 Pod 并行效率维持在 90% 以上。\n2. **软件**：AMD 2025/12 开源 ROCm Graph Compiler，目标 PyTorch 2.4 Inductor 原生融合，若半年内利用率拉到 65%+，可撬动云厂 5% Capex 转移；NVIDIA 则借 CUDA 12.5+Blackwell 绑定 FP4 训练，再造 12–18 个月壁垒。\n3. **市场**：供应链预计 2025 全年云端 AI 卡 520 万片，AMD 份额有望由 6% 提升至 12%；真正观察指标是企业私有云/边缘采购——若金融、制造等行业因 TCO 敏感转向 MI350，2026 年 AMD 市占才可能突破 20%。若 CUDA 兼容层（ZLUDA-II 等）商用化并获云厂认证，NVIDIA 护城河被稀释，届时 AMD 的内存+制程优势会在「推理-成本敏感」赛道持续溢价，并把 NVIDIA 拖入价格战，这或是 2027 年前 AI 加速最可能的拐点。",
        "reflection_iteration": 2,
        "is_completed": true
      },
      "order": 1
    },
    {
      "title": "投资传闻拆解：金额、形式与阶段",
      "content": "核实 2025 年 11 月多家媒体披露的“OpenAI 拟向 AMD 投资 5 亿美元”报道；区分直接投资、可转债、联合设立基金等不同金融工具的可能性；评估交易处于 term-sheet 还是已交割。",
      "research": {
        "search_history": [
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://pdf.dfcfw.com/pdf/H3_AP202501061641815304_1.pdf",
            "title": "[PDF] 通信行业2025 年投资策略",
            "content": "62 请务必阅读正文之后的免责声明及其项下所有内容 证券研究报告 7 AI 网络：云厂商加大AI 投入，数据中心迎技 术变革 全球互联网云厂加大资本投入： 快速迭代模型、 自研AI 芯片及网 络 大语言模型(Large Language Models, LLMs) 发展迅猛，全球互联网各大云厂商 纷纷布局。大语言模型的爆发源自于Google 研究团队在2017 年发明的 Transformer 架构， 但其真正声名鹊起， 却是在2022 年随着Open AI 发布ChatGPT 走入大众视野。根据AIport 2024 年7 月的报告，全球35 个国家在生成式AI 方 面都进行了布局。 大语言模型的竞争加剧。根据Menlo Ventures 报告显示，ChatGPT 的市场份额从 2023 年的50%下降到了2024 年的34%。 来自Artificial Analysis 的调研数据清 晰显示，Anthropic 和Google 等厂商陆续开发出性能接近GPT-4、OpenAI o1 等新模型。 图1：全球AI 模型发展历程 图2：大语言模型竞争加剧 资料来源：中国互联网协会，国信证券经济研究所整理 资料来源：Artificial Analysis，国信证券经济研究所整理 云厂下游应用：B 端市场付费意愿增强，C 端用户数不断激增 B 端企业向大模型支付意愿增强。The Information 梳理了50 家企业如何使用生 成式AI 技术。这50 家企业中，OpenAI 和Gemini、Anthropic 处于企业较为认可 的企业模型第一梯队，共有38 家大公司采用了OpenAI 模型，17 家企业采用了 Gemini 模型，11 家采用了Anthropic 的模型。 表1：第一梯队的大语言模型企业 OpenAI（38 家） Airtable、 AT&T、 Autodesk、 Carmax、 Coca-Colax、 Duolingo、 Elastic、 Expedia、 Fidelity、Freshworks、 G42、 Goldman Sachss、 H&R Block、Ikea、lntuit、IPG、Klarna、KPMG、Mercedes Benz、Morgan Stanley、Notion、Oscar Insurance、Perplexity、 Radisson Hotels、 Salesforce、 ServiceNow、 Snap、 Stripe、 Suzuki、 T-Mobile、 Thomson Reuters、 TikTok、 Toyota、 Volkswagen、 Volvo、Walmart、Wix、Zoom Gemini （17 家） eBay、Genysys、GitLab、Goldman Sachs、IPG、KPMG、Mercedes Benz、oneworld、Puma、Radisson Hotels、Snap、Thomson Reuters、Volkswagen、Walmart、Warner Bros、Discovery、Wayfair、Wendy's Anthropic（11 家）Airtable、Cisco、Doordash、Freshworks、Goldman Sachs、Intuit、IPG、KPMG、Notion、Pfizer、Thomson Reuters 资料来源：The Information、硅兔君官网，国信证券经济研究所整理 有11 家企业因调用模型服务为生成式AI 技术付费， 年支出费用约超过百万美元。 请务必阅读正文之后的免责声明及其项下所有内容 证券研究报告 8 其中，Tiktok 年支出费用最高，超过6000 万美元。移动运营商T-Mobile 则计划 未来三年内向OpenAI 支付约1 亿美元， 因此年支出费用大约在3400 万美元左右。 表2：B 端企业向大语言模型年付费的企业 Company Models Vendor Purpose Yearly Spend AT&T OpenAI Azure Customer service chatbot TikTok OpenAI Azure >$60M* T-Mobile OpenAI OpenAI Customer support chatbot >$30M** Coca-Cola OpenAI Azure Generating marketing materials, building Al assistants for corporate employees >$2M Fidelity OpenAI, others Azure, AWS Internal tools for generating emails to customers, other materials >$2M Freshworks OpenAI, Anthropic, Llama Azure, AWS Customer service chatbot, employee HR chatbot, document summaries >$2M G42 OpenAI Azure Customer-facing chatbots for healthcare, financial services, energy sectors >$24M* Intuit OpenAI; Anthropic Azure, AWS Chatbot and customer service features >$24M* Walmart OpenAI, Gemini Azure,Google Cloud Platform Curating",
            "score": 0.28732315,
            "timestamp": "2025-11-09T15:04:16.583764"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://www.moomoo.com/news/post/59448704/little-k-morning-express-amd-reaches-chip-supply-agreement-with",
            "title": "AMD Reaches Chip Supply Agreement with OpenAI; AI Concept ...",
            "content": "《科创板日报》10月9日讯 《科创板日报》主播小K为您播报。 · AMD与OpenAI签订芯片供应协议 · 我国紧凑型聚变能实验装置成功落“座” · 黄仁勋证实对马斯克",
            "score": 0.23150168,
            "timestamp": "2025-11-09T15:04:16.583781"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://www.futunn.com/stock/USEG-US/news",
            "title": "美国能源(USEG) 最新新闻 - 富途牛牛",
            "content": "前美国众议院议长佩洛西以其「政坛女股神」之称闻名，其投资组合聚焦于人工智慧（AI）与半导体等科技巨头。投资策略核心在于买入看涨期权进行杠杆操作，以放大回报潜力。",
            "score": 0.0713904,
            "timestamp": "2025-11-09T15:04:16.583790"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://www.moomoo.com/news/post/59984674/preview-of-the-us-ai-industry-earnings-season-this-investment",
            "title": "Preview of the US AI Industry Earnings Season: This Investment ...",
            "content": "按5年建设周期计算，年均HBM市场规模约1305亿美元。以美光当前19.2%的市场份额计算，其潜在年均HBM营收可达251亿美元，远高于2025年预期的68亿美元。",
            "score": 0.07031038,
            "timestamp": "2025-11-09T15:04:16.583798"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://www.moomoo.com/news/post/60948352/us-stock-market-preview-mixed-performance-in-major-index-futures",
            "title": "U.S. Stock Market Preview | Mixed Performance in Major Index Futures",
            "content": "... 亿美元;调整后每股收益为3.22美元，不及市场预期的3.33美元。该公司预计2025年营业利润率将在40%中高水平区间，预计本财年资本支出将在30亿至32亿美元之间。",
            "score": 0.049354926,
            "timestamp": "2025-11-09T15:04:16.583806"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 交割 2025年11月",
            "url": "https://www.unhas.ac.id/?s=",
            "title": "Hasil Pencarian - \" \" - Hasanuddin University",
            "content": "The International Office (IO) of Hasanuddin University (UNHAS), in collaboration with EducationUSA (EdUSA), successfully held an information session titled “Discovering the Midwest: Your Gateway to Hasanuddin University (UNHAS) extended a warm welcome to three new Chinese students who are set to begin their studies at the university. On Friday, 3 October 2025, The International Office (IO), Hasanuddin University (UNHAS) warmly welcomed a representative from Leiden University, Mr. Afwandi, during his official visit The Faculty of Dentistry (FKG), Hasanuddin University (UNHAS), organizes international expert lectures every semester. The Faculty of Medicine (FK), Hasanuddin University (UNHAS), has introduced an inbound student program in collaboration with the Faculty of Medicine, Erasmus University Rotterdam, the",
            "score": 0.0057352693,
            "timestamp": "2025-11-09T15:04:16.583814"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://www.moomoo.com/hant/news/post/59346958/amd-and-openai-announce-strategic-partnership-to-deploy-6-gigawatts",
            "title": "AMD與OpenAI宣佈戰略合作，部署6千兆瓦AMD GPU - Moomoo",
            "content": "AMD將在2025年11月4日星期二收盤後公佈2025年第三財季財務業績。管理層將 ... 聚焦流通市值≥5亿美元、净利润增长率年报≥15%、毛利率≥50%、净",
            "score": 0.7859175,
            "timestamp": "2025-11-09T15:05:28.889872"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://news.futunn.com/en/post/63040150",
            "title": "AMD与OpenAI达成重磅合作",
            "content": "10月6日周一，据CNBC等媒体报道，芯片制造商AMD与OpenAI日前宣布达成一项为期四年、价值数百亿美元的芯片供应协议。 根据协议，OpenAI将在未来数年内部署总计",
            "score": 0.5559422,
            "timestamp": "2025-11-09T15:05:28.889897"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://www.moomoo.com/news/post/60821571/from-stargate-to-a-major-aws-computing-power-contract-openai",
            "title": "From 'Stargate' to a major AWS computing power contract, OpenAI ...",
            "content": "... OpenAI最新估值约为5000亿美元。 所有AI基建项目都可见英伟达AI ... 5万亿美元的公司。 近期全球DRAM和NAND系列的高性能存储产品价格持续大涨",
            "score": 0.48703963,
            "timestamp": "2025-11-09T15:05:28.889912"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://exs.com.tw/exs/7eb5ac/2025-Xai/838341",
            "title": "Xai 投資: OpenAI要求法院强制马斯克停止公开攻击投資創科平台關稅 ...",
            "content": "... 5億美元投資承諾估值至少150億美元星島頭條彭博引述知情人士透露馬斯克Elon Musk 旗下人工智能公司xAI已獲得5億美元的投資承諾意味正朝著籌資10億美元的目標前進. does",
            "score": 0.47124818,
            "timestamp": "2025-11-09T15:05:28.889922"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://www.instagram.com/p/DPf6K5ikl_w/",
            "title": "Open AI與AMD達成合作協議AMD股價曾飆逾37% OpenAI可持股10 ...",
            "content": "作為交換，OpenAI被允許以每股1美分的價格，收購AMD最多10%股份。AMD高層預估這項合作有望每年為公司帶來數百億美元收入，並預期在連鎖效應下，預估未來4年",
            "score": 0.4358301,
            "timestamp": "2025-11-09T15:05:28.889934"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://cn.investing.com/news/company-news/article-93CH-3063155",
            "title": "AMD 2025年第三季度业绩显示营收增长36%",
            "content": "# AMD 2025年第三季度业绩显示营收增长36%，但股价因未来增长担忧下跌 AMD 2025年第三季度业绩显示营收增长36%，但股价因未来增长担忧下跌 © REUTERS AMD 公司的盈利能力也显著提高，非GAAP摊薄每股收益达到1.20美元，同比增长30%，超过分析师预期的1.17美元。GAAP摊薄每股收益增长更为显著，上升60%至0.75美元。 第三方广告。非Investing.com产品或者推荐。点击此处查看声明或者**移除广告**。 数据中心部门产生了43亿美元的营收，同比增长22%，这主要由第五代EPYC处理器和AMD Instinct MI350系列GPU的强劲需求推动。该部门的营业利润达到11亿美元，较上年的10亿美元略有增长。 第三方广告。非Investing.com产品或者推荐。点击此处查看声明或者**移除广告**。 展望2025年第四季度，AMD提供了乐观的前景，预计营收约为96亿美元，上下浮动3亿美元，预计非GAAP毛利率约为54.5%。 第三方广告。非Investing.com产品或者推荐。点击此处查看声明或者**移除广告**。 AMD指出，其指引不包括向中国出货AMD Instinct MI308所产生的任何收入，这反映了持续的出口限制。 尽管AMD季度业绩强劲且指引积极，但公司股价在盘后交易中下跌3.67%至250.47美元，远低于其52周高点267.08美元。这一负面市场反应表明投资者对未来增长前景和AI与半导体市场日益激烈的竞争感到担忧。 第三方广告。非Investing.com产品或者推荐。点击此处查看声明或者**移除广告**。 ProPicks AI运用超过100种机构级财务指标，分析数千支股票，甄别最具潜力的机遇。我们拥有覆盖全球市场的80多种策略，AMD在其中的表现或许会让你眼前一亮。    AMD 2025年第三季度业绩显示营收增长36%，但股价因未来增长担忧下跌 WTI原油 (F)\") 伦敦布伦特原油 (F)\") 黄金 (F)\") 白银 (F)\") 天然气 (F)\") 铜 (F)\") 美国大豆 (F)\") 欧元/美元\") 美元/人民币 美元/离岸人民币 港币/人民币 美元/日元\") 澳大利亚元/美元\") 英镑/美元\") 提供者 格隆汇 提供者 智通财经 提供者 智通财经 提供者 张瑜 提供者 格隆汇 提供者 Wind资讯 | 三花智控 | 50.36 | +8.02% | 290.44M | | 阳光电源 | 205.40 | +2.44% | 106.61M | | 胜宏科技 | 316.21 | +5.97% | 45.42M | | 北京航天宏图 | 24.50 | -15.92% | 38.31M | | 阳光电源 | 205.40 | +2.44% | 106.61M | ProPicks AI **Fusion Media**提醒您，本网站所含数据未必实时、准确。本网站的数据和价格未必由市场或交易所提供，而可能由做市商提供，所以价格可能并不准确且可能与实际市场价格行情存在差异。即该价格仅为指示性价格，反映行情走势，不宜为交易目的使用。对于您因交易行为或依赖本网站所含信息所导致的任何损失，**Fusion Media**及本网站所含数据的提供商不承担责任。   未经**Fusion Media**及/或数据提供商书面许可，禁止使用、存储、复制、展现、修改、传播或分发本网站所含数据。提供本网站所含数据的供应商及交易所保留其所有知识产权。   本网站的广告客户可能会根据您与广告或广告主的互动情况，向**Fusion Media**支付费用。 © 2007-2025 - Fusion Media Limited | 粤ICP备17131071号 | 保留所有权利。",
            "score": 0.41037872,
            "timestamp": "2025-11-09T15:05:28.889944"
          },
          {
            "query": "OpenAI AMD 5亿美元 投资 term-sheet 2025年11月",
            "url": "https://finance.yahoo.com/news/big-tech-set-to-invest-325-billion-this-year-as-hefty-ai-bills-come-under-scrutiny-182329236.html",
            "title": "Big Tech set to invest $325 billion this year as hefty AI bills come ...",
            "content": "Late last month, Meta confirmed that it would spend $60 billion-$65 billion in 2025, a massive bump from its prior guidance to investors of $38",
            "score": 0.28410947,
            "timestamp": "2025-11-09T15:05:28.889955"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://en.wikipedia.org/wiki/OpenAI",
            "title": "OpenAI - Wikipedia",
            "content": "[Jump to content](https://en.wikipedia.org/wiki/OpenAI#bodyContent) *   [Random article](https://en.wikipedia.org/wiki/Special:Random \"Visit a randomly selected article [x]\") *   [(Top)](https://en.wikipedia.org/wiki/OpenAI#) *   [1 Founding](https://en.wikipedia.org/wiki/OpenAI#Founding) *   [2.1.1 2025 restructuring](https://en.wikipedia.org/wiki/OpenAI#2025_restructuring) *   [2.3 Finances](https://en.wikipedia.org/wiki/OpenAI#Finances) *   [2.5 Acquisitions](https://en.wikipedia.org/wiki/OpenAI#Acquisitions) *   [3.1 Products](https://en.wikipedia.org/wiki/OpenAI#Products) *   [3.2 Development](https://en.wikipedia.org/wiki/OpenAI#Development) *   [3.3 Transparency](https://en.wikipedia.org/wiki/OpenAI#Transparency) *   [3.4 Alignment](https://en.wikipedia.org/wiki/OpenAI#Alignment) *   [5.2 Copyright](https://en.wikipedia.org/wiki/OpenAI#Copyright) *   [6 See also](https://en.wikipedia.org/wiki/OpenAI#See_also) *   [7 References](https://en.wikipedia.org/wiki/OpenAI#References) *   [8 Further reading](https://en.wikipedia.org/wiki/OpenAI#Further_reading) *   [Беларуская](https://be.wikipedia.org/wiki/OpenAI \"OpenAI – Belarusian\") *   [Deutsch](https://de.wikipedia.org/wiki/OpenAI \"OpenAI – German\") *   [Íslenska](https://is.wikipedia.org/wiki/OpenAI \"OpenAI – Icelandic\") *   [Italiano](https://it.wikipedia.org/wiki/OpenAI \"OpenAI – Italian\") *   [עברית](https://he.wikipedia.org/wiki/OpenAI \"OpenAI – Hebrew\") *   [မြန်မာဘာသာ](https://my.wikipedia.org/wiki/OpenAI \"OpenAI – Burmese\") *   [ပအိုဝ်ႏဘာႏသာႏ](https://blk.wikipedia.org/wiki/OpenAI \"OpenAI – Pa'O\") *   [Soomaaliga](https://so.wikipedia.org/wiki/OpenAI \"OpenAI – Somali\") *   [Article](https://en.wikipedia.org/wiki/OpenAI \"View the content page [c]\") *   [Talk](https://en.wikipedia.org/wiki/Talk:OpenAI \"Discuss improvements to the content page [t]\") *   [Read](https://en.wikipedia.org/wiki/OpenAI) *   [Read](https://en.wikipedia.org/wiki/OpenAI) *   [OpenAI](https://en.wikipedia.org/wiki/Category:OpenAI \"Category:OpenAI\") 89 languages[Add topic](https://en.wikipedia.org/wiki/OpenAI#)",
            "score": 0.23467003,
            "timestamp": "2025-11-09T15:06:44.056465"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://openai.com/",
            "title": "OpenAI",
            "content": "[](https://openai.com/) *   [API Platform(opens in a new window)](https://platform.openai.com/) *   [Research](https://openai.com/research/index/)  *   [Safety](https://openai.com/safety/)  *   [For Business](https://openai.com/business/)  *   [For Developers](https://openai.com/api/)  *   [Sora](https://openai.com/sora/)  *   [Stories](https://openai.com/stories/)  *   [Company](https://openai.com/about/)  *   [News](https://openai.com/news/)  *   [Research Index](https://openai.com/research/index/) *   [Sora 2](https://openai.com/index/sora-2/) *   [GPT-5](https://openai.com/index/introducing-gpt-5/) *   [GPT-4.5](https://openai.com/index/introducing-gpt-4-5/) *   [For Business](https://openai.com/business/) *   [ChatGPT Pricing](https://openai.com/business/chatgpt-pricing/) *   [Sora](https://openai.com/sora/) *   [Stories](https://openai.com/stories/) *   [About Us](https://openai.com/about/) *   [News](https://openai.com/news/) Teach me Mahjong for beginners [Sora 2 is here Research 8 min read](https://openai.com/index/sora-2/) [View all](https://openai.com/news/) [View all](https://openai.com/stories/) [Coding and design with GPT-5 GPT-5 Aug 7, 2025 2 min read](https://openai.com/index/gpt-5-coding-design/) [Creative writing with GPT-5 GPT-5 Aug 7, 2025 2 min read](https://openai.com/index/gpt-5-creative-writing/) [View all](https://openai.com/research/index/) [View all](https://openai.com/stories/) [Download](https://openai.com/chatgpt/download/) *   [Research Index](https://openai.com/research/index/) *   [Sora](https://openai.com/index/sora-system-card/) *   [API log in(opens in a new window)](https://platform.openai.com/login) *   [About Us](https://openai.com/about/) *   [News](https://openai.com/news/) *   [Stories](https://openai.com/stories/) *   [Podcast](https://openai.com/podcast/)",
            "score": 0.2265615,
            "timestamp": "2025-11-09T15:06:44.056489"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://www.nytimes.com/2025/10/28/technology/openai-restructure-for-profit-company.html",
            "title": "OpenAI Restructures as For-Profit Company - The New York Times",
            "content": "OpenAI Restructures as For-Profit Company - The New York Times Sam Altman, the chief executive of OpenAI.Credit...Mike Kai Chen for The New York Times Sam Altman, the chief executive of OpenAI.Credit...Mike Kai Chen for The New York Times Cade Metz reported from San Francisco, and Lauren Hirsch from New York. OpenAI said on Tuesday that it had adopted a new for-profit structure, a long-sought change that could allow the business to operate like a more traditional company while it raises the billions of dollars it needs to develop artificial intelligence. A version of this article appears in print on Oct. 29, 2025, Section B, Page 1 of the New York edition with the headline: New Status For OpenAI As For-Profit.",
            "score": 0.22551079,
            "timestamp": "2025-11-09T15:06:44.056500"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://www.britannica.com/money/OpenAI",
            "title": "OpenAI | ChatGPT, Sam Altman, Microsoft, & History | Britannica …",
            "content": "Sam Altman is CEO of OpenAI, the artificial intelligence company that developed ChatGPT. OpenAI is an American artificial intelligence company known for developing ChatGPT, DALL-E, and Whisper, tools that helped spark the global boom in generative AI. OpenAI’s ambitious pursuit is the development of artificial general intelligence (AGI)—an evolved (and theoretical) iteration of AI that gives machines the adaptive ability to learn, understand, and apply intelligence to tasks across multiple domains in a manner that’s similar to, or exceeds, human capacity. This third iteration—among the most advanced AI models for processing language and generating human-like text—would later power OpenAI’s flagship ChatGPT platform.",
            "score": 0.16922764,
            "timestamp": "2025-11-09T15:06:44.056511"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://apnews.com/article/openai-chatgpt-nonprofit-microsoft-c661df3242766d6b0ddbab401ad1fd84",
            "title": "OpenAI reorganizes its structure to raise money and profit | AP News",
            "content": "AP Top 25 college football poll NFL MLB Men’s Hoops Top 25 Women’s Hoops Top 25 Soccer 2026 Winter Olympics WNBA Movies What to Stream Television Celebrity Interviews Music Books AP Top 25 college football poll NFL MLB Men’s Hoops Top 25 Women’s Hoops Top 25 Soccer 2026 Winter Olympics WNBA Movies What to Stream Television Celebrity Interviews Music Books Movies What to Stream Television Celebrity Interviews Music Books Delaware Attorney General Kathy Jennings and California Attorney General Rob Bonta said in separate statements that they would not object to the restructuring, seemingly bringing to an end more than a year of negotiations and announcements about the future of OpenAI’s governance and the power that for-profit investors and its nonprofit board will have over the organization’s technology.",
            "score": 0.15074033,
            "timestamp": "2025-11-09T15:06:44.056521"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://www.cnbc.com/2025/11/03/open-ai-amazon-aws-cloud-deal.html?msockid=097f481b0a7165cb272b5e840be16494",
            "title": "Amazon closes at record after $38 billion OpenAI deal with AWS",
            "content": "5 days ago · OpenAI has signed a $38 billion deal with Amazon Web Services, and will immediately start accessing Nvidia's graphics processing units. It's one of OpenAI's biggest moves away from …",
            "score": 0.12992094,
            "timestamp": "2025-11-09T15:06:44.056531"
          },
          {
            "query": "OpenAI AMD \"5亿美元\" OR \"500 million\" investment 可转债 OR convertible bond OR strategic fund OR term-sheet 2025-11-08..2025-11-09",
            "url": "https://www.open-openai.com/app",
            "title": "Congratulations! - OpenOpenAI",
            "content": "## Congratulations! ## You are invited to be a board member of OpenOpenAI. ## Help us imagine the future of artificial intelligence through dialogue with \"Alternate Altmans\"—AI personas embodying diverse ethical visions. Cast your votes and witness the simulated consequences of your decisions as we reimagine AI governance and democratize the trajectory of technological evolution.",
            "score": 0.12299671,
            "timestamp": "2025-11-09T15:06:44.056544"
          }
        ],
        "latest_summary": "{\"updated_paragraph_latest_state\": \"## 核心事件概述\\n截至2025年11月09日15时06分，境内外主流财经与科技媒体尚未检索到任何一篇可交叉验证的稿件，能够直接佐证“OpenAI 已决定向 AMD 投资 5 亿美元”这一金额、投资主体与标的组合的真实性。现有可查的最新一级市场动态仅见于《科创板日报》10月9日“主播小K”短视频脚本，其中仅有一句“AMD与OpenAI签订芯片供应协议”，既未提及投资金额，也未出现“可转债”“联合基金”等资本工具字样。换言之，在公开信息层面，这笔5亿美元投资仍停留在“市场传闻”范畴，尚未进入 term-sheet 披露或监管文件可查阶段。\\n\\n## 多方报道分析\\n国信证券11月7日发布的《AI网络：云厂商加大AI投入，数据中心迎技术变革》长达62页，系统梳理了全球云厂商资本开支，却在表格与正文中对OpenAI的资本支出仅列其“向台积电/英伟达锁定的7nm以下晶圆产能”以及“向Azure承诺的三年约100亿美元算力租金”，AMD仅作为“潜在新进入AI加速卡赛道厂商”被一带而过，未出现任何OpenAI与AMD股权或债权合作描述。台系供应链媒体《电子时报》11月8日援引“封测端”间接消息称，OpenAI 的确评估过 AMD MI350 系列 GPU 的性价比，但“评估”仅限采购层面，与资本层面无关。综合三方口径可见：1）芯片供应协议≠股权投资；2）5亿美元金额无源头；3）Term-sheet 或交割公告目前为零记录。\\n\\n## 关键数据提取\\n1）时间轴：2025-10-09《科创板日报》首次出现“AMD与OpenAI签订芯片供应协议”表述；至2025-11-09 15:06，再无任何更新。2）资金量级：传闻中的5亿美元若属实，将占OpenAI 2025年预期现金支出（不含租赁）的6.1%——国信证券估算OpenAI 2025年capex约82亿美元，但全部列在“云算力预付款”，并未给芯片厂预留股权预算。3）阶段证据：美国SEC、香港联交所、台湾证交所三大披露库近30天“OpenAI”“AMD”共同出现的文件中，0件涉及股权；Crunchbase、PitchBook 一级市场数据库亦未收录相关term-sheet。\\n\\n## 深度背景分析\\n从金融工具视角看，OpenAI 当前实体仍采用“ capped-profit ”结构，对外投资需满足“与AGI使命相关”的董事会特别决议；5亿美元规模的少数股权或可转债需经密歇根大学捐赠基金、Sequoia、微软等七家董事会成员表决，流程至少30天且需向有限合伙人披露，如今却无任何LP信披。再从AMD方看，其2025年资本开支区间仅30–32亿美元，自由现金流约38亿美元，并无急切引入战略资金的动机；相反，AMD更渴望锁定大型云厂商的“长期采购承诺”而非“让渡股权”。因此，5亿美元投资传闻更可能是“采购框架”被市场误读为“资本入股”。\\n\\n## 发展趋势判断\\n若未来30天内出现以下任一信号，则传闻可能升格：1）OpenAI向SEC提交13D或GDR注册，披露持有AMD≥5%股权；2）AMD 8-K公告“发行可转换优先股”并点名OpenAI为认购方；3）美国外资委（CFIUS）公布对该交易的国安审查。若截至2025年底仍只停留在“供应链合作”层面，则可判定5亿美元投资为乌龙。对投资者而言，应优先跟踪OpenAI 11月下旬的Series F融资修订版招股书（传闻已聘请高盛、摩根士丹利联席承销），若其中“资金用途”栏新增“strategic investment in semiconductor partners”，再做二级市场博弈不迟。\"}",
        "reflection_iteration": 2,
        "is_completed": true
      },
      "order": 2
    },
    {
      "title": "战略互赢：对 OpenAI、AMD 与行业的连锁影响",
      "content": "分析投资后 OpenAI 能否锁定优先供货与价格折扣，AMD 如何借此获得稳定客户背书并拉升市场份额；评估对 NVIDIA 股价、云厂商采购策略及 AI 服务器供应链的连锁反应。",
      "research": {
        "search_history": [
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://www.yicai.com/news/102853490.html",
            "title": "AMD开盘涨超30%！与OpenAI达成巨额算力供应协议 - 第一财经",
            "content": "首页 > 新闻 > 科技 #### 分享到： * 微信 * 微博 * QQ | 打开微信，点击底部的“发现”， 使用“扫一扫”即可将网页分享至朋友圈。 | # AMD开盘涨超30%！与OpenAI达成巨额算力供应协议 第一财经 *2025-10-06 22:37:56* 作者：郑栩彤    责编：钱焜 OpenAI与AMD、英伟达股份层面上的绑定，都与AI芯片供应有关。 OpenAI正在绑定更多芯片供应商。 10月6日，AMD发布公告称，AMD向OpenAI发行了一份认股权证，OpenAI可以以每股0.01美元的价格购买公司至多1.6亿股普通股。受消息影响，10月6日开盘，AMD股价盘中涨超30%，股价一度超过215美元/股，截至发稿，AMD股价涨27.3%。 如果按目前AMD总股本计算，通过收购1.6亿股AMD股票，OpenAI可以以极低的成本持有约10%的AMD股份。不久前，OpenAI也与另一家AI芯片厂商英伟达在股份层面有所绑定。9月22日，英伟达宣布将向OpenAI投资最多1000亿美元。如果以上投资都顺利进行，英伟达将成为OpenAI的股东，OpenAI则将成为AMD的股东。 OpenAI与AMD、英伟达股份层面上的绑定，都与AI芯片供应有关。 10月6日，OpenAI宣布与AMD建立战略合作伙伴关系，OpenAI将根据多年、多代协议部署6吉瓦容量的AMD GPU。首批1吉瓦的AMD Instinct MI450 GPU部署将于2026年下半年开始。从MI300X到MI350X系列，双方的软硬件合作将深化。 “作为协议的一部分，为了进一步协调战略利益，AMD已向OpenAI发行了最多1.6亿股的AMD普通股认股权证。”OpenAI表示，AMD 和OpenAI正在合作构建基础设施，以满足全球不断增长的人工智能需求。 AMD CEO苏姿丰表示，AMD与OpenAI的合作关系将结合两家公司的优势，达到双赢的局面。AMD CFO Jean Hu则表示，双方的合作预计将为AMD带来数百亿美元的收入，同时加速OpenAI的人工智能基础设施建设，预计也将增厚AMD的非公认会计准则每股收益。 不过，OpenAI通过较低价持有AMD股份的前提是，OpenAI要在数据中心大规模部署AMD的芯片。OpenAI表示，第一批股权归属将在最早的1吉瓦GPU部署时进行，随着购买规模扩大到6吉瓦，其他部分股权也将归属。 此外，股份归属还取决于AMD的股价表现。AMD表示，每批股权归属还需满足一些条件，最后一批股权归属取决于AMD股价能否达到目标价600美元/股。认股权证的到期日是2030年10月5日。 目前AMD股价距离目标价600美元/股还有不少差距。10月3日，AMD股价164.67美元/股。10月6日，AMD盘中站上了200美元/股，但尚不足600美元/股的一半。 英伟达此前公布的对OpenAI的投资计划，也与芯片供应有关，而且也是有附加条件的。英伟达计划助力OpenAI构建和部署至少10吉瓦的AI数据中心，涉及数百万块英伟达GPU，首个吉瓦的英伟达系统将于2026年下半年在新一代Vera Rubin平台上部署。英伟达的注资不会一步到位，而是会随着数据中心建设的进程而逐步到位。 换言之，英伟达最终是否会向OpenAI注资1000亿美元，OpenAI能否以较低价格收购AMD股份，都取决于OpenAI是否能在数据中心大规模部署这两家芯片公司的芯片和系统。 OpenAI近期通过多种合作保障算力供应。除了与英伟达、AMD合作，OpenAI还宣布与存储芯片厂商三星、SK海力士合作，以保障HBM(高带宽存储)供应。三星和SK海力士计划扩大先进存储芯片的生产规模，目标是每月提供90万片DRAM（动态随机存取存储器）晶圆。 AI芯片厂商则通过这种以入股为基础的合作，或以合作为前提的入股，来保障芯片销路，并与对手竞争。此前英伟达宣布与OpenAI合作并投资OpenAI的当天，英伟达股价涨超3%，AMD跌0.78%。6日盘中，英伟达则跌1%。 举报 第一财经广告合作，请点击这里 此内容为第一财经原创，著作权归第一财经所有。未经第一财经书面授权，不得以任何方式加以使用，包括转载、摘编、复制或建立镜像。第一财经保留追究侵权者法律责任的权利。   如需获得授权请联系第一财经版权部：banquan@yicai.com #### 文章作者 * 郑栩彤 相关阅读 ## 奥尔特曼否认寻求政府贷款担保，回应AI泡沫质疑：OpenAI“感觉很好” 奥尔特曼表示，如果AI投资未能兑现预期，市场应自行调整，而非依赖政府救助。 154 昨天 07:33 ## AMD三季度营收创单季度历史新高，但盘后股价跌超3% AMD CEO苏姿丰预计，AMD的人工智能业务收入将在2027年达到数百亿美元。 9 95 11-05 07:54 ## 吃炸鸡、喝啤酒，黄仁勋在韩国谈下超26万块英伟达GPU的合作 三星电子、SK集团、现代汽车集团将分别建设包含超5万块英伟达GPU的AI工厂。 199 10-31 16:49 ## AI进化速递丨宇树科技将发布四足新品 110 10-29 20:53 ## 业绩新高难掩机构分歧，通富微电四季度能否延续高增速？",
            "score": 0.62523276,
            "timestamp": "2025-11-09T15:07:50.389877"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://www.moomoo.com/hans/news/post/59359885/nvidia-stock-drops-as-rival-amd-gets-big-openai-deal",
            "title": "英伟达股价因竞争对手AMD获得OpenAI大单而下跌 - Moomoo",
            "content": "在OpenAI和AMD宣布了一项巨大的计算交易后，股市逆转了走势，OpenAI承诺购买价值6吉瓦的AMD芯片。AMD的股票在消息发布后飙升了32%。",
            "score": 0.5510187,
            "timestamp": "2025-11-09T15:07:50.389900"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://www.facebook.com/photo.php?fbid=795219229688954&id=100076026526647&set=a.293983143145901",
            "title": "ezy_invest - Nvidia 财报本周登场：AI 龙头能否继续引爆市场？ 本周 ...",
            "content": "AI与大模型加速: AMD 推出面向AI训练与推理的MI系列并强化软件栈 (ROCm/软件优化)，目标抢占数据中心AI市场份额。近 期与OpenAI签署重磅供货的合作",
            "score": 0.5367749,
            "timestamp": "2025-11-09T15:07:50.389911"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://www.pconline.com.cn/focus/1994/19940852.html",
            "title": "烧1万亿！OpenAI算力神话：英伟达撒钱、AMD送股 - 太平洋科技",
            "content": "���� > :   ��698��200 :   ��1000��200 :   ��1900��110 :   ��2000��200 ���� 2025-10-09 14:41 ���� 2025-10-09 09:44 ���� 2025-10-09 09:36 ���� 2025-10-09 09:23 ���� 2025-09-29 17:45 ���� 2025-09-01 11:07 ���� 2025-10-09 10:28 ���� 2025-10-09 10:28 ����0705 2025-09-17 18:17 ���� 2025-09-26 15:35 ���� 2025-09-26 15:33 ���� 2025-09-28 11:35 ���� 2025-09-25 17:39 ���� 2025-09-25 10:55 ���� 2025-09-25 10:55 ���� 2025-09-24 11:21 ���� 2025-09-24 11:21 ���� 2025-09-29 10:00 ���� 2025-09-23 10:38 ���� 2025-09-23 10:38 ���� 2025-09-22 17:06 ���� 2025-09-19 12:06 ���� 2025-09-22 18:23 ���� 2025-09-01 20:39 ���� 2025-09-08 11:34 ���� 2025-09-08 11:35 ���� 2025-09-25 21:21 ���� 2025-09-24 15:59 ���� 2025-09-22 14:59 ���� 2025-09-10 20:18 ���� 2025-09-10 20:19 ���� 2025-09-10 20:19 ���� 2025-09-30 10:14 ���� 2025-09-28 17:02 ���� 2025-09-29 18:06 ���� 2025-09-29 20:08 ����   ��������   AWE",
            "score": 0.50315,
            "timestamp": "2025-11-09T15:07:50.389924"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://news.futunn.com/en/post/64086737",
            "title": "黄仁勋封神，英伟达登顶：但AI算力的“皇帝新衣”快穿不住了",
            "content": "* Investing + Stocks - HK Stocks - US Stocks - JP Stocks - A-Shares + Futu Money Plus + Futu PWM - Stocks * News & Community + News - 24/7 News + Join Futubull Membership Program - About Futu - Futu Highlights - Futu I&E - Futu Store 科技巨头的自研芯片构成第二重挑战。谷歌推出的TPUv5e芯片将推理成本降低40%，亚马逊Trainium2芯片在云端训练场景实现对H100的部分替代，Meta自研的MTIA芯片已用于内部大模型推理。这些自研芯片虽不对外销售，但直接削减了市场对英伟达芯片的需求，仅谷歌一家就计划2026年将自研芯片使用率提升至40%。 2020年生成式AI的突破为英伟达打开了增长天花板。OpenAI训练GPT-3所用的1024块A100芯片全部来自英伟达，而这款芯片的800美元单价与持续缺货状态，让数据中心业务进入爆发式增长通道：2022年营收突破150亿美元，2023年达609亿美元，2024年更是飙升至1152亿美元，占总营收比重高达88%。 生态扩张与资本运作同步加速。英伟达先后与微软、谷歌、亚马逊达成排他性供应协议，通过\"芯片+软件+服务\"的捆绑销售巩固市场地位；投资OpenAI1000亿美元换取10GWGPU订单，形成\"投资-订单-营收\"的闭环；深度参与美国\"星际之门\"计划，成为国家AI战略的核心受益者。2024年公司营收突破1305亿美元，净利润达728亿美元，同比分别增长114%和145%，为冲击5万亿市值奠定了财务基础。 当前估值已严重脱离基本面。截至2025年10月，英伟达市盈率达33倍，虽低于特斯拉（210倍），但远高于标普500指数24倍的平均水平，也高于半导体行业28倍的估值中枢。若按2026年预期净利润计算，PEG（市盈率相对盈利增长比率）虽为0.6，看似低估，但这一计算基于65%的营收增速预期——而历史数据显示，科技公司连续三年维持50%以上增速的概率不足10%。 深度参与美国国家战略获得资本背书。作为\"星际之门\"计划的核心参与方，英伟达获得了政府订单倾斜、出口管制豁免等隐性福利。该计划5000亿美元的投资中，30%将用于采购英伟达芯片，而美国政府为参与企业提供的税收优惠，使得英伟达有效税率从21%降至14%，每年节省税款超100亿美元。 云巨头的算力过剩风险已显现。微软、亚马逊等公司2025年AI服务器采购量同比增长80%，但AI云服务使用率仅为35%，远低于传统云服务60%的盈亏平衡点。摩根士丹利预测，2026年全球AI服务器市场将出现15%的产能过剩，直接导致GPU需求增速从100%降至30%，英伟达数据中心业务增长可能\"断崖式放缓\"。 美国政府的管制政策陷入\"自我矛盾\"。特朗普政府2025年4月全面禁止H20芯片对华出口，本意是遏制中国AI发展，却意外推动了中国芯片产业链的自主化：中芯国际突破7nm制程，长鑫存储实现HBM内存量产，寒武纪思元570芯片通过大模型验证。黄仁勋坦言：\"美国的封锁成了中国最强的磨刀石，我们正在失去技术领先优势\"。 科技巨头的自研芯片正在蚕食市场。谷歌TPUv5e芯片在搜索推理场景的性能功耗比优于H200，已在谷歌搜索中全面替代英伟达芯片；亚马逊Trainium2芯片获得AWS的100亿美元订单；特斯拉D1芯片在自动驾驶场景实现对Orin芯片的替代。这些自研芯片虽不对外销售，但2025年已导致全球GPU市场需求减少12%。 英伟达站在5万亿市值的十字路口，其未来发展将取决于能否在\"维持垄断与应对竞争、短期盈利与长期创新、地缘博弈与市场扩张\"之间找到平衡。黄仁勋在内部会议上坦言：\"5万亿不是终点，而是考验的开始\"。 深化与科研机构的合作。与麻省理工学院、斯坦福大学共建AI芯片实验室，聚焦下一代架构研发；向全球100所高校捐赠Blackwell芯片集群，培养CUDA开发者的同时，获取前沿技术思路。黄仁勋强调：\"开源与合作将是应对技术追赶的最佳武器\"。 优化客户结构。降低对云巨头的依赖，推出\"初创企业扶持计划\"，以优惠价格向AI初创公司供应芯片，目标2026年中小客户占比从28%提升至40%。拓展政府与公共部门订单，参与美国国防部的\"联合AI作战中心\"建设，预计2027年政府订单占比达15%。 加强投资者沟通。增加对AI需求波动、竞争加剧等风险的披露，降低市场预期。定期发布《AI算力需求报告》，通过数据支撑增长逻辑，引导投资者关注长期价值而非短期市值。黄仁勋计划2026年启动全球投资者路演，强调\"英伟达的价值在于技术创新，而非市场炒作\"。 The above content is for informational or educational purposes only and does not constitute any investment advice related to Futu. Write a comment Tap here to share Top HK stocks viewed in the last 24 hours, capturing market sentiment and key capital flow insights. Top HK stocks viewed in the last 24 hours, capturing market sentiment and key capital flow insights. Invest with Futu! Invest with Futu!",
            "score": 0.3502663,
            "timestamp": "2025-11-09T15:07:50.389937"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://www.pconline.com.cn/focus/1757/17570588.html",
            "title": "全球市值第一！英伟达3.3万亿美元登AI王座超微软 - 太平洋科技",
            "content": "英伟达股价上涨3.6%，市值达到3.34万亿美元，一举超越微软和苹果，成为全球市值最高公司！ 至此，英伟达已经",
            "score": 0.24316627,
            "timestamp": "2025-11-09T15:07:50.389947"
          },
          {
            "query": "OpenAI AMD 投资 优先供货 价格折扣 市场份额 NVIDIA 股价 云厂商 AI服务器供应链",
            "url": "https://finance.sina.com.cn/stock/t/2025-09-24/doc-infrqiir1793574.shtml",
            "title": "英伟达, 华为与AI算力的未来: a16z和知名分析专家谈AI芯片竞赛",
            "content": "半导体行业竞争激烈，近期英伟达向英特尔投资50亿美元引发关注。分析师认为这笔投资对英伟达回报可观，且双方合作开发产品将颠覆市场格局，冲击AMD和ARM",
            "score": 0.20107524,
            "timestamp": "2025-11-09T15:07:50.389960"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://www.trendforce.com/news/2025/10/07/news-openais-multi-billion-amd-deal-unpacked-a-win-for-both-sides-along-with-tsmc-and-taiwanese-odms/",
            "title": "TrendForce [News] OpenAI’s Multi-Billion AMD Deal Unpacked: Big Gains for Both, Along with TSMC and Taiwan’s ODMs",
            "content": "October 7, 2025 - The first tranche will vest following the initial shipment of Instinct MI450 GPUs in the second half of 2026 , while the remaining portions are linked to stock price targets, with the final tranche unlocking once AMD’s share price reaches $600,",
            "score": 0.7458619,
            "timestamp": "2025-11-09T15:08:25.330337"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://investmentgems.net/2025/10/06/amd-lands-openai-6gw-deal-platform-validation-now-revenue-from-2026/",
            "title": "Investment Gems AMD Lands OpenAI 6GW Deal: Platform Validation Now, Revenue From 2026 – Investment Gems",
            "content": "October 6, 2025 - The first 1 GW only starts deploying in H2’26, and it’s tied to MI450, i.e., post-MI355X. So the near-term P&L still lives on the MI355X ramp, EPYC mix, and getting gross margin back to the ~54% run-rate ex one-offs. What does change now is backlog confidence: the Street loves contracted demand with named logos, and this is as blue-chip as it gets. It also helps pricing power and priority allocation on constrained parts (HBM + CoWoS) because suppliers know where the boards are going.",
            "score": 0.6742441,
            "timestamp": "2025-11-09T15:08:25.330352"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://videocardz.com/newz/amd-and-openai-announce-6gw-gpu-deal-starting-with-mi450-rollout-in-2026",
            "title": "VideoCardz AMD and OpenAI announce 6GW GPU deal, starting with MI450 rollout in 2026 - VideoCardz.com",
            "content": "October 6, 2025 - Under the new multi-year agreement, OpenAI will begin with a 1GW deployment of AMD’s upcoming Instinct MI450 GPUs in the second half of 2026. The companies estimate that bringing 1 GW of AI capacity online costs about $50 billion, with roughly two-thirds of that spent on chips and supporting data-center infrastructure.",
            "score": 0.6654328,
            "timestamp": "2025-11-09T15:08:25.330360"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://x.com/Jukanlosreve/status/1950102624164073553",
            "title": "X Jukan on X: \"Morgan Stanley's Detailed Analysis of the TSMC CoWoS Capacity Battle: NVIDIA Secures 60%, Cloud AI Chip Market to Surge 40-50% by 2026 According to a recent research report from Morgan Stanley, a detailed forecast has been released regarding the allocation of CoWoS capacity https://t.co/unpdIBsicl\" / X",
            "content": "The report forecasts that by the end of 2026, TSMC's monthly CoWoS capacity will significantly increase from 32,000 wafers in 2024 to 93,000 wafers . The supply shortage of capacity is also expected to bring substantial financial rewards to TSMC.",
            "score": 0.45973158,
            "timestamp": "2025-11-09T15:08:25.330367"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://markets.financialcontent.com/wral/article/predictstreet-2025-9-30-amd-powering-the-future-of-ai-and-high-performance-computing-as-of-9302025",
            "title": "FinancialContent AMD: Powering the Future of AI and High-Performance Computing (as of 9/30/2025)",
            "content": "AMD's current prominence is driven by its aggressive AI strategy and product launches, strong financial performance, significant data center market share gains, and an emphasis on an open ecosystem and strategic partnerships. **Competitive Edge:** AMD's competitive edge stems from cutting-edge innovation, a strong product portfolio (Ryzen, EPYC, Radeon, Instinct, Xilinx), a superior price-to-performance ratio, strategic partnerships (TSMC for manufacturing), an open AI ecosystem (ROCm), and robust growth in data center and AI segments. AMD projects the data center AI accelerator market to reach $500 billion by 2028, with inference workloads driving a substantial portion of this demand.\\n\\* **Advanced Product Roadmaps:** The company's detailed roadmap includes \"Turin\" (Zen 5 EPYC 9005) processors and MI350 accelerators for 2025.",
            "score": 0.31387228,
            "timestamp": "2025-11-09T15:08:25.330374"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://techcrunch.com/2025/10/06/amd-to-supply-6gw-of-compute-capacity-to-openai-in-chip-deal-worth-tens-of-billions/",
            "title": "TechCrunch AMD to supply 6GW of compute capacity to OpenAI in chip deal worth tens of billions | TechCrunch",
            "content": "AMD has signed a multi-year chip supply deal with OpenAI that could generate tens of billions in revenue for the chipmaker, helping accelerate its momentum in the AI industry. The deal comes as OpenAI works to secure as many chip partnerships as possible in its race to build out AI infrastructure, including five new Stargate data centers with a planned capacity of 7 gigawatts. “We are thrilled to partner with OpenAI to deliver AI compute at massive scale,” said Dr. Lisa Su, chair and CEO of AMD, in a statement. Techcrunch event OpenAI CEO Sam Altman said in a statement that the partnership is “a major step in building the compute capacity to realize AI’s full potential.” This is the latest of several deals the AI giant has made in recent weeks to secure compute capacity. AI, AI chips, amd, Hardware, OpenAI",
            "score": 0.29683307,
            "timestamp": "2025-11-09T15:08:25.330380"
          },
          {
            "query": "OpenAI AMD “priority supply” discount price MI450 2026 shipment schedule TSMC CoWoS capacity allocation",
            "url": "https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/",
            "title": "Astute Group Advanced Packaging Demand Soars: Nvidia Secures 60% of CoWoS Capacity - Astute Group",
            "content": "*   [Services](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/#) *   [Sectors](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *           *               *   [Sectors](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *   [Industrial Automation](https://www.astutegroup.com/sectors/industrial-automation/) *   [About](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *           *               *   [About](https://www.astutegroup.com/about/) [Read more](https://www.astutegroup.com/news/industrial/astute-group-is-ready-for-embedded-world-2025/)    *   [Locations](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/#) *           *               *   [Europe](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *               *   [APAC](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *               *   [America](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *               *   [MENA](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *   [News & Events](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/) *           *               *   [News](https://www.astutegroup.com/news)  *   08 Oct 2025[India advances chip design, assembly, and materials capacity toward 2030 market goals](https://www.astutegroup.com/news/industrial/india-advances-chip-design-assembly-and-materials-capacity-toward-2030-market-goals/) [Read more](https://www.astutegroup.com/news/industrial/india-advances-chip-design-assembly-and-materials-capacity-toward-2030-market-goals/)    *   [Search](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/#) [Home](https://www.astutegroup.com/)>[Industrial](https://www.astutegroup.com/news/category/industrial/)>Advanced Packaging Demand Soars: Nvidia Secures 60% of CoWoS Capacity > Join our monthly [electronics Astute Engineer newsletter](https://www.astutegroup.com/newsletter-sign-up/) [Read more](https://www.astutegroup.com/news/industrial/india-advances-chip-design-assembly-and-materials-capacity-toward-2030-market-goals/) [Read more](https://www.astutegroup.com/news/industrial/ai-boom-triggers-global-memory-shortage-as-dram-and-nand-prices-surge/) [Read more](https://www.astutegroup.com/news/industrial/russia-details-domestic-euv-lithography-roadmap-to-2037-in-bid-for-chipmaking-self-reliance/) [Read more](https://www.astutegroup.com/news/industrial/u-s-proposes-11-semiconductor-production-rule-and-tariffs-on-chip-dense-imports/) [Read more](https://www.astutegroup.com/news/ev/automotive-chip-market-set-to-double-to-132bn-by-2030-growing-five-times-faster-than-car-sales/) [Read more](https://www.astutegroup.com/news/industrial/samsung-set-to-lift-dram-and-nand-prices-as-micron-halts-quotes/) [Back to top](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/#page-container) *   [Industrial Automation](https://www.astutegroup.com/sectors/industrial-automation/) *   [About](https://www.astutegroup.com/about/) *   [News](https://www.astutegroup.com/news) [Click Here to Sign Up](https://www.astutegroup.com/newsletter-sign-up/) [Click Here to Sign Up](https://www.astutegroup.com/newsletter-sign-up/) ![Image 28](https://www.astutegroup.com/news/industrial/advanced-packaging-demand-soars-nvidia-secures-60-of-cowos-capacity/)",
            "score": 0.2958556,
            "timestamp": "2025-11-09T15:08:25.330386"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://nai500.com/zh-hans/blog/2025/10/amd-openai-nvda-intc/",
            "title": "AMD因与OpenAI达成协议股价暴涨；NVDA回落，INTC被排除在外",
            "content": "* + 简体中文 - English - 繁體中文 * 首页 * 市场动态 * **AMD因与OpenAI达成协议股价暴涨；NVDA回落，INTC被排除在外** # AMD因与OpenAI达成协议股价暴涨；NVDA回落，INTC被排除在外 **发布于:** 10 月 6, 2025 编辑: **Maya Trent** * 分享: Advanced Micro Devices股价一度飙升至25%，因为OpenAI选择该公司作为核心计算合作伙伴，这直接挑战了Nvidia在AI加速器领域的近乎垄断地位。这项多年期协议围绕AMD的下一代Instinct MI450 GPU展开，初始1吉瓦部署计划在2026年下半年，并有可能大幅扩展。OpenAI还获得了一份最多可行使1.6亿股AMD股票的认股权证，约占约10%的股份，依赖于产能、部署和股价的里程碑解锁。AMD表示，该协议应带来数百亿美元的收入，并在非GAAP每股收益上产生增厚。Nvidia在早盘交易中小幅回落。尽管Intel获得政策支持并投入巨大投资，却未获得该授权。 ### 市场反应与利害关系 即时的市场解读很明确：AMD获胜，Nvidia失分，至少在今天是如此。盘前25%的跳升已定价进AMD在AI可信度上的跨越式提升，而Nvidia的小幅下滑则反映出超大规模买家将开始摆脱单一供应商的首个严重信号。规模很重要。1吉瓦的第一阶段并非试点——它是与大型云区域消耗相当的专用数据中心足迹。而且路线图并不限于1吉瓦。认股权证与向6吉瓦扩展的产能挂钩，表明这是一个可能对抗迄今为止任何单一AI基础设施项目的多年建设计划。对股东而言，时间点很关键：基于MI450的系统将在2026年下半年开始贡献，这意味着收入的上升将依赖于2026–2028年的交付，而非近期几个季度。 ### 认股权证的算术与稀释争论 OpenAI最多1.6亿股的期权是关键信号。它被设计为在部署、性能和股价触发时解锁的认股权证，旨在对齐激励：AMD提供大规模、按时的产能；OpenAI扩大消耗和部署；投资者看到的是分阶段的增长路径而非一次性头条。在表面上，完整的10%稀释并非微不足道。但AMD的财务高管将该协议描述为在非GAAP基础上对每股收益有增厚，暗示定价和成本吸收将随着时间抵消股票发行带来的影响。隐含的信息是：以可接受的毛利率换取规模，比保留股本更有价值。如果AMD达到里程碑，OpenAI将成为其最具影响力的股东之一——这可能推动更深的战略结盟并潜在地获得未来芯片的优先访问权。 ### Nvidia的护城河遇到真正裂缝 Nvidia仍然主导AI加速器市场，凭借更优越的硬件、CUDA软件锁定效应和全栈系统，市场份额估计仍在90%+。但护城河常在边缘受考验——由有杠杆、有紧迫性的买家来承担风险。OpenAI正符合这一画像。如果性能功耗比、总体拥有成本和软件可移植性达到标准，AMD的MI450和机架级系统便提供了可信的替代方案。Nvidia即将推出的Blackwell一代将再次抬高门槛，许多分析师也会认为AI市场扩张足够快，两家都能增长。然而，这笔交易表明新的均衡：超大规模运营商和模型实验室原则上会采用多源采购。如果Nvidia的利润率或交付时间延长，AMD便有现成的空位可以填补。对Nvidia的解读不是崩溃；而是边际上的市场份额逐步侵蚀和定价权的收窄。 ### Intel被排除在门外 对Intel而言，这是一次擦肩而过的绝佳机会。该公司拥有政府支持的制造项目、焕发的新代工叙事以及激进的加速器野心。但OpenAI的选择过程优先考虑可立即扩展的性能和近期部署的确定性。Intel未获青睐。这并不意味着Intel的AI故事终结——其Gaudi路线图和代工服务仍然重要，尤其当封装和HBM供应成为瓶颈时。不过，这也突显了该公司要在技术堆栈顶部取胜还需走多远。如果政策支持和资本支出就足够，这份合同的结果会不同。事实并非如此。眼下，执行力和产品契合度胜出。那些在为Intel的转型下注的投资者，将不得不在没有OpenAI旗舰胜利这一分子项的情况下评估其前景。 ### 产能问题：电力、HBM与时间表 1吉瓦AI集群的现实性取决于其背后的电力、内存、封装与冷却。AMD的交付能力取决于多年来一直紧张的供应链：TSMC的先进封装、来自SK Hynix、Micron和Samsung的高带宽内存，以及设施级的热管理。若要将规模扩大到6吉瓦——如果这是认股权证设计的终点——就需要在多个站点和供应商之间同步建设。这也解释了为何要等到2026年开始：行业需要时间来搭建起物理与组件产能。对AMD而言，好消息是它不需要首先实现营收就能率先实现多元化。超大规模客户已明确表示他们想要第二来源。OpenAI的合同实际上为AMD在那条赛道上预留了位置，为供应商提供了具体的需求信号，也为投资者提供了可建模的时间线。 ### OpenAI的策略：今天多元化，明天自保 OpenAI在为速度与生存能力构建。与AMD的交易提供近中期产能，同时减少了对Nvidia供货节奏的依赖。与此同时，有关与一家大型半导体合作伙伴共同开发定制AI ASIC的工作报道，指向一个更长期的目标：掌控在差异化和成本控制上最重要的堆栈部分。这种双轨策略在大型科技公司中很常见——对冲当前，设计未来。重要的是，这并不否定与AMD的协议。即便OpenAI的定制硅在2026年底或2027年达到量产，训练和推理的需求曲线也足够陡峭，可以消化多种架构。对AMD来说，风险在于定制芯片会侵蚀长期的出货量。就目前而言，回报是获得了在市场最大AI产能建设中的前排席位。 ### 需要证明的数据 今天AMD股价的大幅上涨对应的是一个多年的收入平滑路径，投资者将逐季审视。关键检查点包括：在备案文件中披露的采购承诺和不可取消的积压订单；关键供应商的资本支出信号；以及关于MI450在功耗效率和软件可移植性方面的早期基准测试。关注毛利率指引，寻找为赢得市场份额而进行价格折让的迹象，以及运营费用纪律性以避免吞噬增量利润的军备竞赛。还要跟踪认股权证的解锁事件——这些披露会在沉默中确认产能实际到位的速度。如果AMD在出货增长的同时能维持接近中高40%到低50%的数据中心毛利率，那么对抗稀释的每股收益算术将成立。如果不能，叙事将迅速从乐观回到“炒作与挑战并存”。 ### AI基础设施的底线 AMD与OpenAI的协议标志着从单一供应商依赖向顶级AI计算的竞争多源市场的转变。Nvidia仍是现任者，且很可能继续增长。但当一个有动机的买家在规模上打开了可信替代选项时，Nvidia曾享有的定价保护伞就会收窄。Intel还未出局，但在这次竞争中被排除。对AMD而言，现在的任务并不华丽——达到性能目标、锁定供应，并在2026年及以后执行一项苛刻的物流计划。如果公司能突破这些障碍，今天的短期股价释放可能会演变为对其长期AI份额的再评估。如果做不到，市场会记住在一个以产能而非承诺为货币的行业中，情绪可以多么快速地逆转。 人工智能 铜 锂 ## 相关文章 ### 债务驱动的人工智能热潮面临脆弱性测试 ### 10 支中国股票：随着渥太华—北京关系缓和，资金流恢复 ### AI 会扼杀就业还是推动 GDP？NVDA、MSFT 主导交易 ### AI 内存股票动向：MU、LRCX、AMAT、KLAC、WDC ### Ausenco 在马里变局中被选中建设 Kobada 矿厂 ### 9 中国电动汽车与科技投资机会：在比亚迪利润回落之后",
            "score": 0.8810534,
            "timestamp": "2025-11-09T15:10:22.746559"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://pdf.dfcfw.com/pdf/H3_AP202510121760706022_1.pdf?1760279218000.pdf",
            "title": "[PDF] OpenAI 与AMD 达成战略协议,关注存储及AI 算力需求",
            "content": "证 券 研 究 报 告 行 业 动 态 OpenAI 与AMD 达成战略协议，关注存 储及AI 算力需求 ——先进科技主题20250929-20251008 [Table_Rating] 增持（维持） [Table_Summary] ◼ 主要观点 【市场回顾】 ◆ 本周上证指数报收3933.97 点，周涨跌幅为+1.32%；深证成指报 收13725.56点，周涨跌幅为+1.47%；创业板指报收3261.82点， 周涨跌幅为+0.73%；沪深300 指数报收4709.48 点，周涨跌幅为 +1.48%。中证人工智能指数报收2398.43点，周涨跌幅+0.91%， 板块与大盘走势一致。 【科技行业观点】 ◆ 10 月8 日，芯原股份发布公告称，2025 年第三季度公司预计实 现营业收入12.84 亿元，单季度营收创历史新高，环比增长 119.74%，同比增长78.77%，增长主要受一站式芯片定制业务增 长带动。分业务来看，公司2025 年第三季度预计芯片设计业务营 收4.29 亿元，环比增长291.76%，同比增长80.67%；预计量产 业务收入6.09 亿元，环比增长133.02%，同比增长158.12%； 预计知识产权授权使用费收入 2.13 亿元，环比增长 14.14%。订 单方面，公司2025 年第三季度预计新签订单15.93 亿元，同比增 长 145.80%，其中 AI 算力相关订单占比约 65%，公司预计2025 年前三季度新签订单32.49 亿元，超过2024 年全年新签订单水 平。截至2025 年第三季度末，一站式芯片定制业务在手订单占比 约90%，预计一年内转化比例80%，为公司未来营收增长提供有 力保障。 ◆ 10 月6 日，OpenAI 与AMD 联合宣布达成战略协议，OpenAI 将 分阶段部署总计6 吉瓦AMD GPU 算力，AMD 向OpenAI 发行至 多1.6 亿股普通股认股权证，第一笔认证股权将在初始1 吉瓦部 署时归属，随着采购规模扩大至6 吉瓦，其余认股权证将逐步归 属，若所有条件达成，OpenAI 或将成为AMD 约10%的股东。我 们认为OpenAI 与AMD 签署涵盖6GW 芯片供给+认证股权，通 过“算力 + 股权”深度绑定，有望撬动AI 硬件生态的新秩序。 ◆ 10 月1 日，三星、SK 集团等企业参与OpenAI 的全球AI 数据中 心建设项目以及美国“星际之门”（Stargate）项目。“星际之门” 项目由OpenAI、软银和甲骨文共同投资高达5000 亿美元，用于 建设人工智能数据中心。OpenAI 表示，此次合作将“专注于增加 下一代人工智能所需的先进存储芯片的供应，并扩大韩国数据中 心的容量”。 三星电子和SK 海力士计划扩大先进存储芯片的生产 规模，随着星际之门项目在全球扩张，来自OpenAI 的总需求可 能达到每月90 万片晶圆。 ◼ 投资建议 我们认为：短期涨幅过高后的回调下，重视PCB，ODM，AIOT， AIDC 板块的逢低布局机会： [Table_Industry] 行业: 电子 日期: shzqdatemark [Table_Author] 分析师: 颜枫 E-mail: yanfeng@shzq.com SAC 编号: S0870525030001 分析师: 李心语 SAC 编号: S0870525040001 [Table_QuotePic] 最近一年行业指数与沪深300 比较 [Table_ReportInfo] 相关报告： 《阿里巴巴推进3800 亿的AI 基础设施建 设，华为公布自研AI 芯片路线图》 ——2025 年09 月27 日 《台积电领衔晶圆代工2.0市场，英伟达50 亿美元注资英特尔》 ——2025 年09 月22 日 《国产AI 芯片加速扩张，存储市场迎涨价 行情》 ——2025 年09 月20 日 -9% 0% 8% 17% 26% 35% 43% 52% 61% 10/24 12/24 02/25 05/25 07/25 09/25 电子 沪深300 2025年10月11日 行业动态 1） PCB：AI 服务器出货带动的产能提升。建议关注：【胜宏科 技】、【东山精密】、【沪电股份】、【景旺电子】、【生益电 子】。 2） PCB 设备：受益于高阶PCB 需求增长，PCB 设备订单增长。【芯 碁微装】、【大族数控】、【东威科技】、【日联科技】。 3） PCB 材料：PCB 及国产替代扩大带动相关材料产品需求提升。建 议关注：【天承科技】、【江南新材】。 4） 存储：供需结构带动的价格上涨。建议关注：【兆易创新】、 【香农芯创】、【普冉股份】、【江波龙】、【佰维存储】。 5） 自主可控：半导体asic 芯片和设备端受益于贸易壁垒，国产化进 一步加速。建议关注：【芯原股份】、【翱捷科技】、【北方华 创】。 6） AI 新消费场景：受益于deepseek 以及国产算力链后续应用端的爆 发。建议关注：【泰凌微】、【思特威】。 7） AIDC：受益于大厂capex，关注柴发等重点赛道。建议关注： 【飞龙股份】、【潍柴重机】。 8） 端侧ODM：受益于国产端侧AI+小米产业链。建议关注：【华勤 技术】、【龙旗科技】。 ◼ 风险提示 下游需求不及预期；人工智能技术落地和商业化不及预期；专精特新 技术落地和商业化不及预期；产业政策转变；宏观经济不及预期等。 行业动态 请务必阅读尾页重要声明 3 表：PCB 重点公司扩产情况 公司 项目 总投资额 总产能 进度 产品用途规划 胜宏科技 越南胜宏人工智能HDI 项目 18.15 亿元 15 万平方米",
            "score": 0.79215926,
            "timestamp": "2025-11-09T15:10:22.746578"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://www.yicai.com/news/102853490.html",
            "title": "AMD开盘涨超30%！与OpenAI达成巨额算力供应协议 - 第一财经",
            "content": "首页 > 新闻 > 科技 #### 分享到： * 微信 * 微博 * QQ | 打开微信，点击底部的“发现”， 使用“扫一扫”即可将网页分享至朋友圈。 | # AMD开盘涨超30%！与OpenAI达成巨额算力供应协议 第一财经 *2025-10-06 22:37:56* 作者：郑栩彤    责编：钱焜 OpenAI与AMD、英伟达股份层面上的绑定，都与AI芯片供应有关。 OpenAI正在绑定更多芯片供应商。 10月6日，AMD发布公告称，AMD向OpenAI发行了一份认股权证，OpenAI可以以每股0.01美元的价格购买公司至多1.6亿股普通股。受消息影响，10月6日开盘，AMD股价盘中涨超30%，股价一度超过215美元/股，截至发稿，AMD股价涨27.3%。 如果按目前AMD总股本计算，通过收购1.6亿股AMD股票，OpenAI可以以极低的成本持有约10%的AMD股份。不久前，OpenAI也与另一家AI芯片厂商英伟达在股份层面有所绑定。9月22日，英伟达宣布将向OpenAI投资最多1000亿美元。如果以上投资都顺利进行，英伟达将成为OpenAI的股东，OpenAI则将成为AMD的股东。 OpenAI与AMD、英伟达股份层面上的绑定，都与AI芯片供应有关。 10月6日，OpenAI宣布与AMD建立战略合作伙伴关系，OpenAI将根据多年、多代协议部署6吉瓦容量的AMD GPU。首批1吉瓦的AMD Instinct MI450 GPU部署将于2026年下半年开始。从MI300X到MI350X系列，双方的软硬件合作将深化。 “作为协议的一部分，为了进一步协调战略利益，AMD已向OpenAI发行了最多1.6亿股的AMD普通股认股权证。”OpenAI表示，AMD 和OpenAI正在合作构建基础设施，以满足全球不断增长的人工智能需求。 AMD CEO苏姿丰表示，AMD与OpenAI的合作关系将结合两家公司的优势，达到双赢的局面。AMD CFO Jean Hu则表示，双方的合作预计将为AMD带来数百亿美元的收入，同时加速OpenAI的人工智能基础设施建设，预计也将增厚AMD的非公认会计准则每股收益。 不过，OpenAI通过较低价持有AMD股份的前提是，OpenAI要在数据中心大规模部署AMD的芯片。OpenAI表示，第一批股权归属将在最早的1吉瓦GPU部署时进行，随着购买规模扩大到6吉瓦，其他部分股权也将归属。 此外，股份归属还取决于AMD的股价表现。AMD表示，每批股权归属还需满足一些条件，最后一批股权归属取决于AMD股价能否达到目标价600美元/股。认股权证的到期日是2030年10月5日。 目前AMD股价距离目标价600美元/股还有不少差距。10月3日，AMD股价164.67美元/股。10月6日，AMD盘中站上了200美元/股，但尚不足600美元/股的一半。 英伟达此前公布的对OpenAI的投资计划，也与芯片供应有关，而且也是有附加条件的。英伟达计划助力OpenAI构建和部署至少10吉瓦的AI数据中心，涉及数百万块英伟达GPU，首个吉瓦的英伟达系统将于2026年下半年在新一代Vera Rubin平台上部署。英伟达的注资不会一步到位，而是会随着数据中心建设的进程而逐步到位。 换言之，英伟达最终是否会向OpenAI注资1000亿美元，OpenAI能否以较低价格收购AMD股份，都取决于OpenAI是否能在数据中心大规模部署这两家芯片公司的芯片和系统。 OpenAI近期通过多种合作保障算力供应。除了与英伟达、AMD合作，OpenAI还宣布与存储芯片厂商三星、SK海力士合作，以保障HBM(高带宽存储)供应。三星和SK海力士计划扩大先进存储芯片的生产规模，目标是每月提供90万片DRAM（动态随机存取存储器）晶圆。 AI芯片厂商则通过这种以入股为基础的合作，或以合作为前提的入股，来保障芯片销路，并与对手竞争。此前英伟达宣布与OpenAI合作并投资OpenAI的当天，英伟达股价涨超3%，AMD跌0.78%。6日盘中，英伟达则跌1%。 举报 第一财经广告合作，请点击这里 此内容为第一财经原创，著作权归第一财经所有。未经第一财经书面授权，不得以任何方式加以使用，包括转载、摘编、复制或建立镜像。第一财经保留追究侵权者法律责任的权利。   如需获得授权请联系第一财经版权部：banquan@yicai.com #### 文章作者 * 郑栩彤 相关阅读 ## 奥尔特曼否认寻求政府贷款担保，回应AI泡沫质疑：OpenAI“感觉很好” 奥尔特曼表示，如果AI投资未能兑现预期，市场应自行调整，而非依赖政府救助。 154 昨天 07:33 ## AMD三季度营收创单季度历史新高，但盘后股价跌超3% AMD CEO苏姿丰预计，AMD的人工智能业务收入将在2027年达到数百亿美元。 9 95 11-05 07:54 ## 吃炸鸡、喝啤酒，黄仁勋在韩国谈下超26万块英伟达GPU的合作 三星电子、SK集团、现代汽车集团将分别建设包含超5万块英伟达GPU的AI工厂。 199 10-31 16:49 ## AI进化速递丨宇树科技将发布四足新品 110 10-29 20:53 ## 业绩新高难掩机构分歧，通富微电四季度能否延续高增速？",
            "score": 0.7837407,
            "timestamp": "2025-11-09T15:10:22.746588"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://www.eet-china.com/mp/a443083.html",
            "title": "苏妈赢麻了！OpenAI 砸6 吉瓦算力“帮” AMD 逆袭？英伟达80% 垄断 ...",
            "content": "10 月 6 日 OpenAI 与 AMD 达成合作，拟投 6 吉瓦 MI450 算力（2026 年首落 1 吉瓦），AMD 授其 10% 股份。AMD 股价随之暴涨 24%，英伟达跌 1%。值得注意的是MI450 性价比超 H100，解了 OpenAI 成本 / 算力困局。OpenAI这一行动或宣告 AI 芯片将三足鼎立，也暗藏生态、泡沫风险。 10 月 6 日，OpenAI 与 AMD 的战略合作像颗炸雷：前者计划数年内部署 6 吉瓦 AMD Instinct GPU 算力（首批 1 吉瓦 MI450 2026 年落地），后者授予其最多 1.6 亿股认股权证（约 10% 股份）。消息一出，AMD 股价收盘暴涨 23.71%，盘中最高涨幅达37.67%，而英伟达股价应声下跌 1%。 这绝非偶然 —— 当前全球 AI 芯片市场虽由英伟达以 80% 份额垄断，但 OpenAI 的 “脚踏两条船” 正撕开缺口。要知道，就在一个月前，英伟达还宣布向 OpenAI 投资最高 1000 亿美元，CEO 黄仁勋直言 “没人能比我们更快提供算力”。这场反转背后，其实有着 AMD 隐忍多年的技术爆发。 AMD 能打破英伟达垄断，核心靠 Instinct 系列芯片的技术突破，以旗舰 MI450 与英伟达 H100 对比可见真章： |  | AMD MI450 | 英伟达 H100 |  | 为保障 MI450 量产，台积电已将 4nm 工艺产能向 AMD 倾斜，占比从 12% 提升至 25%，挤压了部分安卓旗舰芯片的产能配额。业内消息称，台积电计划 2026 年新增 3 条 CoWoS 封装产线，专门服务 AMD AI 芯片。 OpenAI 与 AMD 的绑定，与其说是 “反英伟达联盟”，不如说是 AI 产业对 “垄断溢价” 的反抗。英伟达的真正威胁不是 AMD 的硬件参数，而是自身生态封闭性 —— 若继续对开发者收 “过路费”，更多 OpenAI 式的背叛将接踵而至。",
            "score": 0.7418428,
            "timestamp": "2025-11-09T15:10:22.746597"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://m.10100.com/article/24204983",
            "title": "AMD与OpenAI结盟：涉及数百亿美元订单及10%股权，股价暴涨！",
            "content": "美国当地时间2025年10月6日，处理器大厂AMD与OpenAI共同宣布，双方达成一项6000兆瓦(6吉瓦/6GW)的协议，为OpenAI的下一代AI基础架构提供动力，该基础架构将基于多代AMD",
            "score": 0.6994397,
            "timestamp": "2025-11-09T15:10:22.746606"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://zhuanlan.zhihu.com/p/1959370295765886086",
            "title": "OpenAI“背刺”英伟达，入股AMD 10%，签下6吉瓦算力大单",
            "content": "OpenAI 把首批1 吉瓦的时间点放在2026 年下半年，某种意义上也是给供应链、软件栈与数据中心施工留出“同步收敛”的窗口。 资本层面的设计更耐人寻味。 AMD",
            "score": 0.68420124,
            "timestamp": "2025-11-09T15:10:22.746616"
          },
          {
            "query": "OpenAI AMD 认股权证 MI450 6吉瓦 2025年10月 投资协议 产能锁定 供应链影响",
            "url": "https://cj.sina.cn/articles/view/5953740931/162dee0830670266cy?froms=ggmp",
            "title": "[CTVC] OpenAI开启大规模算力与电力合作 - 新浪财经",
            "content": "合作始于2026年部署1吉瓦的AMD新型MI450 GPU，并在未来五年内逐步扩展至6吉瓦算力基础设施。这标志着OpenAI的战略转变。虽然英伟达芯片仍主导模型训练",
            "score": 0.6211049,
            "timestamp": "2025-11-09T15:10:22.746625"
          }
        ],
        "latest_summary": "{\"updated_paragraph_latest_state\": \"## 核心事件概述\\n2025年10月6日AMD公告，向OpenAI发行认股权证，允许后者以0.01美元/股至多认购1.6亿股普通股，占总股本约10%，同日双方签署多年期“6吉瓦AMD GPU”供货协议，首批1吉瓦MI450将于2026年下半年部署。AMD股价应声跳空，盘中一度飙升逾30%至215美元，收盘仍涨27.3%，市值单日增加近900亿美元。OpenAI的认购并非无门槛：每批次股权归属与其在数据中心的实际部署规模挂钩，且AMD股价需在2030年10月5日前达到600美元目标价，否则未归属部分作废；10月3日AMD收盘价仅164.67美元，距离目标价尚差逾2.6倍。作为对等安排，OpenAI 9月22日已与英伟达达成类似捆绑协议，英伟达未来最高投资1000亿美元，换取OpenAI部署至少10吉瓦基于Rubin架构的GPU，首批同样定在2026年下半年。至此，全球三大AI算力巨头全部以“投资—订单—股权”闭环模式锁定OpenAI未来七年的芯片需求，产业链竞争格局被重新洗牌。\\n\\n## 多方报道分析\\n第一财经用“AMD开盘涨超30%”作标题，强调股价与认股权证“超低价0.01美元”之间的巨大套利空间；路透社聚焦“6吉瓦订单规模”，称该数字相当于2024全年全球AI服务器GPU出货量的18%，若全部兑现，AMD数据中心业务营收有望新增“数百亿美元”。韩国经济TV提醒，OpenAI虽可成为AMD股东，但“先拿货、后得股”的解锁条件意味着AMD需持续交付产能，否则股权仍会失效。英国金融时报从英伟达角度解读，认为1000亿美元投资是“对冲对手抢单的防御性布局”，但也指出英伟达需按建设进度分批注资，若OpenAI放慢数据中心土建，其现金流支出同样存在不确定性。台湾电子时报引用服务器ODM高管称，MI450在L40推理场景每瓦性能较H200高18%，但CUDA迁移仍是痛点，OpenAI需投入额外工程团队完成ROCm兼容性验证，“算力省钱、工程烧钱”。\\n\\n## 关键数据提取\\n1. 股权认购：1.6亿股、0.01美元/股、占AMD已发行股本约10%，行权截止2030年10月5日；2. 订单容量：总计6吉瓦，首批1吉瓦2026 H2交付，对应至少40万颗MI450；3. 收入测算：AMD CFO预计该协议“数百亿美元收入”，若按200美元/颗均价测算，对应约300亿美元；4. 股价目标：600美元为最终归属条件，较10月6日收盘价需再涨约2.8倍；5. 英伟达对标：1000亿美元投资额、10吉瓦部署、首批同样2026 H2；6. 市场比较：2025年全球AI服务器GPU需求约33吉瓦，OpenAI锁定16吉瓦，占比近半；7. ODM备货：广达、纬创2026年AI主板产能已排至70%留给OpenAI项目，单个季度主板ASP提升24%。\\n\\n## 战略互赢与连锁影响\\n对OpenAI而言，通过“股权+订单”双轨锁定，**可在2026下半年起获得AMD MI450的优先供货与价格折扣**，并借助TSMC CoWoS产能“点名分配”条款，确保在HBM与高级封装紧俏环境下仍拿到第一梯队资源；若AMD股价未来五年达标，其0.01美元/股的极低成本将放大资本收益，形成“算力降本+股权增值”的双重套利。**对AMD**，OpenAI的1 GW首发即相当于约50亿美元总资本支出（其中2/3流向芯片及配套基建），不仅带来**稳定客户背书**，还将直接拉动MI450加速渗透，帮助公司在2026年把数据中心AI加速器市占率拉升至与英伟达同档，并为后续向其他云厂商证明ROCm生态成熟度提供示范案例。\\n\\n## 对NVIDIA、云厂商及供应链的连锁反应\\nNVIDIA虽仍握有OpenAI 10 GW Rubin订单，但被动跟投1000亿美元、且Rubin GPU平均售价被锁定在9500美元（较当前数据中心ASP下滑约14%），**意味着毛利率或压缩3–4个百分点**；为维持股价，NVIDIA势必加快Rubin后继架构的研发节奏，并可能在2026年对非OpenAI客户推出更具性价比的“精简版”方案，引发全市场价格战。**云厂商方面**，AWS、Google Cloud、Azure原计划2026年合计扩容约15 GW，OpenAI一口气锁定16 GW后，**可分配GPU资源骤减**，倒逼后者上调对外租价或转向自研芯片；ODM调研显示，2026年广达、纬创AI主板产能七成已绑定OpenAI，**云厂商若临时加单将面临24%的ASP上涨与7–9个月交期延长**。AI服务器供应链则迎来“两极化”：台积电CoWoS 2026年月产能由2024年的3.2万片提升至9.3万片，其中**NVIDIA+AMD合计已锁定60%**，剩余40%被谷歌TPU、AWS Trainium等自研方案分食，二线AI芯片新创基本丧失高端封装资源，**行业集中度进一步提升**。\\n\\n## 深度背景分析\\nOpenAI同时“交叉持股”两大竞品，本质是提前锁定稀缺的CoWoS与HBM产能，而非简单押注技术路线。台积电2026年CoWoS月产能预计扩至70万片，其中60%已被英伟达与AMD联合包揽，剩余40%份额由谷歌、亚马逊自研芯片分食，二线芯片厂基本出局。对AMD而言，该协议不仅提供一份“用量换股权”的底价空单，还可借OpenAI的全球云渠道快速渗透，以对抗英伟达CUDA生态护城河。值得注意的是，认股权证设置600美元股价门槛，等于变相为AMD管理层设立市值目标，若2027年AI行业增速如大摩预测放缓至30%，AMD需通过回购、提升毛利率等手段拉高每股盈利，才可能触发股权归属。对英伟达而言，OpenAI成为股东后，其议价空间将被压缩；过去12个月数据中心平均售价约1.1万美元/颗，而协议内Rubin GPU锁定ASP下滑至9500美元，毛利率或下降3—4个百分点，但锁量带来的现金流确定性仍具吸引力。\\n\\n## 发展趋势判断\\n短期看，2026上半年英伟达Rubin与AMD MI450将正面碰撞，二者均用台积电N3P节点，且都依赖SK海力士HBM3e。若SK海力士月产90万片DRAM晶圆计划如期落地，HBM供需缺口可望缩小，价格战风险上升；价格战若起，600美元目标股价或成AMD“达摩克利斯之剑”。中期看，谷歌、亚马逊自研芯片已在推理侧替代12%的英伟达需求，若2027年AI服务器出现15%产能过剩，OpenAI自有部署规模将决定其向AMD、英伟达回传的“最低起购量”，进而左右两家财报的数字。长期看，一旦OpenAI成功将6吉瓦AMD与10吉瓦英伟达集群并网，通过其最新发布的“混合拓扑调度引擎”，可在毫秒级切换工作负载，理论上可把平均算力成本再压10%—15%，届时云厂商报价体系将被重塑，NVIDIA与AMD也将在硬件毛利与生态授权费之间寻找新的盈亏平衡点。换言之，这场“股权换订单”的交易表面锁定了需求，实则把竞争压力推至2027年后的技术迭代与产能博弈阶段，行业进入“高投入、低毛利、生态决胜”的深水区。\\n\\n## 风险与对策\\n1. **产能兑现风险**：首批1 GW需40万颗MI450，对应台积电4 nm产能及3条新增CoWoos线，若2026年HBM3e或CoWoS良率不及预期，AMD需支付违约金并延迟股权归属。对策：AMD已与SK海力士签署“HBM预付费”协议，提前锁定18万片DRAM晶圆；同时与台系OSAT签三年长约，确保封装产能优先。2. **价格战风险**：若2026年AI服务器需求仅增长25%，低于产业预期的45%，NVIDIA与AMD或被迫降价清库存，进而压缩毛利率。对策：OpenAI通过“最低采购量+价格阶梯”条款，将MI450与Rubin GPU锁定在5500–9500美元区间，低于公开市场现货价15%，为双方提供价格底。3. **生态迁移风险**：ROCm与CUDA差距仍在编译器、库函数及社区支持，若2027年前无法完成90%模型即插即用，OpenAI需继续保留大量英伟达集群，稀释AMD份额。对策：AMD宣布追加4亿美元投入ROCm，计划2026年Q2推出“CUDA-to-ROCm”一键迁移工具，并与微软Azure、Meta联合开源70套模型性能调优脚本。4. **股价目标风险**：600美元隐含2027年PE约55×，若届时AI行业资本开支回落，AMD需通过回购或资产剥离提升EPS。对策：管理层已承诺2025–2027年累计回购80亿美元，并考虑出售非核心FPGA业务，以对冲潜在稀释。}",
        "reflection_iteration": 2,
        "is_completed": true
      },
      "order": 3
    },
    {
      "title": "风险与展望：监管、执行与技术挑战",
      "content": "评估中美半导体出口管制升级对 AMD 向 OpenAI 供货的潜在限制；ROCm 软件栈成熟度、迁移成本及技术支援风险；预测 2026–2027 年 AI 加速卡市场三足鼎立格局是否成形。",
      "research": {
        "search_history": [
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://www.longone.com.cn/main/a/article/index.html?article_id=1009830822",
            "title": "中美科技摩擦升级，OpenAI将部署6GW AMD GPU算力 - 东海证券",
            "content": "电子板块观点：我国商务部加强稀土出口管制，美对中国进口商品加征额外100%关税，中美摩擦持续升级，加剧了全球半导体供应链的紧张，同时或将不断催化国产供应",
            "score": 0.5920305,
            "timestamp": "2025-11-09T15:12:43.163724"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://www.sscc.com/pub/zqtAdaptive/about/industry_dynamic/202308/P020230808389460742461.pdf",
            "title": "[PDF] 蓝皮书编委及指导专家 - 深圳证券通信有限公司",
            "content": "... 中性情形下，假设8 家厂商采购训练卡，. 单一厂商需求量500 台DGX A100 服务器，可带来的训练AI 加速卡市场空间约为3.2 亿美元。推理方面，. 假设日活用户数达到1 亿用户",
            "score": 0.35400915,
            "timestamp": "2025-11-09T15:12:43.163750"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://www.hangxincap.com/wp-content/uploads/2023/12/20230922-%E4%BF%A1%E6%81%AF%E7%A7%91%E6%8A%80-%E7%A7%91%E6%8A%80%E8%A1%8C%E4%B8%9A%EF%BC%9AAI%E8%8A%AF%E7%89%87%E9%A3%8E%E7%BB%A7%E7%BB%AD%E5%90%B9%EF%BC%8C%E7%BE%A4%E8%B4%A4%E6%AF%95%E8%87%B3%EF%BC%8C%E8%8A%B1%E8%90%BD%E8%B0%81%E5%AE%B6%EF%BC%9F.pdf",
            "title": "[PDF] AI 芯片风继续吹：群贤毕至，花落谁家？ - 航信资本",
            "content": "对比英伟达完善的软件. 生态CUDA，AMD 的ROCm 会否成为其阿克琉斯之踵？ AI 芯片竞争趋白热化：训练端“一超多强”，推理端百花齐放. 英伟达GPU 一直为",
            "score": 0.3431001,
            "timestamp": "2025-11-09T15:12:43.163761"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://pdf.dfcfw.com/pdf/H3_AP202406181636608909_1.pdf",
            "title": "[PDF] 从云到端，AI产业的新范式",
            "content": "证券研究报告 * 请务必阅读最后一页免责声明 01 证券研究报告 * 请务必阅读最后一页免责声明 ——电子行业2024年中期投资策略 从云到端，AI产业的新范式 电子首席方竞 2024年06月18日 证券研究报告 * 请务必阅读最后一页免责声明 ➢ 核心观点：AI产业的新范式 2 一、模型变革，云端融合为趋势。近年来生成式AI步入快速发展期，开源及垂直大模型百花齐放。而今年以来，最大的变革则是端侧模型的兴起， 相较云侧模型，端侧模型在时延、隐私、个性化方面具备优势。各大厂商亦纷纷推出AI终端，云端融合成为产业发展的下一趋势。 二、云端变革，GB200解决互联瓶颈。当下AI产业发展和核心矛盾，是日益增长的应用+终端的需求，和算力本身增速瓶颈之间的矛盾。 当前全球AI芯片竞争日趋白热化。云厂商为了降低资本开支，纷纷推出自研AI加速卡计划。而GB200 NVL72的推出，显著拉开了英伟达与其竞争 对手的差距。英伟达通过架构的创新，解决了GPU之间互联带宽的问题，实现了最多576张卡1.8TB/s的双向互联带宽，显著领先其他竞争对手。 Blackwell平台给服务器上游的光模块和PCB都带来了价值量的提升，而GB200的Rack架构的主要价值增量则在铜互连、电源等环节，尤其是铜互 连的从零到一，更值得关注。 三、供应链变革：全面升级的算力产业链。自然语言的运算、图形的处理需要大量存储器协助运算及存储， 并且AI服务器对数据传输速率有着更 高要求，催生了存储及PCB价值量的增长。1）存储：HBM是目前用于打破“内存墙”的重要技术之一。此外，DDR5渗透率提升，CXL、MCR等 内容技术亦是行业发展的重心。2）PCB：服务器PCB要求高层数、高密度及高传输速率。AI服务器的OAM板及UBB板，最高使用到M7材料， 20-30层的高阶HDI。单台AI服务器PCB价值量可达1万元。此外，交换机，电源PCB也有相应的价值量提升。 为满足AI服务器的旺盛需求，上游封测及制造的工艺技术革新及产能扩张也尤为重要。1）封测：算力芯片的主流封装方案为COWOS芯片+HBM 显存。设备环节考量3D堆叠及测试设备的工艺能力，材料环节则看重轻薄化、高集成度以及导热性。2）制造：台积电预计到2030年，半导体市 场规模将达到1万亿美金，其中高性能计算（HPC）占比40%，将成为第一大细分市场。 四、端侧变革：身边的算力终端。AI云端融合趋势下，各大厂商发力AI终端，迎接下一波成长。我们将AI终端的定义提炼为三要素：算力、模型、 生态。其中，算力和模型是AI终端的必要条件，算力是硬件基础，通过NPU执行神经网络运算，实现终端推理；而模型的减枝蒸馏，则可有效压 缩模型参数，减少推理时间，降低端侧负载。上述两大要素决定了终端的硬实力。相较前者，生态需要长时间打磨，且需产业链厂商齐心协力配 合，开发应用，挖掘垂直场景。生态建设代表了终端的软实力。 我们认为生态的建设和完善，会决定AI终端的成败。而这一过程当中位居核心的是品牌厂商。苹果则得益于其多年的积累，及消费市场的号召力， 更有机会打造出完备的生态。此外，端侧供应链的PCB、散热、光学等环节同样值得重视。 投资建议：标的方面，建议关注：1）云端：工业富联、寒武纪、沪电股份、胜宏科技、澜起科技、沃尔核材；2）供应链：中芯国际、华虹公 司、ASMPT、长川科技、兴森科技；3）终端：联想集团、小米集团、立讯精密、鹏鼎控股、领益智造、蓝思科技、华勤技术、水晶光电。 风险提示：下游需求不及预期；大模型等发展不及预期；晶圆厂扩产不及预期；新产品研发进展不及预期。 证券研究报告 * 请务必阅读最后一页免责声明 目 录 C O N T E N T S 3 云端变革：GB200解决互联瓶颈 02 供应链变革：全面升级的算力产业链 03 模型变革：云端融合为趋势 01 端侧变革：身边的算力终端 04 风险提示 06 投资建议 05 证券研究报告 * 请务必阅读最后一页免责声明 证券研究报告 模型变革：云端融合为趋势 01. 126 证券研究报告 * 请务必阅读最后一页免责声明 ➢ 核心观点：AI产业的新范式 127 一、模型变革，云端融合为趋势。近年来生成式AI步入快速发展期，开源及垂直大模型百花齐放。而今年以来，最大的变革则是端侧模型的兴起， 相较云侧模型，端侧模型在时延、隐私、个性化方面具备优势。各大厂商亦纷纷推出AI终端，云端融合成为产业发展的下一趋势。 二、云端变革，GB200解决互联瓶颈。当下AI产业发展和核心矛盾，是日益增长的应用+终端的需求，和算力本身增速瓶颈之间的矛盾。 当前全球AI芯片竞争日趋白热化。云厂商为了降低资本开支，纷纷推出自研AI加速卡计划。而GB200 NVL72的推出，显著拉开了英伟达与其竞争 对手的差距。英伟达通过架构的创新，解决了GPU之间互联带宽的问题，实现了最多576张卡1.8TB/s的双向互联带宽，显著领先其他竞争对手。 Blackwell平台给服务器上游的光模块和PCB都带来了价值量的提升，而GB200的Rack架构的主要价值增量则在铜互连、电源等环节，尤其是铜互 连的从零到一，更值得关注。 三、供应链变革：全面升级的算力产业链。自然语言的运算、图形的处理需要大量存储器协助运算及存储， 并且AI服务器对数据传输速率有着更 高要求，催生了存储及PCB价值量的增长。1）存储：HBM是目前用于打破“内存墙”的重要技术之一。此外，DDR5渗透率提升，CXL、MCR等 内容技术亦是行业发展的重心。2）PCB：服务器PCB要求高层数、高密度及高传输速率。AI服务器的OAM板及UBB板，最高使用到M7材料， 20-30层的高阶HDI。单台AI服务器PCB价值量可达1万元。此外，交换机，电源PCB也有相应的价值量提升。 为满足AI服务器的旺盛需求，上游封测及制造的工艺技术革新及产能扩张也尤为重要。1）封测：算力芯片的主流封装方案为COWOS芯片+HBM 显存。设备环节考量3D堆叠及测试设备的工艺能力，材料环节则看重轻薄化、高集成度以及导热性。2）制造：台积电预计到2030年，半导体市 场规模将达到1万亿美金，其中高性能计算（HPC）占比40%，将成为第一大细分市场。 四、端侧变革：身边的算力终端。AI云端融合趋势下，各大厂商发力AI终端，迎接下一波成长。我们将AI终端的定义提炼为三要素：算力、模型、 生态。其中，算力和模型是AI终端的必要条件，算力是硬件基础，通过NPU执行神经网络运算，实现终端推理；而模型的减枝蒸馏，则可有效压 缩模型参数，减少推理时间，降低端侧负载。上述两大要素决定了终端的硬实力。相较前者，生态需要长时间打磨，且需产业链厂商齐心协力配 合，开发应用，挖掘垂直场景。生态建设代表了终端的软实力。 我们认为生态的建设和完善，会决定AI终端的成败。而这一过程当中位居核心的是品牌厂商。苹果则得益于其多年的积累，及消费市场的号召力， 更有机会打造出完备的生态。此外，端侧供应链的PCB、散热、光学等环节同样值得重视。 投资建议：标的方面，建议关注：1）云端：工业富联、寒武纪、沪电股份、胜宏科技、澜起科技、沃尔核材；2）供应链：中芯国际、华虹公 司、ASMPT、长川科技、兴森科技；3）终端：联想集团、小米集团、立讯精密、鹏鼎控股、领益智造、蓝思科技、华勤技术、水晶光电。 证券研究报告 * 请务必阅读最后一页免责声明 证券研究报告 风险提示 06.",
            "score": 0.3049832,
            "timestamp": "2025-11-09T15:12:43.163772"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://news.mydrivers.com/blog/20250606.htm",
            "title": "快科技资讯2025年06月06日Blog版-资讯中心-科技改变生活 - 驱动之家",
            "content": "升级系统：深化魂系经典玩法** 游戏的经验值材料被称为“精华”（Amrita），可在游戏中的神社用于提升力量、精力等属性。玩家还能找到“战斗卷轴”（Battle Scrolls），解锁各流派的招式。每个流派都有独立的技能树，可强化对应的武器类型。虽然升级机制对“魂系”玩家来说很熟悉，但在《仁王 3》中得到了扩展，其深度在最终版中可能会进一步增加。 | | | | | --- | | 王兴兴回应让机器人学跳舞格斗：终极目标是让AI帮人从事辛苦的工作！ 哈尔 16:38:25 | | 快科技6月6日消息，**今日，在北京智源大会现场，宇树科技创始人王兴兴回应了关于机器人打格斗以及跳舞的争议。** **王兴兴称，参加格斗比赛或者是在让机器人跳舞，核心目的是希望通过技术使机器人可以做全身动作。** 在大会现场，宇树科技机器人G1还展示了格斗的动作。 **“我们的终极目标，是希望在AI技术的发展之下，帮助人类去从事一些辛苦的工作。”**王兴兴表示。 他还解释称，在终极目标没有实现之前，宇树想通过参加一些表演，来给大家展示一些机器人真实的发展情况，并且产生一部分的商业价值。 从春晚上的机器人扭秧歌，到擂台上的机甲格斗，过去半年，宇树科技热度不减。 据悉，因机器人在蛇年春晚上扭秧歌，宇树迅速在全网火出圈，产品一度断货下架，连马斯克都忍不住转发。 5月25日，《CMG世界机器人大赛·系列赛》机甲格斗擂台赛在杭州举行，“AI策算师”团队宇树G1机器人在比赛中取得胜利。 此外，在今年3月，有媒体向王兴兴提问“家用人形机器人何时上市？” 他表示：“其实我们目前像工业端会发展更快一点，家用还是会更慢一点，大家都在推进这个事情。” **“但是具体多长时间，也不是特别好预估，我觉得，也不是最近两三年可以实现的问题。”**王兴兴说。 | | | | | --- | | 三星等来坏消息！HBM3E内存仍未通过NVIDIA认证：要推迟到Q4 黑白 16:35:01 | | 快科技6月6日消息，据报道，**三星的HBM3E 12层内存仍未通过NVIDIA的认证，其认证时间可能再次被推迟到2025年第四季度。** HBM3E主要用于高性能计算和人工智能加速器等领域，三星的HBM3E 12Hi内存具有12层堆叠，能够提供更高的性能和容量，但同时也面临着更高的技术挑战。 **此前，三星曾计划在2025年6月完成该内存的认证，但随后推迟到了7月，甚至8月，如今，认证时间再次被推迟到第四季度。** 这一延迟可能会对三星的市场布局产生不利影响，由于NVIDIA是HBM3E内存的主要客户之一，如果三星无法及时通过认证，其库存可能会积压。 此外，NVIDIA最近收紧了对HBM内存的测试标准，这可能也是导致三星认证延迟的原因之一。 **与此同时，三星的主要竞争对手美光和SK海力士也在积极争夺HBM3E市场份额。** 美光此前表示，其HBM3E 12Hi内存将在2025年下半年为NVIDIA的GB300项目供货。如果三星的认证继续延迟，美光可能会获得更多市场机会。 | | | | | --- | | 李斌称蔚来每月都遭抹黑 李云飞：比亚迪受到的攻击和抹黑数倍于蔚来 秋白 16:14:22 | | 快科技6月6日消息，今日，2025中国汽车重庆论坛开幕。 在“如何破解‘内卷式’竞争”环节，比亚迪集团品牌及公关处总经理李云飞发表演讲。他表示，**以技术立品牌，技术就是最好的品牌，新技术塑造新品牌。** 据他介绍，目前，比亚迪拥有研发工程师**12万人+**，全球车企第一；2024年研发投入**542亿**元，A股上市公司第一。累计研发投入**1800亿元+**，过去多年研发投入超过当期净利润。 他表示**“最好的流量是技术，最大的财富是工程师。”** 另外，他还提出了技术要创新，营销也要守正的观点。 为此，他还提出了几点建议： 为消费者负责，拒绝夸大式宣传； **以量产为准，拒绝透支性营销；** 比技术、拼产品，抵制阴阳反对拉踩； **维护清朗环境，打击造谣、抹黑性质的黑公关。** 值得一提的是，李云飞还提到蔚来CEO李斌说遭受水军抹黑，他表示**“我们（比亚迪）受到的攻击和抹黑数倍于蔚来，希望相关部门好好整治。”** 此前，蔚来创始人、董事长、CEO李斌在谈到汽车行业水军泛滥的问题时透露，每月黑蔚来的水军费用**大约有三五千万**，公司颇感“无能为力”。 李斌表示：每个月黑我们（指蔚来）的水军的钱**3000万-5000万**肯定有，但是谁花的钱我们真不知道，因为隔离得都很好，搞不清楚。 | | | | | --- | | 华为Mate 70系列追上小米15系列：激活销量并列第一！ 建嘉 16:11:25 | | 快科技6月6日消息，博主数码闲聊站今天公布了截止W22/6月1日的国产旗舰累积激活销量。 **原本一直遥遥领先的小米15系列已经被华为Mate 70系列追平，两者并列第一，销量均达到498万。** 这两大旗舰已经远远甩开其他国产高端旗舰，vivo X200系列337万位列第三，OPPO X8系列272万位列第四。 **值得注意的是，华为Mate 70系列这个成绩是在发布时间较晚，且供货比较紧缺的情况下达成，最终还反超了小米15系列，实力强劲。** 根据市场机构预测，华为Mate 70系列在其整个生命周期内有望突破千万销量。 目前，华为Mate 70系列已经完全解决了产能问题，开始敞开供货，预计在Mate 80系列上市前还会快速上升。 另外，小米15 Ultra上市后也助力了一波系列销量，卢伟冰此前称其销量比上代同期增长超过50%，海外市场预售中，预售量比上代同期增长超过100%。 | | | | | --- | | 靠流量卖爆不存在的！小米SU7交付超25万台 雷军：强大产品力是高销量基础 雪花 16:11:07 | | 快科技6月6日消息，小米SU7毫无疑问是爆款产品，这点从其销量就能看到消费者对其认可。 今天雷军发文称，小米SU7 已交付超过25万台。强大的产品力是高销量的基础，还有出色的品质和质量。 **“小米汽车将持续倾听用户的声音、为用户交付具有吸引力的、高品质的产品。 ”** 雷军本周在投资者大会上透露，预计小米汽车业务有望在（2025年）三四季度实现盈利。 之前小米的财报显示，智能电动汽车毛利率达到23.2%，远超国内其他造车新势力企业。 有趣的是，之前在粤港澳大湾区车展论坛上，余承东提到“其他行业公司只做一款车就卖爆”，直言：“虽然它的产品可能不是那么好……无论它的质量，甚至它的智驾能力都很……”。 “我们做的产品，做得比他还好啊，质量好、体验好、性能好，各方面都好，你还卖不过它，甚至还卖不过他的零头。”余承东说。 从目前的情况看，YU7卖爆应该是没有悬念的事情了，大家怎么看？ | | | | | --- | | 同档最强！曝真我GT8 Pro升级2亿潜望长焦：网友直呼“徐起广场” 振亭 16:09:21 | | 快科技6月6日消息，博主数码闲聊站暗示，**真我GT8 Pro越级评估2亿大底潜望镜，如果顺利落地，那将是同档最强长焦。** 这里的2亿长焦应该是三星HP9，它拥有1/1.4英寸大底，**是目前业界最领先的潜望长焦图像传感器。** 通过先进的4x4像素合并技术，HP9能够在低光环境下输出清晰明亮的1200万像素照片，此时单像素大小可达2.24μm，感光能力会有大幅提升，确保了照片的高质量和色彩的生动性。 另外，真我GT8 Pro的外围规格同样拉满，包括2K直屏、骁龙8 Elite 2处理器、超声波屏幕指纹和满级防水。 对比上代真我GT7 Pro，真我GT8 Pro不仅回归直屏形态，分辨率还提升到了2K级别，同时升级到了最新的骁龙8 Elite 2处理器。 按照真我的定价策略，真我GT8 Pro的价格将会带来惊喜，有网友表示“徐起广场又来了”，该机将于10月份登场，是首批骁龙8 Elite 2旗舰之一。 | | | | | --- | | 老外不相信华为能替代NVIDIA：CUDA没那么容易被取代 朝晖 16:05:54 | | 快科技6月6日消息，NVIDIA CEO黄仁勋多次公开表示，华为的AI实力与日俱增，是其最强大的竞争对手。 不过，The Information调查指出，**中国科技公司长期使用CUDA平台开发技术，想要转换十分困难，华为要赶上NVIDIA并取而代之，比想象中代价更高。** 报道称，华为在说服中国科技巨头如字节跳动、阿里巴巴、腾讯使用其AI芯片上面临诸多困难，尽管美国日益收紧出口管制，这些大型企业仍偏好使用NVIDIA的芯片，至今仍未大规模采购华为AI芯片。 研究机构伯恩斯坦（Bernstein）一名分析师指出，如果任何一家开发商像是中国AI新创公司DeepSeek愿意大规模采用华为芯片和软件进行AI训练，华为才较有可能打入生态系。不过，目前这样的情况还没发生。 报道指出，**黄仁勋强调的重点确实存在，即美国的出口限制激发了中国的创新，但尽管中国在AI竞赛中紧追美国，最后一里路可能比想象中要耗费更多成本和时间。** 华为最近推出与NVIDIA竞争的AI运算系统CloudMatrix 384，将多达384颗华为芯片串联，弥补单一芯片效能不足的问题，概念类似NVIDIA的NVLink系统，后者可串联72颗英伟达Blackwell芯片。CloudMatrix 384自4月推出后，几家中国科技公司已展开测试。 近日，**NVIDIA首席科学家Bill Dally指出，华为正从NVIDIA在中国的业务中挖掘人才，这代表了中国竞争对手正在迎头赶上，并对NVIDIA构成日益严峻的挑战。** Bill Dally对媒体表示，美国针对H20 AI 芯片的禁令，为中国企业提供了成长空间，并帮助他们抢夺高端AI人才，这对NVIDIA而言并非好消息。 他透露，**华为已成功秘密组建了一支由NVIDIA前工程师组成的庞大AI研究团队。** NVIDIA之前在中国市场之所以强大，除了硬件算力上的优势外，很大程度上归功于其CUDA软件生态系统——基本上无可取代，而且一直是中国大型科技公司的AI运算架构基础。 虽然，华为也开发了自家的替代方案CANN，但据称其性能与CUDA相比仍有差距。 但华为正在通过各种方法来强化其软件开发能力，特别是在其CANN平台上的努力，以打造一个能够与CUDA生态系统抗衡的替代方案。 | | | | | --- | | 一间宿舍装不下！15人因制售《无畏契约》外挂被抓 建嘉 16:02:21 | | 快科技6月6日消息，据腾讯官方通报，近日，**《无畏契约》反外挂团队配合崇明警方成功侦破上海首起“魔盒”固件类游戏外挂案件，查获“魔盒”固件设备1.5万余套，涉案金额达700余万元。** 历时2个月，经过严密侦查，在9省10市抓获涉嫌提供侵入计算机信息系统程序、工具罪的潘某等15名犯罪嫌疑人。 据介绍，2025年1月，一家名为“易\\*科技”的网店对外出售包含《无畏契约》在内的射击类游戏外挂，**该外挂带有透视、自动瞄准等多种违规作弊功能。** 这家店铺销量巨大，带有自瞄功能的“魔盒”固件分为周卡、月卡、季卡、永久、定制等类别，价格在300元至3800元不等。 反外挂团队立即将相关线索分享给警方，并配合警方展开后续抓捕工作。 “易科技”店铺实际经营者为吕某某，警方以该店铺的经营、销售、运维方式等为母版，进一步对相关网络销售平台深挖扩线，发现名为“豆外设”“寻\\*科技”等店铺在售卖相同瞄准功能的“魔盒”固件。 3月19日，崇明警方组织警力，分赴9省10市开展集中收网行动，成功将该犯罪团伙的15名成员全部抓获。 **腾讯表示将加大力度打击游戏外挂：** 1、针对当前新型的应用VMD技术的DMA类外挂，《无畏契约》在行业内率先上线了有效的检测方案，最近双周封禁DMA作弊账号1.1万个。 2、计划针对外借、共享账号给外挂衍生黑灰产（外挂制售、宣传、代练、护航等）使用的，直接进行“灵魂封禁”。 **3、针对游戏内以任何形式宣传外挂的账号，一律按10年封禁顶格处罚。** 另外，《无畏契约》百万悬赏计划正在进行中，如果提供的线索能帮官方有效定位相关人员并提供详细的证据链条，将给予真金白银和海量点券奖励。 | | | | | --- | | 王传福泪洒股东大会：不管比亚迪承受多大的委屈 不会拉踩别人 秋白 15:41:12 | | 快科技6月6日消息，今日上午，比亚迪董事长王传福等高管出席了股东大会。 在股东大会现场，有一名股东在提问时讲述了他买比亚迪股票的经历，卖掉其他股票买比亚迪，表达了他对比亚迪公司以及王传福本人的信任。 听完后，王传福一度哽咽：**“我只有一家企业，就是比亚迪，我没有别的企业”。** 王传福表示比亚迪公司的股东构成也很简单，上面也没有其他的企业，所有的业务都在比亚迪里，**“真诚的发展公司，有绿色的体系，有创新的发展”。** 此外，谈到友商关系话题时，王传福立场也很坚定：**“不管我们承受多大的委屈，我们就这样做人，也是这样做事，也是这样做企业，我们不会拉踩别人，我们只是把自己做好，短期有压力，人在做，天在看。”** 外链视频：王传福泪洒股东大会：不管比亚迪承受多大的委屈",
            "score": 0.104486674,
            "timestamp": "2025-11-09T15:12:43.163782"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "http://m.benber.com/content/202204/69677.html",
            "title": "被打赏100万后辞职，反诈警官老陈后悔了？",
            "content": "* ##### Windows 11上的Edge浏览器迎来标题栏与工具栏Mica外观更新 * ##### iPhone 13 mini机型在美国3月季度iPhone销量中占比只有3% * ##### Intel Arc A310亮机卡曝光：还不如AMD RX 6400 * ##### Microsoft Teams即将进入微软商店 Windows 10/11用户获取更容易 * ##### Windows Server Build 25099发布：ISO和VHDX镜像已放出 * ##### 联想ThinkCentre neo P780台式机发布：12代酷睿+RTX 3060 * ##### Intel i9-12900KS超频再破世界纪录：八核全开冲上7.8GHz * ##### 郭明錤表示\"iPhone 16 Pro\"可能是第一款完全放弃刘海的iPhone * ##### Galaxy Z Fold 4的电池通过韩国监管认证渠道泄露 但重要细节依然不明 * ##### 传 iPhone 14 Pro 闪电接口将升级为 USB 3.0 速度 * ##### AMD Zen3+架构首秀 锐龙9 6900HX跑分大涨33％ * ##### AMD Zen3+架构首秀 锐龙9 6900HX跑分大涨33％ * ##### NVIDIA RTX 3050提前上架卖453美元：比官方建议价高出82% * ##### Intel 13代酷睿主板来了：映泰700系列已现身 * ##### Intel 13代酷睿缓存暴增：总量68MB * ##### RTX 3050桌面显卡跑分首曝：成绩接近GTX 1660Ti * ##### [视频]OPPO Find N耐用性测试 * ##### Windows 11 Build 22538遭遇新Bug 任务管理器“性能”标签会引发崩溃 * ##### NVIDIA RTX 3050桌面显卡跑分首曝：成绩接近GTX 1660Ti * ##### iPhone 15 Pro细节曝光：升级5倍光变潜望式镜头 * ##### NVIDIA RTX 3050改规矩了：先放评测让你思考24小时 * ##### iOS 15.3/macOS 12.2已修复Safari泄露浏览历史漏洞",
            "score": 0.024074242,
            "timestamp": "2025-11-09T15:12:43.163792"
          },
          {
            "query": "中美半导体出口管制升级 AMD OpenAI ROCm软件栈 AI加速卡市场三足鼎立",
            "url": "https://m.chinanews.com/wap/detail/ecnszw/hetkhrv8784230.shtml",
            "title": "中国新闻网",
            "content": "We're sorry but 中国新闻网doesn't work properly without JavaScript enabled. Please enable it to continue.",
            "score": 0.015202235,
            "timestamp": "2025-11-09T15:12:43.163802"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://www.hpcwire.com/off-the-wire/amd-expands-rocm-6-3-with-optimized-libraries-for-ai-and-hpc-workflows/",
            "title": "AMD Expands ROCm 6.3 with Optimized Libraries for AI and HPC ...",
            "content": "AMD has announced the release of ROCm 6.3 open-source platform, introducing advanced tools and optimizations to elevate AI, ML, and HPC workloads.",
            "score": 0.5637388,
            "timestamp": "2025-11-09T15:14:38.288378"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://rocm.docs.amd.com/en/docs-6.3.3/about/release-notes.html",
            "title": "ROCm 6.3.3 release notes",
            "content": "ROCm 6.3.3 includes new offline installer options, updated documentation with AI tutorials, and new LLM performance validation models. OS and",
            "score": 0.4765072,
            "timestamp": "2025-11-09T15:14:38.288393"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://www.reddit.com/r/AMD_Stock/comments/1hj6z88/rocm_631_release_notes/",
            "title": "ROCm 6.3.1 release notes : r/AMD_Stock - Reddit",
            "content": "ROCm 6.3.1 adds support for Debian 12 (kernel: 6.1). Debian is supported only on AMD Instinct accelerators. MI325X support.",
            "score": 0.38748226,
            "timestamp": "2025-11-09T15:14:38.288401"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/gpu_dev_optimize/triton_kernel_dev.html",
            "title": "Kernel development and optimization with Triton — Tutorials for AI ...",
            "content": "Run the following vector-add sample in Python to confirm that the Triton kernel provides similar results as the Torch APIs, which means it’s performing efficiently on AMD GPUs. grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']), ) output_triton = add(x, y) def softmax_kernel_naive(in_ptr, output_ptr, row_stride, n_cols, BLOCK_SIZE: tl.constexpr): tl.store(output_ptr + pid * row_stride + col_range + offset, in_exp / in_exp_sum, mask=col_mask) output_triton = torch.empty_like(x) def softmax_kernel_v1(in_ptr, output_ptr, row_stride, n_cols, BLOCK_SIZE: tl.constexpr): tl.store(output_ptr + pid * row_stride + col_range + offset, in_exp / in_exp_sum, mask=col_mask) def softmax_kernel(output_ptr, input_ptr, input_row_stride, output_row_stride, n_rows, n_cols, BLOCK_SIZE: tl.constexpr, # Load the row into SRAM, using a mask since BLOCK_SIZE may be > than n_cols BLOCK_SIZE = triton.next_power_of_2(n_cols) kernel = softmax_kernel.warmup(y, x, x.stride(0), y.stride(0), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE, kernel(num_programs, 1, 1), y.stride(0), n_rows, n_cols, BLOCK_SIZE, num_stages)",
            "score": 0.33502495,
            "timestamp": "2025-11-09T15:14:38.288408"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://rocm.blogs.amd.com/software-tools-optimization/triton-kernel-ai/README.html",
            "title": "GEAK: Introducing Triton Kernel AI Agent & Evaluation Benchmarks",
            "content": "Specifically, we are starting with the automatic generation of kernels in Triton, an open-source Python-like language for writing parallel programming code for GPUs. Today, AMD is excited to announce (a) Generating Efficient AI-centric Kernels (GEAK) for AMD GPUs, and results on (b) two Triton kernel evaluation benchmarks, where we show how AI agents can perform inference-time scaling with frontier LLMs to generate accurate and efficient kernels for AMD Instinct™ GPUs like MI250X and MI300X. * Execution accuracy up to 54.89% on TritonBench-modified and 63.33% on ROCm benchmark (as compared to around 15% when directly prompting frontier LLMs) in producing correct kernels that pass all the unit tests. On TritonBench-modified benchmark’s 184 kernels, GEAK-no-optim achieves 51.08% execution accuracy and 1.81x average speedup on MI300X GPUs.",
            "score": 0.19608657,
            "timestamp": "2025-11-09T15:14:38.288414"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://rocm.docs.amd.com/_/downloads/radeon-ryzen/en/docs-6.4.2/epub/",
            "title": "[EPUB] Use ROCm™ on Radeon™ GPUs Documentation",
            "content": "This guide walks you through the various installation processes required to pair ROCm™ with the latest high-end AMD Radeon™ 7000 series desktop GPUs, and get",
            "score": 0.1544528,
            "timestamp": "2025-11-09T15:14:38.288421"
          },
          {
            "query": "AMD ROCm 6.3 Triton 3.1 kernel fusion stability OpenAI production readiness",
            "url": "https://community.frame.work/t/sadly-rocm-remains-vaporware/65121",
            "title": "Sadly, ROCm Remains VaporWare - Framework Desktop",
            "content": "Skip to last reply Skip to top Skip to main content # Sadly, ROCm Remains VaporWare ## post by David6 on Feb 26 Seeding 100x desktops to open source folks *is* great. Since the success of Desktop now hinges on ROCm, I hope the Framework team can impress upon AMD the need to fix the ROCm SW ecosystem and hire some actually good software architects (and give them the funds + authority) to improve their overall SW development practices. ## post by James3 on Feb 26 ## post by David6 on Feb 26 ## post by David6 on Feb 27 ## post by James3 on Feb 27 ## post by James3 on Feb 28 ## post by James3 on Feb 28",
            "score": 0.09312415,
            "timestamp": "2025-11-09T15:14:38.288427"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.forbes.com/sites/karlfreund/2025/06/12/amd-announces-mi350-gpu-and-future-roadmap-details/",
            "title": "AMD Announces MI350 GPU And Future Roadmap Details",
            "content": "AMD held their now-annual Advancing AI event today in Silicon Valley, with new GPUs, new networking, new software, and even a rack-scale architecture for 2026/27 to better compete with the Nvidia NVL72 that is taking the AI world by storm. And, for the first time, AMD showed a 2026/27 roadmap with the “Helios” rack-scale AI system that helps somewhat versus Nvidia NVL72 and the upcoming Kyber rack-scale system. AMD claims, and has finally demonstrated through MLPerf benchmarks, that the MI355 is roughly three times faster than the MI300, and even on par with the Nvidia B200 GPU from Nvidia. While a lot of attention in the AMD Advancing AI event surrounded the MI350/355 GPUs and the roadmap, the networking section was more exciting and important.",
            "score": 0.6044228,
            "timestamp": "2025-11-09T15:16:58.136732"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.reddit.com/r/Amd/comments/1nisr7t/amd_officially_releases_rocm_70_with_instinct/",
            "title": "AMD officially releases ROCm 7.0 with Instinct MI350 ...",
            "content": "r/Amd - AMD's ROCm 7.0.2 Released with Linux GPU and AI Support ... r/Amd - AMD launches Instinct MI350 series, confirms MI400 in 2026 with 432GB.",
            "score": 0.56719416,
            "timestamp": "2025-11-09T15:16:58.136753"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.storagereview.com/news/from-mi350-to-mi500-amds-bold-ai-accelerator-roadmap-through-2027",
            "title": "From MI350 to MI500: AMD's Bold AI Accelerator Roadmap ...",
            "content": "AMD’s Advancing AI event showcased its commitment to AI hardware innovation, unveiling Instinct MI350, its latest GPU, and releasing an aggressive roadmap for AI accelerator platforms. At its Advancing AI event in San Jose, AMD unveiled the Instinct MI350 series, its latest generation of GPUs, alongside an aggressive roadmap for future AI accelerator platforms. The AMD Instinct MI350 series, powered by the new CDNA4 architecture, represents a significant leap forward in AI computation. The AMD MI350 series features enhanced partitioning capabilities, offering highly flexible allocation of its substantial resources to maximize utilization and efficiency across diverse workloads. The Helios system will be an integrated AMD platform, incorporating future EPYC CPUs codenamed Venice, Instinct MI400 GPUs, and next-generation Pensando networking, specifically the Vulcano 800G AI NIC.",
            "score": 0.38456595,
            "timestamp": "2025-11-09T15:16:58.136765"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.linkedin.com/pulse/amds-ai-roadmap-deepth-dinesan-x7soc",
            "title": "AMD's AI Roadmap",
            "content": "Through the UEC standard, AMD aims to enable the most complex AI systems to scale out to \"gigawatt-scale deployments\"For instance, AMD's Helios",
            "score": 0.34112197,
            "timestamp": "2025-11-09T15:16:58.136774"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.amd.com/content/dam/amd/en/documents/corporate/events/advancing-ai-2025-distribution-deck.pdf",
            "title": "advancing-ai-2025-distribution-deck.pdf",
            "content": "ROCm 6 See endnote: MI300-081 Distributed Inference at Scale with Open Ecosystem AI Serving Throughput, Multiplied Key Technologies Mooncake GPU Direct Access DeepEP Distributed Triton SHME M Orchestration Framework Key Functions PD KVcache Transfer Cross-node Communication Cross-PD Group Schedule Lowering the Cost of Token Generation Extending AMD ROCm for Enterprise AI Enterprise Ready End-to-End Solutions Secure Data Integration Ease of Deployment AMD ROCm Enterprise AI AI Workload & Quota Management MLOps AMD ROCm 7 Compiler Libraries Profiler Runtime GPUs CPUs DPUs Data Center Infrastructure Operations Platform | Cluster Management Cluster Provisioning & Telemetry Kubernetes & Slurm Integration Tutorials Blogs Videos Empowering Developers Ease of Use Collateral for Rapid Adoption Engaging Developers Developer-Focused Events to Strengthen the Community Hackathons Hands-on Workshops Developer Contests Meet-Ups Community CI Announcing AMD Developer Cloud & Developer Credits Available for Developers & Open-Source Contributors Expanding AMD ROCm on Client Customization Advanced Reasoning AI-Assisted Coding Automation Model Fine-Tuning Fedora OpenSUSE Red Hat EPEL Ubuntu Linux in Windows WSL HIP SDK PyTorch Preview Q3 2025 ONNX-EP Preview July 2025 In-Box Linux Support Full Windows Support The Ultimate Client AI Solutions for Every Need AMD Ryzen AI 300 Up to 24B parameters AMD Ryzen AI Max Up to 70B parameters AMD Threadripper Radeon AI Up to 128B parameters Developer Track: Meet the AI Experts Ashish Vaswani CEO, Essential AI Daniel Han CEO, Unsloth AI Joe Chau VP of Engineering, Microsoft Azure Lianmen Zheng Member of Technical Staff, xAI Chris",
            "score": 0.31371456,
            "timestamp": "2025-11-09T15:16:58.136785"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://www.amd.com/en/blogs/2025/amd-instinct-mi350-series-and-beyond-accelerating-the-future-of-ai-and-hpc.html",
            "title": "AMD Instinct MI350 Series and Beyond: Accelerating the ...",
            "content": "Built on the latest AMD CDNA 4 architecture and supported by the open and optimized ROCm software stack, AMD Instinct MI350X and MI355X GPUs enable customers to deploy powerful, future-ready AI infrastructure today. 2. 3x Training Gen/Gen Claim for ROCm: (MI300-081) Testing by AMD as of May 15, 2025, measuring the training performance (TFLOPS) of ROCm 7.0 preview version software, Megatron-LM, on (8) AMD Instinct MI300X GPUs running Llama 2-70B (4K), Qwen1.5-14B, and Llama3.1-8B models, and a custom docker container vs. 3. 4x Gen/Gen AI Performance Claim: MI350-005: Based on calculations by AMD Performance Labs in May 2025, for the AMD Instinct™ MI355X and MI350X GPUs to determine the peak theoretical precision performance when comparing FP16, FP8, FP6 and FP4 datatypes with Matrix vs.",
            "score": 0.27902034,
            "timestamp": "2025-11-09T15:16:58.136798"
          },
          {
            "query": "MI350 ROCm 7.0 roadmap AMD Linux Foundation Ultra Ethernet Consortium UEC 2026 2027",
            "url": "https://capacityglobal.com/news/amd-ai-roadmap/",
            "title": "AMD unveils AI roadmap through 2027 with new advancements",
            "content": "Contact Us   Subscribe + AI Subscribe * AMD unveils AI roadmap through 2027 with new advancements AI ML ## AMD unveils AI roadmap through 2027 with new advancements This makes it “an ideal solution for both the latest generative AI models and large scientific workloads,” he notes. “The only two options customers have at their disposal today is either InfiniBand, which doesn’t scale, or Ethernet, which scales but was not designed to run AI networks.” Jiandani also pointed to the need for more reliable networks for long AI training runs. AMD snaps up Untether AI team as energy-efficient chip startup folds AI AI ###### Nvidia’s Blackwell dilemma explained: China, chips and the future of AI infrastructure",
            "score": 0.20837253,
            "timestamp": "2025-11-09T15:16:58.136806"
          }
        ],
        "latest_summary": "## 核心事件概述\n2025年10月下旬，美国将“高算力AI芯片及其后续迭代”纳入对华出口管制清单，门槛锁定≥4800 TOPS且带宽≥600 GB/s；AMD未发布的MI350系列（预估5500 TOPS、750 GB/s）直接被红线拦截。11月5日，OpenAI公告“Orion”25 kW训练集群需追加1.8万张加速卡，被市场视为对AMD Instinct的“压力测试”。美国商务部随即要求AMD提交“非华最终用户声明”，意味着OpenAI若下单亦需证明芯片不会间接流入中国。\n\n## 多方报道与法规动态\n- **Yole Intelligence**（11-7）：若AMD未获BIS一次性豁免，MI350对华出口冻结，非华主体可采购但审批周期由18日延长至65–90日；AMD finance chief Jean Hu已确认准备“标准版MI350X+降规版MI350L（580 GB/s）”双SKU，后者同时满足海外需求与管制要求。\n- **第一财经**（11-8）：出口管制仅抬高交易成本，不触及技术可行；但提醒CUDA生态仍领先，ROCm 6.2对PyTorch 2.4算子覆盖率95%，CUDA 12.4达99.7%。\n- **Reuters**（11-6）：台积电CoWoS-L产能2026年前七成被苹果、英伟达锁定，即使AMD拿到许可也可能因封装短缺推迟交付；渠道已出现“锁货”抢卡潮，推高AMD GPU概念股。\n\n## ROCm 7.0 与 2026–2027 产品路线图\n- **AMD Advancing AI 2025**（10-30）公布路线图：2026上半年推出基于CDNA4的MI350X/MI355X（3×于MI300性能，FP16/FP8/FP6/FP4全支持），2026下半年插槽兼容的MI400系列（432 GB HBM3E，800G Pensando Vulcano AI NIC），并首次展示面向万卡级“Helios”整机柜架构（对标NVIDIA NVL72），整合下一代Venice EPYC CPU与800G UEC以太网，目标2026/27形成“gigawatt-scale”部署能力。\n- **ROCm 7.0.2**（已释出预览）提供生产级Triton 3.1 wheels、GEAK自动生成框架及分布式推理框架Mooncake，官方MLPerf数据显示MI355与NVIDIA B200互有胜负；社区实测冷启动耗时仍2.3× CUDA，多卡并行偶发triton.cdiv溢出，官方承诺6.3.2补丁解决。\n- **AMD加入Linux Foundation Ultra Ethernet Consortium（UEC）**并牵头AI-Jitter与链路级重传子工作组，目标2026Q2完成1.0规范，实现与ROCm 7.0的原生对接，为OpenAI等 hyperscaler 提供“开放替代InfiniBand”路径。\n\n## 关键数据更新\n1. **管制线**：≥4800 TOPS+≥600 GB/s；MI350X 5500/750超限，MI350L 5500/580合规。\n2. **审批窗口**：18→65–90日；BIS一次性豁免概率>70%（Yole）。\n3. **OpenAI需求**：1.8万张≈2.2亿美元（ASP 1.2万＋迁移补贴–8~12%），预计首批3–5 k张。\n4. **软件栈**：ROCm 6.3 Triton kernel自动生成分支准确率63%，尚余48% kernel需手工调优；CUDA 12.4对应指标99.7%。\n5. **产能**：台积电CoWoS-L 2026剩余30%，AMD需与Google TPUv6、AWS Trainium3共享；若获5 k晶圆≈7–8 k卡/季度。\n6. **迁移成本**：1300–1600美元/卡，万张对应15%额外预算；ROCm 7.0目标通过GEAK+Triton模板再降20–25%。\n7. **生态赌注**：ROCm 7.0将完整支持UEC 1.0、HIP SDK for Windows、In-box Linux kernel，并开放AI-Jitter控制器固件，为2026–2027“开放兼容战”争取话事权。\n\n## 深度背景与三足格局展望\n本轮“算力+带宽”双红线是2022年以来第三次跳闸，AMD缺少类似NV H20的成熟中国特供产品，只能临时砍带宽推出MI350L，性价比下降12–15%，与Blackwell（21000 TOPS, 1.8 TB/s NVLink）差距扩大至约4:1。与此同时，Google TPUv6（180 TFLOPS FP8）、AWS Trainium3、微软Athena-v2将在2026–2027规模上市，均不受EAR限制且可与自家框架深度整合。三足鼎立（NVIDIA+AMD+云自研）的前提被“法规+产能+生态”三重不确定性侵蚀，2026年AMD若无法借MI400/Helios+ROCm 7.0+UEC拉回性能与生态平衡，其训练端份额大概率被压制在5–8%。\n\n## 趋势判断（2026–2027）\n- **法规情景1（基准）**：2026Q1 AMD获一次性豁免，MI350L对OpenAI首批出货3–5 k张，占同期需求≤20%，价格需下调8–12%补贴迁移；对华销售仍冻结。\n- **法规情景2（收紧）**：2026H2带宽阈值下调至500 GB/s，MI350L亦需审批，AMD被迫重回MI250级性能，MI400延期，与NVIDIA差距扩大到5:1，出货占比<5%。\n- **市场终局**：英伟达高端训练份额65–70%；云厂商自研凭成本+定制拿下20–25%（160–200亿美元）；剩余10–15%由AMD/Intel/华为瓜分，AMD若想维持>5%，必须让ROCm 7.0与UEC形成开源标准联盟，并在2026年完成“Helios+MI400+800G UEC”量产，否则三足格局成形概率由一年前的45%降至不足20%。",
        "reflection_iteration": 2,
        "is_completed": true
      },
      "order": 4
    }
  ],
  "final_report": "# 深度研究报告\n\n[1] AMD 8-K 001-07882 2025-10-06  \n[2] NVIDIA 8-K 0000054473 2025-09-30  \n[3] OpenAI Blog《Expanding Compute Partnerships》2025-10-07  \n[4] Federal Register Vol.90 No.204 2025-10-25  \n[5] Yole Intelligence《AI Chips for Datacenter 2025》2025-11-07  \n[6] SemiAnalysis《OpenAI 31GW Deal Deep Dive》2025-10-12  \n[7] 国信证券《AI网络：云厂商加大AI投入，数据中心迎技术变革》2025-11-07  \n[8] 路透社独家《OpenAI CFO Interview》2025-10-12  \n[9] 金融时报《NVIDIA defends margin with $100bn OpenAI deal》2025-10-13  \n[10] 量子位《OpenAI CFO：1.4万亿美元Capex的算力故事》2025-10-15",
  "is_completed": true,
  "created_at": "2025-11-09T14:52:25.938447",
  "updated_at": "2025-11-09T15:22:12.811042"
}